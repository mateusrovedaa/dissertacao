%
% Exemplo LaTeX de monografia UNISINOS
%
% Elaborado com base nas orientações dadas no documento
% ``GUIA PARA ELABORAÇÃO DE TRABALHOS ACADÊMICOS''
% disponível no site da biblioteca da Unisinos.
% http://www.unisinos.br/biblioteca
%
% Os elementos textuais abaixo são apresentados na ordem em que devem
% aparecer no documento.  Repare que nem todos são obrigatórios - isso
% é devidamente indicado em cada caso.
%
% Comentários abaixo colocados entre aspas (`` '') foram
% extraídos diretamente do documento da biblioteca.
%
% Este documento é de domínio público.
%

%=======================================================================
% Declarações iniciais identificando a classe de documento e
% selecionando alguns pacotes adicionais.
%
% As opções disponíveis (separe-as com vírgulas, sem espaço) são:
% - twoside: Formata o documento para impressão frente-e-verso
%   (o default é somente-frente)
% - english,brazilian,french,german,etc.: idiomas usados no documento.
%   Deve ser colocado por último o idioma principal.
%=======================================================================
\documentclass[twoside,english,brazilian]{UNISINOSmonografia}
\usepackage[utf8]{inputenc} % charset do texto (utf8, latin1, etc.)
\usepackage[T1]{fontenc} % encoding da fonte (afeta a sep. de sílabas)
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage[portuguese,ruled,vlined,linesnumbered]{algorithm2e}
\usepackage{graphicx} % comandos para gráficos e inclusão de figuras
\usepackage{bibentry} % para inserir refs. bib. no meio do texto
\usepackage{subcaption}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{babel}

%=======================================================================
% Escolha do sistema para geração de referências bibliográficas.
%
% O default é usar o estilo unisinos.bst.  Comente a definição abaixo
% e descomente a linha seguinte para usar o estilo do ABNTeX (é
% necessário ter esse pacote instalado).
%
% A vantagem do unisinos.bst é que ele permite o uso de um arquivo .bib
% seguindo as orientações tradicionais do BibTeX (veja essas orientações
% em http://ctan.tug.org/tex-archive/biblio/bibtex/contrib/doc/btxdoc.pdf).
% Entretanto, o estilo não suporta algumas citações mais exóticas como
% apud.  Para isso, use o ABNTeX, mas esteja ciente de que muitas de
% suas referências serão incompatíveis com os estilos tradicionais do
% BibTeX como plain, alpha, ieeetr, entre outros.
%=======================================================================
\unisinosbst
%\usepackage[alf]{abntcite}

%=======================================================================
% Dados gerais sobre o trabalho.
%=======================================================================
\autor{Roveda}{Mateus}
\titulo{VISPAC: COMPRESSÃO ADAPTATIVA E PRIORIZAÇÃO INTELIGENTE NO MONITORAMENTO DE SINAIS VITAIS DE PACIENTES EM ARQUITETURAS Edge-Fog-Cloud}
\orientador[Prof.~Dr.]{Righi}{Rodrigo da Rosa}
%\coorientador[Prof.~Dr.]{Lamport}{Leslie}

\unidade{Unidade Acadêmica de Pesquisa e Pós-Graduação}
\curso{Programa de Pós-Graduação em Computação Aplicada}
\nivel{Nível Mestrado}
\natureza{%
Dissertação apresentada como requisito parcial para a obtenção
do título de Mestre pelo Programa de Pós-Graduação em Computação
Aplicada da Universidade do Vale do Rio dos Sinos --- UNISINOS
}
\local{São Leopoldo}
\ano{2025}

% dados da ficha catalográfica
% (obrigatória somente para dissertações e teses)
\cip{Dissertação (mestrado)}{004.732}
\bibliotecario{Bibliotecária responsável: Fulana da Silva}{12/3456}

% cada palavra-chave deve ser fornecida duas vezes, uma em português e
% outra no idioma estrangeiro (na verdade, em tantos idiomas quantos se
% desejar).
\palavrachave{brazilian}{Internet das Coisas}
\palavrachave{brazilian}{Sinais vitais}
\palavrachave{brazilian}{Compressão de dados adaptativa}
\palavrachave{brazilian}{Compressão de dados híbrida}
\palavrachave{brazilian}{Cidades inteligentes}
\palavrachave{english}{Internet of Things}
\palavrachave{english}{Vital signs}
\palavrachave{english}{Adaptive data compression}
\palavrachave{english}{Hybrid data compression}
\palavrachave{english}{Smart cities}


%=======================================================================
% Início do documento.
%=======================================================================
\begin{document}
\capa
\folhaderosto
\folhadeaprovacao % não deve ser incluída nos TCCs

%=======================================================================
% Agradecimentos (opcional).
%=======================================================================
\begin{agradecimentos}
Aos meus pais (Leonel e Eliane). Mesmo sem acesso ao conhecimento quando jovens, sempre reforçaram, ao longo da minha vida, que estudar, aprender e compartilhar são fundamentais. A vocês, o meu mais sincero obrigado. Vocês fizeram escolhas e renúncias que me permitiram estudar e alcançar meus objetivos.

À minha esposa Kátia, que sempre ofereceu apoio emocional e motivacional para que essa etapa fosse cumprida. Seu apoio permitiu-me seguir em frente diante dos desafios e do cansaço. Você foi muito importante nessa jornada. Sem você, dificilmente chegaria ao final tão empolgado.

Ao meu orientador, Rodrigo da Rosa Righi, que, ao longo da jornada, sempre instigou a ir além e direcionou os caminhos a serem trilhados e os objetivos a serem alcançados. Estendo o agradecimento a todos os professores que fizeram parte desse caminho, deixando um pouco de si em prol do conhecimento e do avanço científico, além dos avaliadores, que apontaram itens importantes para ajustes e visões, para que o trabalho ficasse mais coeso e atingisse os objetivos estipulados. Também estendo os agradecimentos a todos os alunos/professores com quem, indiretamente, acabei tendo contato ao longo do processo.

Por fim, a Universidade do Vale do Rio dos Sinos, que abriu suas portas para essa pesquisa e me permitiu ter uma experiência enriquecedora no processo, alcançando meu objetivo e contribuindo para a iniciação científica.
\end{agradecimentos}

%=======================================================================
% Resumo em Português.
%
% A recomendação é para 150 a 500 palavras.
%=======================================================================
\begin{abstract}
A Internet das Coisas (IoT) tem impactado de forma expressiva diversas áreas, especialmente a medicina, ao viabilizar o monitoramento contínuo e remoto de pacientes por meio de arquiteturas \textit{Edge-Fog-Cloud}, que combinam conectividade e processamento em tempo hábil. O desafio central está no grande volume de dados gerado por múltiplos sensores, que pode sobrecarregar a infraestrutura de rede, aliado à necessidade de garantir que alterações clínicas críticas sejam comunicadas com mínima latência, permitindo intervenções rápidas. Neste cenário, o tema desta dissertação é a otimização do monitoramento de sinais vitais em ambientes de saúde conectados, com foco na utilização eficiente de recursos computacionais e de rede. Embora existam avanços relevantes na área, a maioria dos trabalhos relacionados trata compressão e priorização de forma dissociada, sem integrar uma compressão multissinal adaptativa a uma priorização clínica baseada em escores padronizados. Além disso, falta um ciclo fechado onde a inteligência das camadas \textit{fog-cloud} reconfigure dinamicamente a coleta na camada \textit{edge}. Esta dissertação propõe o modelo \textit{Vital Sign Prioritization and Adaptive Compression} (ViSPAC), que unifica compressão e priorização adaptativa com base no escore clínico National Early Warning Score 2 (NEWS2). O escore é utilizado para ajustar, em tempo hábil, os parâmetros de compressão e a frequência de coleta, otimizando recursos sem comprometer a fidelidade dos sinais. O modelo incorpora uma estratégia de controle que equilibra eficiência e segurança clínica por meio de três algoritmos interdependentes: configuração dinâmica por sinal vital, \textit{back-off} exponencial condicionado ao risco e vigilância contínua (\textit{keep-alive}). Os experimentos foram conduzidos em ambiente distribuído na AWS com 20 nós de borda operando sob restrições de hardware similares a dispositivos IoT. Os resultados demonstraram que o ViSPAC reduziu em 96,7\% o número de transmissões comparado à linha de base, alcançou taxa de compressão média de 81,6\% (superior aos 75,0\% do cenário estático) e obteve distorção PRD média global de apenas 1,16\%, substancialmente inferior aos 3,62\% do modelo estático. A adoção de serialização binária \textit{MessagePack} reduziu o volume bruto dos \textit{payloads} em aproximadamente 30\% em relação ao JSON textual. A latência média do ciclo de \textit{feedback} foi de 1.048,9 ms, adequada para monitoramento remoto não invasivo. Em síntese, o ViSPAC apresenta-se como uma solução equilibrada para o monitoramento de saúde em larga escala no contexto de Cidades Inteligentes, otimizando recursos de rede e energia sem comprometer a capacidade de resposta a eventos clínicos adversos.
\end{abstract}

%=======================================================================
% Resumo em língua estrangeira (obrigatório somente para teses e
% dissertações).
%
% O idioma usado aqui deve necessariamente aparecer nos parâmetros do
% \documentclass, no início do documento.
%=======================================================================
\begin{otherlanguage}{english}
\begin{abstract}
The Internet of Things (IoT) has substantially impacted various fields, especially medicine, by enabling continuous and remote patient monitoring through Edge-Fog-Cloud architectures, which combine connectivity with real-time processing. The central challenge lies in the large volume of data generated by multiple sensors, which can overload the network infrastructure, coupled with the need to ensure that critical clinical changes are communicated with minimal latency to allow timely interventions. In this context, the central theme of this dissertation is the optimization of vital sign monitoring in connected healthcare environments, focusing on the efficient use of computational and network resources. Although notable advances have been made in the field, most related works address compression and prioritization separately, without integrating adaptive multi-signal compression with clinical prioritization based on standardized scores. Moreover, there is a lack of a closed-loop system in which intelligence in the fog-cloud layers dynamically reconfigures data collection at the edge. This dissertation proposes the Vital Sign Prioritization and Adaptive Compression (ViSPAC) model, which unifies adaptive compression and prioritization based on the clinical score National Early Warning Score 2 (NEWS2). The score is used to adjust compression parameters and sampling frequency in real time, optimizing resources without compromising signal fidelity. The model incorporates a control strategy that balances efficiency and clinical safety through three interdependent algorithms: dynamic configuration per vital sign, risk-conditioned exponential back-off, and continuous vigilance (keep-alive). Experiments were conducted in a distributed AWS environment with 20 edge nodes operating under hardware constraints similar to IoT devices. The results demonstrated that ViSPAC reduced the number of transmissions by 96.7\% compared to the baseline, achieved an average compression rate of 81.6\% (higher than the 75.0\% of the static scenario), and obtained a global average PRD distortion of only 1.16\%, substantially lower than the 3.62\% of the static model. The adoption of binary MessagePack serialization reduced raw payload volume by approximately 30\% compared to textual JSON. The average feedback loop latency was 1,048.9 ms, suitable for non-invasive remote monitoring. In summary, ViSPAC presents itself as a balanced solution for large-scale health monitoring in the context of Smart Cities, optimizing network and energy resources without compromising the ability to respond to adverse clinical events.
\end{abstract}
\end{otherlanguage}

%=======================================================================
% Lista de Figuras (opcional).
%=======================================================================
\listoffigures

%=======================================================================
% Lista de Tabelas (opcional).
%=======================================================================
\listoftables


%=======================================================================
% Lista de Siglas (opcional).
%
% Deve ser passada como parâmetro a maior das siglas utilizadas.
%=======================================================================
\begin{listadesiglas}{FAPERGS}
\item[ABNT] Associação Brasileira de Normas Técnicas
\item[AWS] Amazon Web Services
\item[BVP] Blood Volume Pulse
\item[CAPES] Coordenação de Aperfeiçoamento de Pessoal de Nível Superior
\item[CD] Compression Deviation
\item[CPU] Central Processing Unit
\item[ECG] Eletrocardiograma
\item[FAPERGS] Fundação de Amparo à Pesquisa do Estado do Rio Grande do Sul
\item[FC] Frequência Cardíaca
\item[FR] Frequência Respiratória
\item[HTTP] HyperText Transfer Protocol
\item[IaC] Infrastructure as Code
\item[IoT] Internet of Things
\item[JSON] JavaScript Object Notation
\item[MessagePack] Formato de serialização binária compacto
\item[MQTT] Message Queuing Telemetry Transport
\item[MSE] Mean Squared Error
\item[NEWS2] National Early Warning Score 2
\item[PRD] Percentage Root Mean Difference
\item[PSNR] Peak Signal-to-Noise Ratio
\item[QoS] Qualidade de Serviço
\item[RMSE] Root Mean Square Error
\item[SaaS] Software as a Service
\item[SAMU] Serviço de Atendimento Móvel de Urgência
\item[SCADA] Supervisory Control and Data Acquisition
\item[SDT] Swinging Door Trending
\item[SoC] System on a Chip
\item[SpO2] Saturação Periférica de Oxigênio
\item[SSIM] Structural Similarity Index
\item[TCP] Transmission Control Protocol
\item[TLS] Transport Layer Security
\item[ViSPAC] Vital Sign Prioritization and Adaptive Compression
\item[VSAC] Vital Sign Adaptive Compressor
\item[WBAN] Wireless Body Area Network
\end{listadesiglas}

%=======================================================================
% Sumário
%=======================================================================
\tableofcontents

%=======================================================================
% Introdução
%=======================================================================
\chapter{Introdução}
\label{intro}

Nos últimos anos, a Internet das Coisas (IoT) tem ganhado destaque na área da saúde, apresentando crescimento significativo impulsionado pelo desenvolvimento de dispositivos especializados para aplicações médicas. Uma revisão sistemática recente identificou avanços substanciais em tecnologias de sensores vestíveis para monitoramento de saúde, abrangendo aplicações clínicas, reabilitação e avaliação de risco de doenças \cite{Gu2026}. Em particular, o monitoramento remoto de pacientes por meio da IoT vem se mostrando de grande importância, pois permite acompanhar continuamente sinais vitais fora do ambiente hospitalar, aliviando a sobrecarga dos hospitais e oferecendo melhor suporte a pacientes com doenças crônicas \cite{Damera2025}. Sinais vitais como frequência cardíaca (FC), temperatura corporal, saturação de oxigênio periférico (\textit{SpO\textsubscript{2}}) e frequência respiratória são indicadores essenciais do estado de saúde; seu acompanhamento em tempo hábil possibilita a detecção precoce de alterações clínicas relevantes e uma intervenção médica mais rápida. Pacientes idosos ou com enfermidades crônicas frequentemente necessitam desse monitoramento contínuo de parâmetros fisiológicos, pois a falta de vigilância pode acarretar riscos graves à sua saúde. Nesse contexto, a combinação de IoT e sistemas de saúde conectados tem impulsionado a telemedicina e a criação de soluções de \textit{e-health} inteligentes, integrando sensores biomédicos que coletam esses sinais e os encaminham para avaliação remota em tempo hábil \cite{ALI2025}. A Figura \ref{fig:mhd} demonstra um painel de exemplo para monitoramento de saúde pública em tempo hábil, onde é possível analisar sinais vitais, alertas e o status do sistema a nível macro.

\begin{figure}[ht]
\caption{Painel de controle de exemplo para monitoramento da saúde pública}
\label{fig:mhd}
\centering
\includegraphics[width=\textwidth]{imagens/mhd.png}
\fonte{Adaptado do projeto Minha História Digital, de autoria de Rodrigo da Rosa Righi e Alexandre Luis de Andrade}
\end{figure}

Entretanto, o monitoramento unificado traz um grande desafio: gerenciar a quantidade gigantesca de dados gerados. Estudos recentes demonstram que sistemas de monitoramento contínuo de sinais vitais podem ser escalados para operar em redes hospitalares com múltiplas unidades, evidenciando tanto a viabilidade quanto os desafios de infraestrutura envolvidos \cite{Nguyen2026}. Relatórios de mercado mostram que a infraestrutura conectada continua crescendo rápido. Como mostra a Figura \ref{fig:iot_forecast}, o mundo chegou a 21,1 bilhões de dispositivos IoT ativos em 2025, e a previsão é que esse número suba para \textbf{23,9 bilhões já em 2026} \cite{IoTAnalytics2025}. Isso faz com que o volume de dados gerados no mundo todo dispare. Estimativas apontam que vamos atingir a marca de 221 Zettabytes (ZB) de dados armazenados até 2026 \cite{CybersecurityVentures2025, BetaSystems2025}. Nesse cenário, o problema deixa de ser apenas limitações de rede e passa a ser o alto custo financeiro e energético para transmitir e guardar tudo isso na nuvem \cite{IDC2025}.

\begin{figure}[ht]
\caption{Previsão de mercado global de IoT e crescimento da base instalada (2020-2035)}
\label{fig:iot_forecast}
\centering
\includegraphics[width=\textwidth]{imagens/iot_analysis.png}
\fonte{Adaptado de \cite{IoTAnalytics2025}}
\end{figure}

Quando examinamos o tráfego gerado por sensores de saúde, percebemos que a maioria dos dados transmitidos não é informação clínica de fato, mas sim informações extras exigidas pelos protocolos de comunicação (\textit{overhead}). Para entender melhor esse problema, vamos analisar uma transmissão padrão via HTTP/1.1. Os dados úteis contêm as informações vitais básicas: FC (1 byte), \textit{SpO\textsubscript{2}} (1 byte), identificador (4 bytes) e horário (8 bytes), totalizando apenas 14 bytes. Porém, para que diferentes sistemas consigam se comunicar, esses dados precisam ser formatados em estruturas como JSON, que adiciona vários caracteres extras e aumenta o tamanho para cerca de 49 bytes:

\begin{verbatim}
{"pid":1234,"ts":1726713420000,"fc":78,"spo2":98}
\end{verbatim}

O problema fica ainda maior quando esses dados são preparados para o transporte pela rede. Cada transmissão precisa incluir os cabeçalhos do HTTP/1.1 (cerca de 124 bytes) \cite{rfc9112}, além dos cabeçalhos das camadas de infraestrutura: IPv4 (20 bytes) \cite{rfc791} e TCP (20 bytes) \cite{rfc9293}. Somando tudo, o custo final para transmitir aqueles 14 bytes de informação real chega a aproximadamente 213 bytes, criando uma proporção bem desequilibrada entre o conteúdo útil e toda a estrutura necessária para enviá-lo.


Esse desequilíbrio gera consequências quando consideramos o cenário de larga escala mencionado antes. Transmitir pacotes onde a maior parte é apenas estrutura de protocolo esgota rapidamente a bateria dos dispositivos portáteis e aumenta os custos operacionais na nuvem, já que os serviços de armazenamento e transferência de dados cobram pelo volume total movimentado \cite{aws_pricing}. Dessa forma, a ineficiência no transporte de pequenos volumes de dados impõe barreiras técnicas e financeiras que podem inviabilizar a sustentabilidade do monitoramento contínuo.

Nesse contexto, torna-se crucial empregar técnicas eficientes de compressão de dados para reduzir o tráfego sem perder informações clínicas relevantes. A compressão adequada dos sinais vitais permite minimizar o volume transmitido da borda até a nuvem, evitando sobrecarga da rede e atendendo aos requisitos de tempo de resposta dos sistemas de telemonitoramento \cite{Kadhim2022}. Diversas abordagens vêm sendo exploradas na literatura para dados biomédicos, incluindo métodos com perdas controladas (lossy) e sem perdas (lossless), com o objetivo de otimizar a utilização de banda e armazenamento sem comprometer a integridade dos sinais necessários ao diagnóstico.

Além da compressão, outro aspecto fundamental em sistemas de IoT para a medicina é a priorização dos dados coletados para suportar decisões clínicas em tempo hábil. Nem todos os sinais transmitidos possuem a mesma criticidade: leituras dentro da normalidade toleram certa latência, enquanto alterações maiores exigem entrega imediata para permitir intervenções rápidas. Abordagens recentes propõem classificar pacotes em níveis de prioridade de acordo com limiares fisiológicos, demonstrando redução da latência de alerta quando filas de prioridade são empregadas \cite{DANG2025}. Essa diferenciação visa garantir qualidade de serviço (QoS) adequada, de modo que informações críticas (e.g., detecção de arritmia cardíaca ou queda significativa de saturação de oxigênio) sejam comunicadas com o mínimo de atraso e confiabilidade máxima, pois atrasos na entrega de dados vitais anômalos podem ser potencialmente fatais. Estratégias de roteamento e gerenciamento de fila sensíveis à prioridade têm se mostrado eficazes para reduzir a latência de dados emergenciais em redes de sensores corporais e ambientes hospitalares conectados \cite{Anwar2022}. Em um cenário prático, essa capacidade de priorização pode beneficiar diretamente serviços de emergência como o SAMU (Serviço de Atendimento Móvel de Urgência): ao receber, em tempo hábil, o escore de risco clínico de múltiplos pacientes monitorados em uma região, a central de regulação médica poderia otimizar o despacho de ambulâncias, priorizando os casos mais críticos e permitindo que médicos e socorristas tomem decisões de triagem fundamentadas em dados objetivos, especialmente em cenários de múltiplas vítimas ou recursos limitados. 

Portanto, a utilização da arquitetura \textit{edge-fog-cloud} se torna fundamental. Considerada o estado da arte para sistemas distribuídos, sua estrutura remete à organização político-geográfica de uma cidade: a borda (\textit{edge}) corresponde à coleta local de dados (residências, empresas); a névoa (\textit{fog}) atua como um centro de processamento regional (postos de saúde, centros de dados municipais); e a nuvem (\textit{cloud}) representa a infraestrutura centralizada (secretaria de saúde estadual ou nacional ou hospitais). Nesse ecossistema, mecanismos de compressão e priorização de dados como os discutidos aqui funcionam como um \textit{middleware} essencial, que viabiliza a tomada de decisão clínica em tempo hábil e insere o monitoramento de saúde como um serviço chave em aplicações de Cidades Inteligentes.

Nesse cenário, a literatura propõe modelos arquiteturais que aliem compressão de dados e entrega seletiva de informações conforme sua relevância clínica. Dentre eles, destaca-se o modelo VSAC (\textit{Vital Sign Adaptive Compressor}), concebido para transmissão eficiente de sinais vitais em aplicações IoT para a medicina \cite{Andrade2025}. O VSAC combina algoritmos de compressão com perdas e sem perdas em uma arquitetura hierárquica de múltiplas camadas (\textit{edge–fog–cloud}), reduzindo drasticamente o volume de dados transmitido sem comprometer a qualidade da informação. Em sua operação, inicialmente aplica-se compressão \textit{lossy} adaptativa para filtrar e reter apenas as informações mais relevantes de cada sinal vital, seguida de compressão \textit{lossless} para compactar os dados antes do envio às camadas superiores. Essa abordagem híbrida demonstrou desempenho superior aos métodos convencionais de redução de dados, alcançando ganhos de compressão de até 46\% na taxa de redução de bytes transmitidos, quando comparada a técnicas isoladas \cite{Andrade2025}. Em outras palavras, o VSAC provê um mecanismo otimizado de coleta e agregação de sinais heterogêneos distribuídos geograficamente, com processamento em tempo hábil na borda, atendendo às demandas de aplicações de tele-saúde em cenários de cidades inteligentes.

\begin{figure}[ht]
\caption{Coleta de sinais vitais através de sensores, compressão adaptativa e envio para um centro de processamento (hospital) para cálculo do risco clínico. Essa coleta acontece como um ciclo, coletando diversas vezes os sinais vitais dos pacientes e transmitindo, podendo inundar a rede com pacotes caso não haja compressão e/ou tratamentos}
\label{fig:micro}
\centering
\includegraphics[width=0.9\textwidth]{imagens/macro.pdf}
\fonte{Elaborado pelo autor}
\end{figure}


Na presente dissertação, propõe-se uma continuidade do VSAC, com testes com multiplos sinais vitais (incluindo, além da FC já considerada, parâmetros como o \textit{SpO\textsubscript{2}}) e a incorporação de um mecanismo de priorização inteligente dos dados baseado em escores clínicos de gravidade, utilizando o NEWS2, denominado \textit{Vital Signs Prioritized Adaptive Compression} (ViSPAC). Em termos práticos, o sistema passa a adaptar dinamicamente os níveis de compressão e a ordem de transmissão dos sinais de acordo com indicadores clínicos de urgência, potencializados por \textit{feedbacks} das camadas \textit{fog} ou \textit{cloud}. Essa estratégia permite que informações críticas recebam tratamento preferencial (menor compressão ou envio imediato), assegurando que eventos potencialmente perigosos sejam comunicados sem atrasos significativos.

Assim, o modelo proposto não apenas mantém os benefícios de redução de volume de dados e arquitetura do VSAC, como também agrega uma camada adicional na gestão dos dados médicos, priorizando-os conforme o estado do paciente. Espera-se, com isso, otimizar a transmissão dos sinais vitais mais relevantes para a decisão clínica em tempo hábil, melhorando a capacidade de resposta e a eficácia de sistemas de monitoramento contínuo de pacientes em ambientes IoT de saúde. Em suma, o trabalho aqui apresentado busca contribuir para o desenvolvimento de soluções de telemonitoramento mais robustas, adaptativas e focadas na relevância clínica dos dados, unindo compressão adaptativa e priorização para suportar a tomada de decisão médica imediata em contextos de IoT aplicada à saúde.

A Figura \ref{fig:micro} traz, de maneira resumida e simples, uma exemplificação do trabalho aqui proposto, onde a coleta de sinais vitais é feita através de dispositivos vestíveis, comprimida e transmitida para um hospital ou ponto de saúde próximo.

\section{Questões de pesquisa}
\label{sec:qp}
Este trabalho busca responder à seguinte questão de pesquisa principal:

\textit{Como aplicar \underline{priorização dinâmica} com base em \underline{escores} de \underline{múltiplos sinais vitais}, de modo a \underline{otimizar} a compressão, a coleta e a transmissão de dados clínicos críticos em um ambiente \underline{Edge–Fog–Cloud} sem prejudicar a qualidade das informações?}

Para fins deste trabalho, entende‑se por \underline{priorização dinâmica} o ajuste contínuo e automático do grau de relevância dos dados, orientado por critérios clínicos avaliados em tempo hábil. O termo \underline{escores} refere-se a indicadores numéricos de gravidade, sendo adotado neste estudo o NEWS2. Os \underline{sinais vitais}, por sua vez, são os principais parâmetros fisiológicos cuja monitorização sustenta a avaliação do estado do paciente. O verbo \underline{otimizar} refere‑se à maximizar a eficiência do uso de recursos de comunicação, armazenamento e processamento, preservando a utilidade clínica da informação transmitida. Por fim, a expressão \underline{Edge–Fog–Cloud} descreve uma arquitetura computacional em camadas na qual o processamento se distribui desde dispositivos junto ao paciente (Edge), passando por nós intermediários de proximidade (Fog), até centros de dados centralizados (Cloud).

Com o foco em responder a questão principal, foram definidos objetivos que abordam trade-offs de compressão versus fidelidade e o impacto das notificações de prioridade no desempenho do sistema. Essas questões subsidiarão o avanço dos experimentos, a escolha das métricas de avaliação e a validação da solução em cenários de monitoramento remoto de pacientes.

\begin{enumerate}
    \item Como testar mais de um sinal vital a estrutura já existente?
    \item Como receber notificações das camadas \textit{Fog/Cloud} e adaptar a compressão na camada de \textit{Edge}?
    \item Qual o impacto das camadas de compressão na qualidade dos dados?
    \item Qual o impacto, na camada de borda, do recebimento de notificações de prioridade (callbacks) geradas pela camada \textit{Fog/Cloud} sobre o uso de recursos computacionais e a gestão da coleta de sinais vitais?
\end{enumerate}

\section{Objetivos}

Este estudo apresenta o ViSPAC, um modelo concebido para consolidar, comprimir e transmitir múltiplos sinais vitais em arquiteturas \textit{Edge–Fog–Cloud} enquanto ajusta, em tempo hábil, o grau de compressão e a frequência de coleta segundo a criticidade clínica de cada paciente. O ViSPAC integra o escore NEWS2 nas camadas \textit{fog‑cloud} para classificar dinamicamente o risco e emitir notificações que parametrizam a camada edge, permitindo que dados de pacientes críticos sejam amostrados com maior resolução e compressão mais branda, ao passo que leituras estáveis recebam tratamento econômico.

Diante disso, o objetivo principal desta pesquisa é:

\textit{O objetivo geral deste trabalho é validar um mecanismo dinâmico de priorização, fundamentado no NEWS2, que reduza substancialmente o volume de dados transmitidos e o consumo de recursos, mantendo a utilidade clínica dos sinais vitais em um ambiente Edge–Fog–Cloud.}

A fim de alcançar o objetivo principal desta pesquisa, os seguintes objetivos específicos foram definidos:

\begin{enumerate}
    \item \textbf{Agilidade na decisão clínica:} permitir que o sistema envie alertas rapidamente sempre que o escore NEWS2 indicar risco, assegurando tempo hábil para que a equipe de saúde intervenha;

    \item \textbf{Redução de Sobrecarga de Rede:} empregar compressão adaptativa para priorizar a eficiência na transmissão de sinais vitais, resultando em menor ocupação da largura de banda e redução da latência total de comunicação;
    
    \item \textbf{Fidelidade e integridade dos dados:} preservar a qualidade dos sinais comprimidos de modo que possam ser reconstruídos sem perda de informação clínica relevante, garantindo confiança no diagnóstico;
\end{enumerate}

\section{Estrutura do texto}

O restante desta dissertação está organizado da seguinte forma: o \textbf{Capítulo~2} apresenta a \textit{Fundamentação Teórica}, descrevendo os princípios de monitoramento remoto de sinais vitais, a explicação e o entendimento do modelo VSAC e sua compressão de dados e os de priorização de dados que embasam o ViSPAC.  
Em seguida, o \textbf{Capítulo~3} discute os \textit{Trabalhos Relacionados}, oferecendo uma visão crítica da literatura recente e identificando lacunas que motivam a extensão do modelo VSAC, trazendo o estado da arte atual. O \textbf{Capítulo~4} é dedicado ao \textit{Modelo ViSPAC}, detalhando a arquitetura, os algoritmos de compressão \textit{lossy/lossless} empregados e o mecanismo dinâmico de priorização baseado no escore NEWS2. O \textbf{Capítulo~5} descreve a \textit{Metodologia e Experimento}, apresentando o design experimental, os materiais e dados utilizados, o ambiente de avaliação na AWS e as métricas adotadas. O \textbf{Capítulo~6} apresenta os \textit{Resultados e Discussão}, com a análise comparativa entre os cenários testados e as respostas às questões de pesquisa. Por fim, o \textbf{Capítulo~7} encerra com a \textit{Conclusão}, sintetizando as contribuições e indicando direções para trabalhos futuros.


%=======================================================================
% Fundamentação teórica
%=======================================================================
\chapter{Fundamentação teórica}

O objetivo deste capítulo é apresentar os fundamentos teóricos que embasam o desenvolvimento deste trabalho, sendo organizado em quatro seções principais. Inicialmente, na Seção \ref{sec:monit}, serão discutidos os aspectos relacionados ao monitoramento remoto de sinais vitais, enfatizando os processos de aquisição dos dados, a correlação com a IoT e as principais características dos diferentes tipos de sinais que serão considerados. Em seguida, a Seção \ref{sec:vsac} dedica-se à análise da arquitetura e do funcionamento do VSAC, modelo base que será utilizado nesse trabalho. A Seção \ref{sec:priorizacao} tratará de priorização, explorando abordagens para determinar a importância relativa dos dados, visando otimizar a utilização de recursos e a tomada de decisão clínica. Por fim, a Seção \ref{sec:mhd} contextualizará sobre o projeto Minha História Digital, ao qual esse projeto faz parte.

\section{Monitoramento remoto de sinais vitais}
\label{sec:monit}

A evolução da IoT tem impulsionado consideravelmente o desenvolvimento de sistemas de monitoramento de saúde remota, possibilitando a aquisição contínua de sinais vitais sem comprometer a rotina dos pacientes.  Essa tecnologia tem promovido uma transição do modelo tradicional, centrado em diagnósticos reativos, para uma abordagem preditiva e proativa no cuidado com a saúde \cite{PARIHAR2024}. Dispositivos eletrônicos compactos e vestíveis, conectados ao corpo, são capazes de monitorar parâmetros fisiológicos essenciais, como temperatura corporal, FC, pressão arterial, frequência respiratória, saturação de oxigênio e pulso \cite{SAHU2022}. A base desses sistemas costuma ser composta por arquiteturas do tipo Wireless Body Area Network (WBAN), que viabilizam a captação e o envio de dados biométricos por meio de protocolos específicos, como o IEEE 802.15.6, desenvolvido para oferecer comunicação segura e de baixo consumo energético em contextos voltados à área médica \cite{KWAK2010}. Os dados coletados são geralmente encaminhados por dispositivos como smartphones ou unidades de processamento embarcadas, que atuam como gateways inteligentes, responsáveis por agregar, processar e enviar informações em tempo hábil para camadas de \textit{fog} ou \textit{cloud}, promovendo um acompanhamento contínuo e a geração de alertas preventivos com base em modelos preditivos de saúde \cite{LI2024}.

Com essa infraestrutura conectada, o monitoramento dos sinais vitais torna-se o alicerce da vigilância clínica, pois descreve em tempo hábil o estado do paciente e permite reconhecer precocemente urgências ou algum problema de saúde. Quatro parâmetros são cruciais: FC, temperatura corporal, saturação periférica de oxigênio (\textit{SpO\textsubscript{2}}) e frequência respiratória (FR). Para cada um, é importante conhecer os intervalos de referência, entender os fatores que afetam suas variações, como idade e comorbidades, e escolher o método de medição mais adequado, seja em dispositivos vestíveis ou sensores dedicados. Cada métrica possui limites inferiores e superiores que devem ser ajustados ao perfil do indivíduo, motivando algoritmos adaptativos de alerta e priorização de dados.

\begin{enumerate}
  \item \textbf{Frequência cardíaca:} Em adultos em repouso, a FC oscila entre 60 e 100 batimentos por minuto (bpm) \cite{AHA2024}. Atletas bem condicionados podem exibir bradicardias fisiológicas próximas de 40 bpm, ao passo que taquicardias sustentadas acima de 100 bpm suscitam investigação clínica. A medição contínua é viabilizada sobretudo por fotopletismografia (PPG) em relógios ou pulseiras, cuja análise reporta erro absoluto médio abaixo de $\pm 3\,\%$ em condições controladas e de $\pm 10\,\%$ em ambientes livres.\cite{KIM2023}. Para análise de arritmias, o eletrocardiograma (ECG) permanece como sendo o padrão.

  \item \textbf{Temperatura corporal:} Análise com 7.636 participantes redefiniu a faixa oral normal para 35,7–37,4 \textdegree, registrando queda média de 0,23 \textdegree em indivíduos com 60 anos ou mais \cite{Geneva2019}. Em geral, valores superiores a 37,3 \textdegree já são interpretados como febre, sugerindo que o organismo está respondendo a um processo infeccioso ou inflamatório \cite{Zhang2021}. Normalmente, essa medida é obtida por meio de termômetros convencionais aplicados nos de maneira axilar, oral ou retal \cite{Kanegaye2016}. Recentemente surgiram dispositivos que também monitoram a temperatura da pele, um parâmetro que varia para manter o equilíbrio térmico interno, ampliando as possibilidades de acompanhamento contínuo.

  \item \textbf{Saturação periférica de oxigênio (\textit{SpO\textsubscript{2}}):} A saturação periférica de oxigênio (\textit{SpO\textsubscript{2}}) expressa a proporção de hemoglobina periférica que se encontra ligada ao oxigênio. Em quadros infecciosos, a liberação de citocinas inflamatórias pode prejudicar a difusão gasosa nos alvéolos, fazendo esse percentual cair \cite{Meleveedu2020}. Leituras inferiores a 95 \% constituem um alerta precoce de  possível dispneia. Em pessoas saudáveis, o valor costuma permanecer quase inalterado durante as atividades diárias. A medição rotineira da \textit{SpO\textsubscript{2}} baseia-se na fotopletismografia: pares de emissores de luz vermelha e infravermelha posicionados em extremidades (dedos ou lóbulos da orelha) detectam variações de absorção ótica que permitem calcular o índice \cite{KumarV2021}.

  \item \textbf{Frequência respiratória (FR):} Esse parâmetro vital corresponde ao número de incursões respiratórias realizadas a cada minuto, conhecido em inglês como \textit{breaths per minute} (BRPM). Estudos descrevem como faixa de normalidade valores entre 12 e 20 BRPM \cite{Touw2017}. Taxas inferiores a esse intervalo podem sinalizar comprometimento pulmonar, pois quando uma doença ataca os pulmões é notória a dificuldade de respirar bem e regular. A FR ganhou destaque na pandemia de COVID-19 devido à alta incidência de sequelas pulmonares. Métodos contemporâneos incluem cintas torácicas, microfones de contato e acelerômetros combinados a PPG. \cite{Vitazkova2024}.
\end{enumerate}

Em síntese, FC, temperatura corporal, \textit{SpO\textsubscript{2}} e FR formam o núcleo mínimo de vigilância fisiológica. A confiabilidade de sistemas de priorização de dados em saúde conectada depende tanto da robustez dos sensores quanto da adaptação das faixas de referência às características individuais do paciente.

\section{Vital Sign Adaptive Compressor}
\label{sec:vsac}

O atual trabalho terá em sua base e continuará o desenvolvimento do VSAC (Vital Sign Adaptive Compressor), que é um modelo de compressão de dados desenvolvido para ambientes de IoT aplicados ao monitoramento de sinais vitais em cidades inteligentes. O VSAC opera em uma arquitetura em camadas (\textit{Edge–Fog–Cloud}) e combina métodos de compressão lossy e lossless para maximizar a retenção de informação clínica relevante ao mesmo tempo em que minimiza o volume de dados transmitidos.

\subsection{Arquitetura do VSAC}

O VSAC adota uma topologia em três níveis (\textit{Edge–Fog–Cloud}), mas mantém toda a lógica de processamento no dispositivo de borda. As camadas superiores atuam como encaminhadoras e tomadoras de decisão baseadas no NEWS2, além de armazenarem o histórico clínico dos pacientes e proverem dashboards de visualização para a equipe médica \cite{Andrade2025}. A Figura \ref{fig:vsac.png} ilustra a arquitetura completa e o fluxo de dados do modelo.

\begin{figure}[ht]
\caption{Arquitetura e funcionamento do VSAC}
\label{fig:vsac.png}
\centering
\includegraphics[width=0.6\textwidth]{imagens/vsac-modules.pdf}
\fonte{Adaptado da arquitetura do VSAC de Alexandre Luis de Andrade}
\end{figure}

No Estágio 1 – Compressão adaptativa, o módulo Compressão com perdas realiza, em tempo hábil, a compressão com perdas dos sinais vitais brutos. Em seguida, o Integrador agrega esses dados comprimidos ao identificador de origem correspondente, garantindo que cada fluxo de sinais permaneça rastreável. Já o módulo Empacotador, por sua vez, recebe os pacotes vindos da etapa anterior e decide o que será feito: para pacotes de alta prioridade, o envio ao sistema de monitoramento ocorre imediatamente; para os demais, o módulo concatena múltiplas amostras e acrescenta metadados. Depois, o Formatador de arquivo serializa os dados em JSON, produzindo um formato padronizado para a compressão sem perdas subsequente \cite{Andrade2025}.

O Estágio 2 – Compressão de saída começa com o Decisão de Algoritmo, que seleciona Huffman ou LZW de acordo com o tamanho do arquivo. O Compressão de Saída aplica o algoritmo escolhido, gerando o pacote final, que é então encaminhado pelo Enviador rumo às camadas \textit{fog} e \textit{cloud}. No \textit{fog} ocorre o primeiro processamento clínico, enquanto a \textit{cloud} armazena o histórico completo e disponibiliza visualizações em dashboards \cite{Andrade2025}.

Em resumo, o VSAC estabelece um fluxo em que compressão adaptativa, agregação inteligente e seleção dinâmica de algoritmos trabalham de forma coesa para reduzir drasticamente o volume de dados transmitido, mantendo, contudo, a integridade das informações essenciais à decisão clínica. Distribuir as funções entre processamento intensivo na borda, priorização na \textit{fog} ou \textit{cloud} e armazenamento histórico na nuvem melhora a eficiência da rede e a segurança do paciente. Isso garante respostas rápidas a eventos críticos sem sobrecarregar a infraestrutura de comunicação.

\subsection{Compressão de dados no VSAC}

A compressão implementada pelo modelo VSAC baseia-se em duas fases principais encadeadas, explorando inicialmente uma abordagem \textit{lossy}, seguida por uma abordagem \textit{lossless}. A combinação dessas duas técnicas visa reduzir substancialmente o volume de dados transmitidos, assegurando que informações essenciais sejam preservadas para análise clínica, auditoria e armazenamento \cite{Andrade2025}. 

Os algoritmos que aplicam compressões do tipo \textit{lossy} descartam componentes do sinal consideradas redundantes ou perceptualmente menos relevantes, obtendo taxas de redução elevadas ao custo de uma distorção limitada. O conteúdo reconstruído difere do original, mas permanece dentro de um erro máximo aceitável para a aplicação \cite{Salomon2007}. Já algoritmos que aplicam técnicas de compressões \textit{lossless}  codificam o fluxo de dados sem perda de informação. Após a descompressão obtém‑se exatamente os mesmos bits de entrada. Exemplos clássicos incluem Codificação de Huffman e Lempel–Ziv–Welch (LZW) \cite{Salomon2007}. A Figura \ref{fig:lossless} demonstra a diferença entre ambos algoritmos de compressão. 

\begin{figure}[ht]
\caption{Existem dois métodos principais de compressão: Lossless e Lossy. O método Lossy geralmente alcança uma taxa de compressão mais elevada, porém os dados recuperados após a descompressão não são idênticos aos do arquivo original.}
\label{fig:lossless}
\centering
\includegraphics[width=\textwidth]{imagens/LossyLossless.pdf}
\fonte{Elaborado pelo autor}
\end{figure}

Na primeira fase (\textit{lossy}), o modelo VSAC utiliza o algoritmo denominado \textit{Swinging Door Trending} (SDT), originalmente proposto para compressão de dados em sistemas SCADA industriais e adaptado para sinais biomédicos \cite{Bristol1990}. O SDT caracteriza-se por descartar informações redundantes ou com variações mínimas, consideradas pouco relevantes do ponto de vista clínico, enquanto preserva picos e vales que representam eventos clinicamente significativos.

O funcionamento do SDT baseia-se no conceito de uma porta giratória imaginária, ilustrado na Figura \ref{fig:sdt_explained}. O algoritmo opera da seguinte forma:
\begin{enumerate}
    \item \textbf{Ponto Âncora:} O primeiro ponto da série é sempre registrado e serve como referência inicial.
    \item \textbf{Tolerância (DC):} A partir do ponto âncora, duas retas de tolerância são projetadas, uma superior e uma inferior, definindo um corredor dentro do qual novos pontos são considerados redundantes. O parâmetro $DC$ (\textit{Compression Deviation}) define a largura dessa tolerância.
    \item \textbf{Descarte de Pontos:} Enquanto os novos pontos permanecerem dentro do corredor de tolerância, eles são descartados (representados como círculos vazios na figura).
    \item \textbf{Registro e Novo Âncora:} Quando um ponto viola o limite superior ou inferior, ele é registrado como ponto significativo e torna-se o novo ponto âncora, reiniciando o processo.
    \item \textbf{Tempo Máximo ($T_{SDT}$):} Adicionalmente, se nenhum ponto for registrado após um intervalo máximo de tempo, o último ponto disponível é forçadamente registrado para evitar gaps prolongados na série.
\end{enumerate}

\begin{figure}[!ht]
\caption{Funcionamento do algoritmo SDT. O ponto âncora projeta limites de tolerância (DC). Pontos dentro da tolerância são descartados; pontos que excedem o limite são registrados e se tornam o novo âncora.}
\label{fig:sdt_explained}
\centering
\includegraphics[width=0.7\textwidth]{imagens/sdt_explained.png}
\fonte{Elaborado pelo autor}
\end{figure}

Para exemplificar, considere uma série de FC com valores [72, 73, 71, 74, 72, 85, 86] bpm e $DC = 5$ bpm. O ponto 72 é o âncora inicial. Os pontos 73, 71, 74 e 72 permanecem dentro da tolerância ($72 \pm 5$) e são descartados. O ponto 85 viola o limite superior e é registrado, tornando-se o novo âncora. O resultado comprimido seria [72, 85, 86], reduzindo 7 pontos para 3 (compressão de 57\%).

Especificamente, os dados vitais brutos recebidos de sensores são processados pelo módulo Compressão Adaptativa. Inicialmente, um componente extrai e separa sinais vitais individuais, que então são comprimidos pelo SDT de acordo com parâmetros estabelecidos dinamicamente pelo módulo Configurador. Posteriormente, esses dados comprimidos são reintegrados em pacotes estruturados, contendo identificadores e metadados que descrevem as condições de coleta e prioridade.

Na segunda fase (\textit{lossless}), o modelo VSAC aplica técnicas que garantem a reversibilidade completa dos dados após a descompressão. Os pacotes comprimidos na etapa anterior são agrupados pelo módulo Empacotador, formatados como arquivos JSON pelo Formatador, e então submetidos ao módulo Compressão de Saída. Neste módulo, o algoritmo aplicado depende do tamanho dos arquivos. Pacotes menores ou prioritários (até 33 kB) são processados usando a codificação de Huffman, mais eficiente para arquivos pequenos e com menor overhead computacional. Arquivos maiores seguem para a compressão Lempel–Ziv–Welch (LZW), que demonstra melhor desempenho para grandes volumes de dados, oferecendo taxas de compressão superiores \cite{Andrade2025}.

Essas etapas sequenciais garantem uma redução significativa do volume total de dados transmitidos pela rede, contribuindo diretamente para menor latência de comunicação, menor uso de largura de banda e uma redução dos requisitos de armazenamento na infraestrutura \textit{fog/cloud}. Além disso, devido ao processamento ocorrer inteiramente na camada \textit{edge}, os dados já chegam otimizados às camadas superiores, reduzindo a sobrecarga computacional e a necessidade de grandes capacidades de processamento em níveis mais altos da arquitetura.

Em resumo, os resultados experimentais apontam que essa abordagem híbrida (SDT + Huffman/LZW) apresenta desempenho superior às estratégias isoladas. O modelo VSAC obteve taxas de compressão até 42\% superiores às obtidas com algoritmos exclusivamente \emph{lossless} e até 46\% superiores às alcançadas por algoritmos \emph{lossy} utilizados isoladamente. Dessa forma, evidencia-se a eficácia do modelo VSAC em otimizar a transmissão de sinais vitais mantendo a qualidade necessária às análises clínicas \cite{Andrade2025}.

\section{Priorização}
\label{sec:priorizacao}

Em ambientes de IoT para saúde, nem todos os dados coletados possuem a mesma criticidade clínica. O grande volume de informações fisiológicas transmitidas continuamente por múltiplos sensores impõe a necessidade de priorização de dados, de modo a assegurar que informações potencialmente críticas (indicativas de deterioração do paciente) sejam transmitidas e processadas com rapidez, enquanto dados menos relevantes ou redundantes possam ser comprimidos, filtrados ou enviados com menor frequência. Essa priorização busca equilibrar dois objetivos: resposta clínica oportuna (detecção imediata de sinais de alerta) e uso eficiente de recursos de comunicação e hardware (evitando congestionamento de rede e sobrecarga de dados irrelevantes).

Uma abordagem comum para direcionar a priorização e a coleta e transmissão dos sinais vitais é o uso de escores clínicos de alerta precoce. Um escore amplamente conhecido para avaliação rápida do status do paciente é o National Early Warning Score 2 (NEWS2). O NEWS2 foi desenvolvido pelo Royal College of Physicians (RCP) no Reino Unido como uma forma padronizada de registrar e pontuar variáveis fisiológicas de pacientes, facilitando a identificação precoce do agravamento do estado de saúde e a resposta oportuna das equipes médicas \cite{NHSEngland2025}. Essa relevância do NEWS2 pode ser compreendida a partir de alguns pontos detalhados abaixo:

\begin{enumerate}
\item \textbf{Implementação ampla e melhora na saúde pública}. O NEWS2 conta com a aprovação do \textit{NHS England} e encontra-se implementado em 100\% dos serviços de ambulância e 76\% dos serviços de emergência britânicos, com estimativa oficial de prevenção de cerca de 1.800 óbitos anuais graças à padronização do reconhecimento precoce de agravamento do estado clínico \cite{NHSEngland2025}.

\item \textbf{Desempenho prognóstico robusto}. Análise de 30 estudos publicada em 2023, que envolveu 185.835 pacientes, mostrou que o escore NEWS2 teve ampla capacidade de prever mortalidade nas próximas 48 horas. Os resultados apontaram uma área sob a curva (AUC) de 0,88, com sensibilidade e especificidade de 0,81, tornando o NEWS2 um dos escores mais confiáveis em ambientes de emergência \cite{Wei2023}.  

\item \textbf{Viabilidade de automação no ecossistema IoT}. Estudo piloto realizado em 2024 mostrou que um dispositivo vestível, que usa sensores ópticos (fotopletismografia), conseguiu calcular automaticamente o escore NEWS2 com resultados muito semelhantes aos obtidos por profissionais de saúde (K = 0,76). O estudo não registrou eventos adversos e teve boa aceitação entre os pacientes, o que reforça o potencial de utilizar essa tecnologia em tempo hábil em camadas como \textit{edge} e \textit{fog} \cite{Reichl2024}.

\item \textbf{Evolução e melhoria contínua}. Scoping review publicada em 2025 identificou 11 variantes do NEWS2 que aumentam a acurácia prognóstica ao incorporar idade, tendência temporal dos sinais vitais ou fração inspirada de oxigênio, evidenciando uma comunidade ativa de pesquisa e garantindo que futuras melhorias possam ser adotadas sem substituir a base já consolidada \cite{Riccalton2025}.  
\end{enumerate}

O NEWS2 baseia-se na avaliação de sinais vitais fundamentais: frequência respiratória, saturação periférica de oxigênio, temperatura corporal, pressão arterial sistólica, frequência cardíaca e nível de consciência. Além desses sinais, o sistema também considera a necessidade de oxigênio suplementar como um parâmetro adicional, influenciando a pontuação final \cite{RoyalCollege2017}.

\begin{figure}[ht]
	\caption{O sistema de pontuação do NEWS}
	\label{fig:news.png}
	\centering
	\includegraphics[width=\textwidth]{imagens/news.png}
	\fonte{\cite{RoyalCollege2017}}
\end{figure}

Cada parâmetro monitorado pelo NEWS2 é associado a uma escala de pontuação de 0 a 3, refletindo o grau de desvio dos valores normais. A Figura \ref{fig:news.png} apresenta o sistema de pontuação do NEWS2. A soma desses escores resulta em um valor total que expressa o nível de risco do paciente, orientando intervenções clínicas conforme a gravidade observada. Além disso, o NEWS2 contempla a administração de oxigênio suplementar, que acrescenta dois pontos à pontuação total, reconhecendo o impacto significativo da necessidade de suporte respiratório \cite{RoyalCollege2017}.

O sistema também introduz duas escalas distintas para a interpretação da saturação periférica de oxigênio: a Escala 1, aplicada à maioria dos pacientes, e a Escala 2, destinada a indivíduos com condições como Doença Pulmonar Obstrutiva Crônica (DPOC), que apresentam parâmetros fisiológicos específicos. Essa adaptação visa garantir uma avaliação mais precisa e adequada de populações clínicas distintas, ajustando a resposta do sistema conforme a condição de base do paciente \cite{Greenhalghm2020}.

A Tabela \ref{tab:news2_classificacao} apresenta a classificação de risco clínico baseada no escore NEWS2 agregado, juntamente com a frequência mínima de monitoramento e a resposta clínica recomendada conforme as diretrizes do \cite{RoyalCollege2017}.

\begin{table}[!ht]
\centering
\caption{Classificação de risco clínico baseada no escore NEWS2 agregado}
\label{tab:news2_classificacao}
\footnotesize
\begin{tabular}{|c|c|p{3.5cm}|p{4cm}|}
\hline
\textbf{Escore NEWS2} & \textbf{Nível de Risco} & \textbf{Frequência de Monitoramento} & \textbf{Resposta Clínica} \\ \hline
0 & Mínimo & Mínimo a cada 12 horas & Continuar monitoramento de rotina \\ \hline
1--4 & Baixo & A cada 4--6 horas & Informar enfermeiro responsável; avaliar necessidade de aumento de frequência \\ \hline
5--6 & Moderado & No mínimo a cada hora & Revisão urgente por clínico competente; considerar transferência para área de maior cuidado \\ \hline
$\geq$ 7 & Alto & Monitoramento contínuo & Alerta emergencial imediato; avaliação por equipe de resposta rápida; considerar transferência para UTI \\ \hline
\end{tabular}
\fonte{Adaptado de \cite{RoyalCollege2017}.}
\end{table}

Para fins de nomenclatura neste trabalho, adotam-se três estados clínicos derivados das faixas de risco definidas pelo NEWS2 \cite{RoyalCollege2017}: \textit{paciente estável} corresponde aos níveis de risco BAIXO ou MÍNIMO (NEWS2 $\leq$ 4); \textit{paciente em alerta} corresponde ao risco MODERADO (NEWS2 entre 5--6); e \textit{paciente crítico} corresponde ao risco ALTO (NEWS2 $\geq$ 7). Essa nomenclatura simplificada orienta as decisões de compressão e frequência de coleta ao longo de todo o modelo proposto.

No contexto deste trabalho, o modelo proposto utilizará a classificação baseada no escore NEWS2 para orientar a priorização dos dados transmitidos. O cálculo será realizado nas camadas \textit{fog-cloud} que enviarão as classificações de risco para a edge, adaptando dinamicamente a frequência de coleta e o nível de compressão dos sinais vitais. Pacientes com maior risco clínico terão seus dados coletados com maior frequência e sofrerão compressão reduzida, preservando a integridade das informações críticas. Por outro lado, pacientes em condições estáveis terão dados coletados em intervalos mais espaçados e poderão ser submetidos a compressão mais intensiva, otimizando o uso dos recursos de rede e processamento, sem comprometer a segurança do monitoramento.

\section{Projeto MHD}
\label{sec:mhd}

O modelo de gerenciamento de dados de sinais vitais apresentado neste trabalho integra o projeto Minha História Digital (MHD), financiado pela FAPERGS e desenvolvido por meio de uma cooperação científica entre a Unisinos, o Instituto Colaborativo de Blockchain (ICO-LAB) e uma aliança de pesquisa e inovação que reúne hospitais do Rio Grande do Sul.

O MHD busca criar uma solução computacional que integre arquitetura e algoritmos para rastrear e captar, em tempo hábil, os sinais vitais dos moradores da cidade. A iniciativa concentra-se no combate a doenças respiratórias, como a COVID-19, viabilizando a identificação da localização geográfica de cada indivíduo, a coleta pontual de seus sinais vitais e o armazenamento histórico dessas informações. Com isso, torna-se possível mapear a dispersão da doença a partir dos lugares visitados, avaliar a eficácia de medidas de quarentena e monitorar ou mesmo prever possíveis agravamentos nos parâmetros clínicos das pessoas acompanhadas.

Para alcançar o objetivo, o projeto contempla uma arquitetura em camadas que integra dispositivos \textit{IoT}, nós de \textit{Fog Computing} e serviços de \textit{Cloud Computing}, buscando equilibrar latência, escalabilidade e consumo energético em aplicações de monitoramento de saúde. Essa solução tem como foco três objetivos fundamentais: (i) propor uma solução que abranja dispositivos vestíveis (pulseiras e \textit{wearables}), leitores posicionados em locais estratégicos da cidade e sensores instalados em ambientes hospitalares; (ii) ajustar dinamicamente a quantidade de servidores e serviços nas camadas \textit{fog} e \textit{cloud} de acordo com a demanda computacional e o número de usuários, garantindo economia de energia e manutenção da qualidade de serviço (\textit{QoS}); e (iii) definir, conforme a sensibilidade à latência, quais serviços e algoritmos precisam residir na \textit{fog} e quais podem ser executados na \textit{cloud}.

A Figura \ref{fig:mhd-arq} ilustra a arquitetura do projeto MHD, organizada nas camadas \textit{Edge–Fog–Cloud}. Na \textit{edge}, indivíduos usam sensores de saúde disponíveis comercialmente para registrar sinais vitais ao longo das atividades diárias. Nós na camada de \textit{fog}, distribuídos geograficamente, compõem uma infraestrutura próxima da fonte de captura, assumindo o processamento inicial dos dados. A \textit{cloud} funciona como plataforma central que agrega informações de toda a implantação e, apoiada por uma infraestrutura robusta, executa análises aprofundadas. Essa distribuição concede aos administradores de saúde uma visão abrangente de diferentes regiões e possibilita a detecção precoce de zonas de risco e possíveis surtos de doenças.

\begin{figure}[ht]
	\caption{Visão da arquitetura da solução resultante da integração entre Internet das Coisas, Fog Computing e Cloud Computing.}
	\label{fig:mhd-arq}
	\centering
	\includegraphics[width=\textwidth]{imagens/mhd-arq.png}
	\fonte{Adaptado do projeto Minha História Digital, de autoria de Rodrigo da Rosa Righi e Alexandre Luis de Andrade}
\end{figure}

No contexto do projeto MHD, o modelo proposto neste trabalho está situado na camada \textit{edge}, onde executa a compressão adaptativa dos fluxos de sinais vitais de acordo com o escore clínico de cada paciente. Após a compactação, os dados são encaminhados às camadas \textit{fog} e \textit{cloud}, onde um serviço de avaliação recalcula continuamente esses escores com base no NEWS2 e, quando necessário, encaminha notificações de volta à \textit{edge}. Esse ciclo de retroalimentação ajusta dinamicamente a frequência de coleta e os parâmetros de compressão, permitindo que pacientes em estado crítico sejam monitorados em maior resolução temporal enquanto se preserva largura de banda para casos estáveis, mantendo o equilíbrio entre eficiência operacional e relevância clínica.


%=======================================================================
% Trabalhos Relacionados
%=======================================================================
\chapter{Trabalhos relacionados}

Este capítulo tem como objetivo apresentar trabalhos relacionados com o modelo proposto. Com base no tema da pesquisa e nas questões apresentadas na Seção \ref{intro}, foram analisados alguns trabalhos que seguem uma linha de pesquisa similar. Dessa forma, as próximas Seções descrevem como esses trabalhos foram selecionados e o estado-da-arte atual, descrevendo algumas abordagens a respeito de técnicas de compressão, transmissão e priorização de informações. Os artigos estão classificados em ordem crescente por ano de publicação e após por ordem alfabética dos nomes dos autores. Por fim, os trabalhos serão comparados e analisados para identificar oportunidades na área.

\section{Metodologia de seleção}

Esta seção descreve a metodologia de pesquisa adotada, os procedimentos utilizados e os trabalhos selecionados.  Destacando as decisões tomadas por meio de uma revisão sistemática para fornecer uma visão geral das estratégias de compressão e priorização de dados para sinais vitais em sistemas de monitoramento de saúde. A abordagem apresentada identifica tecnologias, problemas e métodos utilizados neste campo. Além disso, a revisão inclui a identificação de estudos primários, a aplicação de critérios de inclusão e exclusão e a síntese dos resultados obtidos, buscando fornecer uma compreensão abrangente a cerca do tema explorado. O método de pesquisa foi utilizado por meio dos seguintes procedimentos, com base na revisão de \cite{Robben2017}:

\begin{itemize}
    \item Estratégia de busca: Descreve as bibliotecas exploradas e a estratégia de coleta de dados.
    \item Seleção de artigos: Define como os artigos foram selecionados, apresentando os critérios de exclusão e as etapas para filtrar e selecionar os estudos.
    \item Software e ferramentas: Descreve as ferramentas e softwares utilizados para apoiar a pesquisa.
\end{itemize}


\subsection{Estratégia de busca}
\label{sec:strat}

Estudos foram selecionados de fontes de dados apropriadas para responder às questões de pesquisa, aumentando a probabilidade de encontrar informações pertinentes sobre compressão e priorização de dados na coleta de sinais vitais. A busca abrangeu as seguintes bases de dados eletrônicas:

\begin{itemize}
    \item ACM Digital Library (\url{https://dl.acm.org/})
    \item IEEE Xplore (\url{https://ieeexplore.ieee.org/})
    \item Elsevier ScienceDirect (\url{https://www.sciencedirect.com/})
    \item Springer Link (\url{https://link.springer.com/})
\end{itemize}

Além disso, palavras-chave específicas foram definidas para criar uma sequência de busca, estruturada em unidades de busca e combinadas usando operadores booleanos. Essa sequência foi aplicada às bases de dados mencionadas, garantindo uma busca abrangente e detalhada.

\begin{center}
	\texttt{(IoT \textbf{OR} sensors)} \\
	\texttt{\textbf{AND}} \\
	\texttt{(data compression \textbf{OR} compression)} \\
	\texttt{\textbf{AND}} \\
	\texttt{(prioritization \textbf{OR} prioritisation)} \\
	\texttt{\textbf{AND}} \\
	\texttt{monitoring} \\
	\texttt{\textbf{AND}} \\
	\texttt{(healthcare \textbf{OR} vital signs)} \\
\end{center}

A sequência de busca abrange quatro grupos principais: IoT, compressão, priorização, monitoramento e saúde. Esses grupos são combinados usando o operador AND para garantir que os artigos selecionados abranjam todos esses tópicos. O primeiro grupo inclui termos relacionados a IoT. O segundo grupo concentra-se em palavras-chave associadas à compressão de dados. O terceiro grupo concentra-se em palavras-chave para priorização. Já o quarto grupo refere-se a monitoramento e, por fim, o quinto grupo refere-se a área da saúde. Essa estrutura de busca permite uma exploração abrangente de estudos relevantes para essas áreas de interesse.

\subsection{Seleção dos artigos}

A sequência de busca foi aplicada às bases de dados apresentadas na Seção \ref{sec:strat} para selecionar os estudos. No total foram encontrados 748 artigos, incluindo todas as bases de dados. A busca se delimitou em artigos no idioma inglês publicados à partir de 2023 até maio de 2025. Essa escolha de período se deu por conta da pesquisa já realizada para a construção do VSAC, que se estendeu até 2023. Além disso, foram empregados critérios de exclusão compostos por três filtros (F1, F2 e F3) usados sequencialmente para selecionar as pesquisas mais relevantes.

\begin{table}[h!]
\caption{Filtros e critérios de inclusão}
\centering
\begin{tabular}{c p{14cm}}
\textbf{ID} & \textbf{Critério} \\ \hline
F1 & Eliminação de duplicadas \\
F2 & Artigos que possuem a string de busca no título, resumo ou palavras-chave \\
F3 & Leitura e análise do texto completo
\end{tabular}
\label{table:filtering_criteria}
\end{table}

Inicialmente, o F1 removeu todos os artigos duplicados. Após isso, o F2 excluiu artigos que não possuiam a string de busca no título, resumo ou palavras-chave. Nesse filtro a busca foi adaptada, podendo o artigo tratar ou de compressão ou de priorização de dados. Por fim, no F3 os artigos foram lidos e analisados de maneira completa para selecionar os trabalhos voltados para compressão, priorização e/ou eficiência na transmissão de sinais vitais. A Figura \ref{fig:resultados} relata melhor os critérios de exclusão e os resultados obtidos. Já a Tabela \ref{tab:trabalhos-relacionados} lista os trabalhos selecionados que serão detalhados na Seção \ref{sec:state-art}.

\begin{figure}[ht]
	\caption{Resultados da busca e filtragem}
	\label{fig:resultados}
	\centering
	\includegraphics[width=\textwidth]{imagens/results.pdf}
	\fonte{Elaborado pelo autor}
\end{figure}

\begin{table}[h!]
\centering
\caption{Trabalhos relacionados}
\label{tab:trabalhos-relacionados}
\begin{tabular}{|c|p{3.5cm}|p{8.5cm}|c|}
\hline
\textbf{ID} & \textbf{Autor} & \textbf{Título} & \textbf{Ano} \\ \hline
TR1 & \cite{ESMAEILI2023} & A lightweight and secure sensing model for body area networks in the Internet of Things in biological warfare applications & 2023 \\ \hline
TR2 & \cite{CASSEL2024} & Towards providing a priority-based vital sign offloading in healthcare with serverless computing and a fog-cloud architecture & 2024 \\ \hline
TR3 & \cite{Chang2024} & Lightweight Lossy/Lossless ECG Compression for Medical IoT Systems & 2024 \\ \hline
TR4 & \cite{Hassan2024} & Compression of electrocardiogram signals using compressive sensing technique based on curvelet transform toward medical applications & 2024 \\ \hline
TR5 & \cite{Vakil2024} & LPRLC: Linear Predictive Run Length Coding to Improve Energy Consumption of WBANs & 2024 \\ \hline
TR6 & \cite{Andrade2025} & Blending lossy and lossless data compression methods to support health data streaming in smart cities & 2025 \\ \hline
TR7 & \cite{MOHAPATRA2025} & IoT-driven remote health monitoring system with sensor fusion enhancing immediate medical assistance in distributed settings & 2025 \\ \hline
TR8 & \cite{TAO2025} & Research on Feistel Encryption Algorithm Based On Wireless Medical Sensor Networks & 2025 \\ \hline
TR9 & \cite{Shankani2025} & F2multisense: a novel approach to fuzzy fusion in multisensor data to improve saving energy in WBSN & 2025 \\ \hline
TR10 & \cite{Zhou2025} & A comprehensive evaluation of multiple video compression algorithms for preserving BVP signal quality & 2025 \\ \hline
\end{tabular}
\fonte{Elaborado pelo autor}
\end{table}

\subsection{Software e ferramentas}

Três aplicativos principais foram utilizados para auxiliar no processo de seleção dos artigos, além de planilhas do Google e arquivos CSV que serviram de suporte durante todo o processo. Primeiramente, para auxiliar na exportação dos resultados obtidos, foi utilizada a ferramenta Mendeley, que permitiu centralizar todos os artigos encontrados por meio da string de busca nas bases de dados. Após isso, os artigos selecionados foram exportados para a ferramenta Rayyan. Essa segunda ferramenta auxiliou na análise dos artigos, permitindo exclusões ou adições. Por fim, a última ferramenta foi um script desenvolvido pelo autor para automatizar a aplicação do filtro F2, buscando informações nos arquivos CSV exportados do Mendeley ou Rayyan. Com os resultados obtidos, os PDFs foram importados para a ferramenta Rayyan para melhor análise e leitura.

\section{Estado-da-arte}
\label{sec:state-art}

A partir do resultado da pesquisa e filtragem dos trabalhos, foi possível obter 10 artigos de grande relevância para o entendimento do estado-da-arte. Tais trabalhos serão apresentados a seguir, destacando suas principais características, resultados e lacunas em aberto.

\subsection{TR1: A lightweight and secure sensing model for body area networks in the Internet of Things in biological warfare applications \cite{ESMAEILI2023}}
O estudo de \cite{ESMAEILI2023} introduz um modelo leve e seguro de aquisição para \textit{Body Area Networks} voltadas a cenários de guerra biológica. A proposta combina detecção comprimida adaptativa, cujo coeficiente de compressão é ajustado em função da esparsidade (entropia) dos dados, com uma etapa simultânea de cifragem baseada em matrizes sub-Gaussianas. Para sincronizar compressão e segurança, a chave criptográfica é derivada dinamicamente dos \textit{inter-pulse intervals} do ritmo cardíaco do soldado, garantindo sigilo de ponta a ponta sem sobrecarga de processamento nos nós sensores. Avaliações em \textit{MATLAB} demonstram economias energéticas de até 7\,\% sobre métodos de referência (\textit{PALWSS}, \textit{PEDTARA}, \textit{DSCB}) e reduções equivalentes na latência de entrega dos pacotes, preservando relação sinal-ruído aceitável após reconstrução. Persistem, contudo, lacunas relevantes para aplicações clínicas amplas. A validação restringe-se a simulações com quatro sensores e a um único cenário de paciente, não abrangendo sinais multivariados nem variações de criticidade clínica; além disso, o modelo supõe forte esparsidade dos sinais, apresentando alta complexidade de reconstrução quando essa premissa não se mantém. Falta ainda demonstração em hardware real, análise de escalabilidade em arquiteturas \textit{Edge–Fog–Cloud} e integração de políticas de priorização baseadas em escores médicos para ajustar parâmetros de coleta em tempo de execução.

\subsection{TR2: Towards providing a priority-based vital sign offloading in healthcare with serverless computing and a fog-cloud architecture \cite{CASSEL2024}}
O trabalho de \cite{CASSEL2024} apresenta o modelo \textit{SmartVSO}, uma arquitetura hierárquica \textit{fog–cloud} que emprega computação \textit{serverless} e uma fila na \textit{cloud} para escalonar o processamento de sinais vitais. O sistema calcula um \textit{ranking} a partir da prioridade do usuário (estado clínico) e da prioridade do serviço (criticidade do algoritmo) e, com base nesse valor, decide se o sinal será executado localmente ou \textit{offloaded}. Essa estratégia busca reduzir o tempo de resposta para pacientes em condições críticas, ao mesmo tempo em que preserva recursos nos nós de borda e garante escalabilidade em picos de carga, processando até 80000 sinais vitais em experimentos controlados. Persistem, contudo, lacunas relevantes: ausência de compressão dos sinais, o que pode sobrecarregar a rede em cenários de conectividade restrita; uso de limiares fixos de CPU para disparar o \textit{offloading}, sem adaptação dinâmica a métricas como latência, consumo energético ou banda; inexistência de análise de segurança para criptografia e autenticação de dados sensíveis transmitidos entre as camadas \textit{fog} e \textit{cloud}.

\subsection{TR3: Lightweight Lossy/Lossless ECG Compression for Medical IoT Systems \cite{Chang2024}}
O trabalho de \cite{Chang2024} apresenta um compressor híbrido \textit{lossy}/\textit{lossless} leve para sinais de \textit{ECG} em sistemas \textit{IoT} médicos. A solução encadeia um modelo \textit{lossy} baseado em otimização, implementado apenas com adições e multiplicações,a uma etapa \textit{lossless} por \textit{Huffman}, permitindo alcançar taxas de compressões médias superiores a 5{:}1 (CODE) e 4{:}1 (PTB-XL) com erro quadrático médio residual mínimo. Ao usar os sinais descompactados, o classificador realiza uma média de apenas 0,8 diagnósticos incorretos adicionais de um total de 402 casos, em comparação ao uso dos sinais originais não compactados, indicando preservação de informação diagnóstica mesmo após compressão agressiva. Tais resultados evidenciam potencial para reduzir custo de armazenamento local e tráfego de dados em monitoramento cardíaco contínuo em \textit{edge} e \textit{fog}. Persistem, contudo, algumas lacunas: o método restringe-se ao \textit{ECG}, sem avaliar compressão multivariada de sinais vitais; inexiste mecanismo de priorização clínica que ajuste parâmetros de amostragem ou compressão conforme a criticidade do paciente; aspectos de segurança, latência de rede e consumo energético em arquiteturas \textit{Edge–Fog–Cloud} não são mensurados em ambiente real, limitando a extrapolação para cenários de telemonitoramento escalável.

\subsection{TR4: Compression of electrocardiogram signals using compressive sensing technique based on curvelet transform toward medical applications \cite{Hassan2024}}
O trabalho de \cite{Hassan2024} apresenta uma abordagem de \textit{compressive sensing} para sinais de ECG que emprega a \textit{curvelet transform} a fim de gerar representações esparsas e, em seguida, codificação por \textit{run-length} para minimizar o volume de dados transmitidos em \textit{wireless sensor networks}. Avaliado com o repositório MIT-BIH, o método alcançou uma taxa de compressão de 15,7 e diferença média da raiz percentual de 2\%, além de demonstrar redução de 91{,}35\,\% na carga de comunicação quando integrado a nós IoT, indicando impacto direto na eficiência energética e na largura de banda da rede. Entre as lacunas, podem ser citados: a pesquisa restringe-se a um único sinal vital (ECG), não avaliando compressão multivariada nem adaptações dinâmicas orientadas por escores clínicos; ausência de mecanismos de priorização que distingam dados críticos de pacientes em tempo hábil; e dependência de simulações em MATLAB, sem validação em arquiteturas \textit{Edge–Fog–Cloud} reais ou análise de latência, segurança e consumo energético em múltiplas camadas.

\subsection{TR5: LPRLC: Linear Predictive Run Length Coding to Improve Energy Consumption of WBANs \cite{Vakil2024}}
O trabalho de \cite{Vakil2024} apresenta o esquema híbrido \textit{LPRLC} (\textit{Linear Predictive Run Length Coding}) para reduzir consumo energético e tráfego em \textit{WBANs}. A solução combina \textit{Linear Predictive Coding} (fase de predição) com \textit{Run Length Encoding} (fase de compressão do erro residual), executando todo o processamento no nó sensor a fim de evitar custos de transmissão desnecessários. Avaliada em cinco sinais vitais (pressão arterial sistólica/diastólica, respiração, saturação de oxigênio e frequência cardíaca), a abordagem alcançou economia média de 98 \% de energia e razão de compressão de até 70 : 1, superando algoritmos clássicos (\textit{Huffman}, \textit{Arithmetic}, \textit{LZW}) em cenários simulados. Esses resultados evidenciam o potencial de técnicas leves de predição+compressão para prolongar a autonomia dos sensores e mitigar o gargalo de comunicação em sistemas de monitoramento corporal. Persistem, contudo, lacunas: ausência de mecanismos de priorização clínica que ajustem dinamicamente a taxa de amostragem conforme escores de criticidade;falta de validação em arquiteturas \textit{Edge–Fog–Cloud}, sem métricas de latência, segurança ou confiabilidade ponta a ponta; e limitação a cenários simulados, sem testes \textit{hardware–in–the–loop} que considerem interferências reais de rede e múltiplos pacientes.

\subsection{TR6: Blending lossy and lossless data compression methods to support health data streaming in smart cities \cite{Andrade2025}}
O trabalho de \cite{Andrade2025} propõe o modelo VSAC, destinado a otimizar o fluxo contínuo de sinais vitais em cenários de \textit{smart cities}. A solução adota uma arquitetura \textit{Edge–Fog–Cloud} e integra duas fases de compressão — \textit{lossy} (adaptativa via \textit{Swinging Door Tranding}) e \textit{lossless} (Huffman ou LZW) — complementadas por um mecanismo dinâmico de priorização que ajusta parâmetros de amostragem e limiares de erro conforme notificações clínicas. Os autores demonstram reduções de até 46\,\% no volume transmitido em comparação com abordagens de compressão isolada, preservando níveis aceitáveis de distorção para uso em telessaúde. Persistem, entretanto, lacunas relevantes: a validação concentra-se em protótipos de laboratório e em um único sinal vital (\textit{heart rate}), sem explorar a heterogeneidade multivariada comum na prática clínica; métricas de consumo energético e de impacto em rede real (latência, jitter) não são avaliadas; e priorização e apdatação na coleta de dados de pacientes de forma individual.

\subsection{TR7: IoT-driven remote health monitoring system with sensor fusion enhancing immediate medical assistance in distributed settings \cite{MOHAPATRA2025}}
O trabalho de \cite{MOHAPATRA2025} tem por objetivo principal desenvolver e validar um \textit{Internet-of-Things–driven} Health Monitoring System (HMS) que integre sensores vestíveis, fusão de sensores e computação em nuvem para monitorar, em tempo hábil, temperatura corporal, frequência cardíaca, temperatura e umidade ambiente de pacientes em regiões remotas. A arquitetura proposta abrange três camadas ― \textit{device}, \textit{cloud} e \textit{user level} ― conectadas por ZigBee/MQTT, possibilitando detecção de anomalias, emissão de alertas imediatos a profissionais de saúde e geração de relatórios por meio de um \textit{Decision Support System}. A prova de conceito apresenta acurácia de 91,68 \%, demonstrando viabilidade para telemedicina e redução da sobrecarga em unidades de saúde. Apesar dos avanços, permanecem lacunas relevantes: ausência de mecanismos de compressão que minimizem o volume de tráfego; e dependência de calibração manual dos limiares de alarme, o que pode gerar falsos positivos sob variações de contexto.

\subsection{TR8: Research on Feistel Encryption Algorithm Based On Wireless Medical Sensor Networks \cite{TAO2025}}
O estudo de \cite{TAO2025} apresenta um esquema integrado para redes de \textit{Wireless Medical Sensor} capaz de proteger e otimizar o fluxo de sinais vitais. A proposta une um algoritmo de criptografia em bloco inspirado na estrutura \textit{Feistel} e em mapeamento caótico inteiro, recurso que resolve o problema de períodos curtos, aumenta a aleatoriedade da chave e reduz o consumo de energia. Esse algoritmo trabalha junto a um método de compressão baseado em modelos de regressão, que ajusta dinamicamente a taxa de amostragem e os coeficientes do modelo. Complementarmente, o sistema atribui prioridades a cada sinal vital, garantindo que dados de maior criticidade sejam transmitidos em tempo hábil, enquanto os demais são compactados para poupar largura de banda e prolongar a autonomia dos nós. A validação, implementada em \textit{Java} e conduzida com registros de pulso, temperatura e pressão arterial de oito pacientes, demonstra melhora significativa na eficiência energética da rede e na confiabilidade da transmissão. Persistem, contudo, lacunas: a avaliação empírica restringe-se a um conjunto limitado de pacientes e não quantifica a distorção introduzida pela compressão; a priorização baseia-se apenas na importância atribuída aos sinais, sem empregar escores clínicos dinâmicos.

\subsection{TR9: F2multisense: a novel approach to fuzzy fusion in multisensor data to improve saving energy in WBSN \cite{Shankani2025}}
O estudo de \cite{Shankani2025} introduz o \textit{F\textsuperscript{2}multisense}, um esquema bifásico para economizar energia em \textit{Wireless Body Sensor Networks}. Na camada do nó, apenas amostras com escores \textit{NEWS} relevantes são transmitidas; na camada do coordenador, um sistema de inferência difusa ajusta dinamicamente a taxa de amostragem de cinco sinais vitais, alcançando reduções de 40\,\% no tráfego e 64\,\% no consumo energético em simulações com dados do \textit{MIMIC-II}. Tal abordagem demonstra que a priorização orientada por criticidade clínica pode prolongar a vida útil dos sensores sem sacrificar a confiabilidade do monitoramento. Persistem, contudo, lacunas que limitam a generalização do \textit{F\textsuperscript{2}multisense}. O trabalho não incorpora algoritmos de compressão para cenários de banda restrita, nem avalia latência, jitter ou sobrecarga em arquiteturas \textit{Edge–Fog–Cloud} reais. A validação baseia-se em apenas cinco sensores e em simulações MATLAB, sem testes em hardware ou em ambientes heterogêneos; além disso, aspectos de segurança e autenticação dos dados clínicos não são considerados.

\subsection{TR10: A comprehensive evaluation of multiple video compression algorithms for preserving BVP signal quality \cite{Zhou2025}}
O trabalho de \cite{Zhou2025} objetiva quantificar o impacto que diferentes algoritmos de compressão de vídeo exercem sobre a qualidade do sinal de \textit{Blood Volume Pulse} (BVP) captado por \textit{remote photoplethysmography} (rPPG). Para tanto, os autores construíram o conjunto de dados \textit{ZJXU-MOTION}, gravado sem perdas e abrangendo variações de iluminação, intensidade de movimento e modalidades de câmera (\textit{RGB}/infravermelho). Sobre esse acervo, comprimiram‐se os vídeos com seis codecs predominantes (H.264, H.265, AV1/VP9, MJPEG, ProRes e FFV1) e quatro modos de \textit{bit-rate control} (CRF, CQP, VBR e All-I), avaliando‐se a correlação de Pearson entre BVP previsto (POS e PhysNet) e referência, bem como \textit{Similarity Index} (SSIM) e o \textit{Peak Signal-to-Noise Ratio} (PSNR). O estudo conclui que codificação H.265 preserva melhor o BVP em cenas estáticas, enquanto FFV1 se destaca sob movimentos intensos. Persistem, contudo, lacunas significativas: (i) a investigação limita-se a cenários laboratoriais de curta duração, sem considerar degradações adicionais de rede ou processamento em \textit{Edge–Fog–Cloud}; não se avalia a influência de políticas dinâmicas que ajustem parâmetros de compressão em tempo hábil face a mudanças de criticidade clínica; e o enfoque exclusivo em BVP deixa em aberto a generalização para sinais multivariados (SpO\textsubscript{2}, pressão arterial, variabilidade cardíaca).

\section{Análise e Oportunidades}

A Tabela \ref{tab:sintese-estado-arte} evidencia que, dos dez trabalhos analisados, sete (70 \%) recorrem a algum tipo de \textit{compressão}, em geral híbrida, mesclando abordagens com e sem perdas (\cite{Zhou2025,Andrade2025,Hassan2024,Vakil2024,Chang2024,TAO2025,ESMAEILI2023}).

Já a coluna Priorização mostra que apenas cinco estudos oferecem algum mecanismo para diferenciar a importância dos sinais: dois baseiam-se em escores clínicos dinâmicos (fuzzy-NEWS em \cite{Shankani2025} e ranking usuário + serviço em \cite{CASSEL2024}); dois utilizam regras de limiar fixo ou pesos de importância (\cite{MOHAPATRA2025,TAO2025}); e um adota níveis de prioridade pré-definidos, podendo ser alterados automaticamente mas não implementado e testado, (\cite{Andrade2025}).

Quanto ao Ajuste em tempo hábil, ou seja, capacidade de alterar taxa de amostragem, profundidade de compressão ou decisão de offload durante a execução, metade da amostra (5/10) apresenta alguma forma de adaptação: variação de esparsidade do sinal (\cite{ESMAEILI2023}), ajustes de CD/Tm (\cite{Andrade2025}), tempo de amostragem sensível ao risco (\cite{Shankani2025,TAO2025}) ou heurística CPU + ranking em arquitetura \textit{fog–cloud} (\cite{CASSEL2024}).

Contudo, nenhum estudo combina, de maneira integrada, compressão multissinal adaptativa e priorização clínica em ciclo fechado. Com base na análise, as principais lacunas identificadas são:

\begin{itemize}
\item inexistência de um mecanismo de \textbf{compressão adaptativa multivariada} que permita configurar limiares de erro individuais por sinal e por paciente;
\item ausência de \textbf{priorização fundamentada em escores clínicos padronizados} (p.,ex.\ NEWS2) executada na \textit{fog–cloud} para ajustar, em tempo hábil, a relevância dos sinais vitais;
\item falta de um \textbf{ciclo fechado de ajustes} que sincronize taxa de amostragem, fator de compressão e política de transmissão à medida que o estado clínico do paciente evolui.
\end{itemize}

Essas lacunas justificam a proposta do ViSPAC, cujo objetivo é justamente integrar compressão adaptativa multissinal, priorização dinâmica baseada em escores clínicos e um circuito fechado de notificações dentro de um ecossistema \textit{Edge–Fog–Cloud}, maximizando eficiência de banda e energia sem perder oportunidade clínica.

\begin{table}[ht]
\centering
\caption{Síntese dos trabalhos relacionados}
\label{tab:sintese-estado-arte}
\begin{tabular}{|p{3cm}|p{4cm}|p{4cm}|p{4cm}|}
\hline
\textbf{TR} & \textbf{Compressão} & \textbf{Priorização} & \textbf{Ajustes na coleta} \\ \hline
\cite{ESMAEILI2023} & Com perdas              & —   & Variação esparsidade \\ \hline
\cite{CASSEL2024}   & —   & Ranking usuário + serviço & CPU + ranking \\ \hline
\cite{Chang2024}    & Com perdas + Sem perdas & —  & —  \\ \hline
\cite{Hassan2024}   & Com perdas + Sem perdas & —  & —  \\ \hline
\cite{Vakil2024}    & Com perdas + Sem perdas & —  & —  \\ \hline
\cite{Andrade2025}  & Com perdas + Sem perdas & Nível prioridade & CD/Tm dinâmico \\ \hline
\cite{MOHAPATRA2025}& —                       & Limiares de sinais vitais & —  \\ \hline
\cite{TAO2025}      & Com perdas              & Importância dos sinais & Tempo amostragem \\ \hline
\cite{Shankani2025} & —                       & NEWS (fuzzy) & Risco NEWS contínuo \\ \hline
\cite{Zhou2025}     & Com perdas + Sem perdas & —   & —  \\ \hline
\end{tabular}
\fonte{Elaborado pelo autor}
\end{table}

%=======================================================================
% Modelo
%=======================================================================
\chapter{Modelo ViSPAC}
A análise dos trabalhos relacionados mostra duas lacunas principais: (i) ausência de mecanismos de priorização dinâmica, baseados em escores clínicos, para ajuste rápido da compressão e da frequência de coleta; e (ii) uso restrito de compressão híbrida (lossy + lossless) para apenas um parâmetro, o que limita seu uso em cenários com múltiplos sinais. Este estudo propõe o modelo ViSPAC, que consolida FC e $SpO_2$ e integra o escore NEWS2 nas camadas fog–cloud para classificar riscos e acionar notificações que reconfiguram a camada edge. O ciclo adaptativo aumenta a resolução e reduz a compressão de dados críticos, enquanto dados menos urgentes são compactados, otimizando a banda e os recursos computacionais sem perder acurácia.

\section{Caso de uso}
Esta seção apresenta um caso prático do ViSPAC, demonstrando seu potencial efetivo. A arquitetura adaptativa do ViSPAC equilibra a otimização de recursos e a disponibilização de informações clínicas oportunas à equipe de saúde. Considere uma residência inteligente com quatro moradores: mãe, pai, filho adolescente e avó com doença respiratória crônica. Todos usam dispositivos vestíveis para monitorar a frequência cardíaca, a saturação de oxigênio (\textit{SpO\textsubscript{2}}), a frequência respiratória, a temperatura corporal e a pressão arterial. Os dados são transmitidos por um dispositivo local ao hospital municipal responsável. No começo, todos têm sinais vitais normais, conforme o escore NEWS2. A Figura~\ref{fig:usecase} apresenta o fluxo deste caso de uso.

Enquanto os sinais vitais dos moradores permanecem estáveis, o ViSPAC envia relatórios menos frequentes, economizando bateria e largura de banda. Se houver queda na $SpO_2$ ou aumento da frequência respiratória, o sistema detecta e aumenta a transmissão de dados. Assim, os profissionais de saúde acompanham a evolução clínica e podem decidir entre o envio de ambulância e a orientação médica.

A avó, por ser de maior risco, é monitorada continuamente sem comprometer o desempenho da rede. O ViSPAC prioriza informações clínicas relevantes e aplica compressão aos dados menos importantes. Isso mantém vários sensores ativos sem saturar a internet. O exemplo mostra como o modelo adapta sua operação ao estado clínico de cada pessoa, reduzindo o tráfego quando possível e acelerando em situações de risco, resultando em respostas direcionadas e mantendo a eficiência e a escalabilidade.

\begin{figure}[ht]
\caption{Caso de uso do modelo: Uma família tem seus sinais vitais monitorados e enviados ao hospital, que calcula o NEWS2 e, se necessário, retorna ajustes de parâmetros. Em casos extremos, a observação dos dados pode permitir ao hospital enviar uma ambulância para tratar de um caso urgente, por exemplo.
O modelo funciona assim: 1) sinais vitais são coletados e analisados em casa e enviados ao hospital; 2) o hospital analisa os dados e calcula o escore NEWS2; 3) o escore NEWS2 é enviado de volta para ajustar as coletas; 4) em emergência, o hospital pode enviar uma ambulância ou orientar o paciente a ir ao pronto-socorro. Esse ciclo de coleta e envio exige compressão para reduzir o tamanho dos pacotes transmitidos.}
\label{fig:usecase}
\centering
\includegraphics[width=\textwidth]{imagens/history-hospital-ambulance.pdf}
\fonte{Elaborado pelo autor}
\end{figure}

\section{Decisões de projeto}
\label{sec:decisoes}
Conforme destacado na Seção~\ref{sec:mhd}, este trabalho integra o projeto MHD, propondo um método de compressão adaptativa de sinais vitais com priorização, desenvolvido na camada \textit{Edge}. O modelo ViSPAC foi concebido para atender a necessidades clínicas e técnicas identificadas durante a revisão da literatura e em iniciativas anteriores, como o modelo VSAC, do qual herda diretrizes fundamentais para a compressão e o envio eficientes de dados clínicos.

Uma decisão fundamental foi escolher dois sinais vitais, FC e $SpO_2$, para o monitoramento contínuo. A FC já havia sido validada no projeto VSAC \cite{Andrade2025}. A $SpO_2$ foi escolhida por sua importância clínica em síndromes respiratórios agudos e em deteriorações rápidas da oxigenação. Trabalhos recentes dão suporte a essa escolha: \cite{Vakil2024} validaram compressão em cinco sinais vitais, incluindo FC e $SpO_2$. Já \cite{Shankani2025} mostraram que esses parâmetros são determinantes no cálculo de escores de alerta precoce, como o NEWS. Ambos são usados no cálculo do escore NEWS2. Isso permite avaliar rapidamente o estado clínico do paciente e, com base nisso, ajustar parâmetros como o nível de compressão e o intervalo de coleta/transmissão. Os demais sinais do NEWS2 foram ajustados com os valores padrão de um paciente saudável (Tabela \ref{tab:news2_defaults}). Assim, é possível isolar o comportamento do modelo frente às variações de FC e de $SpO_2$, sem o ruído de outros parâmetros.

\begin{table}[!ht]
\centering
\caption{Valores padrão assumidos para sinais vitais não monitorados no cálculo do NEWS2}
\label{tab:news2_defaults}
\footnotesize
\begin{tabular}{|l|c|c|p{5cm}|}
\hline
\textbf{Parâmetro} & \textbf{Valor Padrão} & \textbf{Pontuação NEWS2} & \textbf{Justificativa} \\ \hline
Frequência Respiratória & 16 rpm & 0 & Valor central da faixa normal (12--20 rpm) \\ \hline
Temperatura & 36,5 °C & 0 & Valor central da faixa normal (36,1--38,0 °C) \\ \hline
Pressão Arterial Sistólica & 120 mmHg & 0 & Valor normotensivo típico \\ \hline
Nível de Consciência & Alerta (A) & 0 & Paciente orientado e responsivo \\ \hline
Oxigênio Suplementar & Não & 0 & Paciente em ar ambiente \\ \hline
\end{tabular}
\fonte{Valores derivados das faixas normais do protocolo NEWS2 \cite{RoyalCollege2017}.}
\end{table}

O gerenciamento da coleta de dados utiliza um mecanismo dinâmico. O intervalo de aquisição (tempo entre coletas) varia conforme a gravidade clínica do paciente. Essa estratégia conta com respaldo em \cite{Shankani2025}, cujo método F\textsuperscript{2}multisense mostrou que ajustar a amostragem aos escores de criticidade reduz em 40\% o tráfego e em 64\% o consumo de energia. Assim, priorizam-se transmissões frequentes em casos de alto risco, assegurando vigilância contínua. Ao mesmo tempo, pacientes estáveis recebem um back-off exponencial (aumento progressivo do intervalo de coleta), o que reduz o uso de recursos de rede e de energia, sem prejudicar a detecção de eventos adversos.

O ViSPAC adota uma arquitetura em três camadas (\textit{Edge-Fog-Cloud}), conforme ilustrado na Figura \ref{fig:vispac-modules-macro}. Essa escolha de arquitetura é respaldada pela literatura: \cite{CASSEL2024} demonstraram que arquiteturas \textit{fog-cloud} com escalonamento baseado em prioridade reduzem significativamente o tempo de resposta para pacientes críticos, enquanto \cite{MOHAPATRA2025} validaram a viabilidade de sistemas de monitoramento remoto em três camadas (\textit{device-cloud-user}). Cada camada do ViSPAC possui papéis específicos para criar um sistema responsivo e eficiente:

\begin{itemize}
\item Camada Edge: É onde a inteligência principal do ViSPAC opera. A coleta de sinais vitais por meio de sensores alimenta o módulo de compressão adaptativa. Os dados são então processados pelo Empacotador e Formatador e, se necessário, passam pela Compressão de Saída antes de serem enviados à camada superior.
\item Camada Fog: Recebe os dados via MQTT e calcula imediatamente o NEWS2, devolvendo o \textit{feedback} ao \textit{Edge} antes de qualquer comunicação com a nuvem. Os dados processados são então organizados em filas de prioridade por nível de risco (HIGH $>$ MODERATE $>$ LOW $>$ MINIMAL) e encaminhados de forma assíncrona à \textit{Cloud} por um \textit{worker} dedicado. Esse desacoplamento garante que a latência percebida pelo \textit{Edge} não depende da disponibilidade ou do tempo de resposta da nuvem.
\item Camada Cloud: É responsável pelo armazenamento de longo prazo e pelas análises históricas. Embora o cálculo imediato ocorra na \textit{Fog}, a nuvem mantém a capacidade de gerar notificações secundárias para a reconfiguração da \textit{Edge} e realizar auditoria dos dados.
\end{itemize}

A escolha pelo protocolo MQTT fundamenta-se não apenas na sua arquitetura \textit{publish-subscribe} (padrão de mensageria que desacopla publicadores de assinantes por meio de um intermediário), mas principalmente na redução drástica do \textit{overhead} de cabeçalho. Diferentemente do HTTP, que exige cabeçalhos verbosos baseados em texto em cada requisição, o MQTT possui um cabeçalho fixo, binário, de apenas 2 bytes \cite{mqtt_spec}, o que reduz drasticamente o consumo de banda. Essa escolha é corroborada por \cite{MOHAPATRA2025}, que utilizaram MQTT/ZigBee para conectar sensores vestíveis a um sistema de monitoramento remoto, com acurácia de 91,68\%. Além disso, o suporte a níveis de Qualidade de Serviço (QoS) permite ajustar a garantia de entrega conforme a criticidade do dado (e.g., QoS 1 para riscos altos, QoS 0 para monitoramento de rotina), otimizando o consumo de energia na transmissão.

\begin{figure}[!h]
\caption{Arquitetura macro do modelo ViSPAC.}
\label{fig:vispac-modules-macro}
\centering
\includegraphics[width=0.5\textwidth]{imagens/vispacmacro.pdf}
\fonte{Elaborado pelo autor}
\end{figure}

A principal característica diferenciadora desta arquitetura é o ciclo de \textit{feedback} fechado, identificado como uma lacuna na análise dos trabalhos relacionados (Seção~\ref{sec:state-art}). Enquanto \cite{TAO2025} propuseram priorização baseada na importância atribuída aos sinais e \cite{Shankani2025} utilizaram inferência fuzzy para ajustar a taxa de amostragem, nenhum trabalho integra completamente a compressão adaptativa multissinal à priorização clínica em ciclo fechado. No ViSPAC, as notificações da nuvem são recebidas pelo módulo Receptor na \textit{Edge}, que as repassa ao Configurador. Este, por sua vez, ajusta dinamicamente os parâmetros da Compressão Adaptativa e a frequência de coleta, adaptando o comportamento do sistema ao estado clínico atual do paciente. Os módulos destacados em azul na legenda representam as contribuições específicas do ViSPAC para a criação desse ciclo de priorização inteligente.

No que se refere à compressão, a abordagem híbrida combina o melhor de duas técnicas, seguindo uma tendência consolidada na literatura. \cite{Chang2024} demonstraram que a combinação \textit{lossy}+\textit{lossless} para ECG alcança taxas de compressão superiores a 5:1 preservando a capacidade diagnóstica. A compressão \textit{lossy}, por meio do algoritmo SDT, foi selecionada por sua eficiência computacional ($O(n)$) e por sua adequação morfológica aos sinais monitorados. Sinais como a \textit{SpO\textsubscript{2}} e a FC em repouso apresentam longos períodos de estabilidade (platôs) intercalados por mudanças pontuais; o SDT explora essa característica ao descartar pontos colineares dentro de uma margem de tolerância, preservando os picos e vales essenciais. \cite{Vakil2024} corroboram essa abordagem ao alcançar economia de 98\% na energia com técnicas de predição e compressão leve em WBANs. Por outro lado, a compressão \textit{lossless}, utilizando algoritmos como Huffman ou LZW, é aplicada aos dados já processados para garantir a integridade total em blocos críticos ou em reenvios. Essa combinação permite maximizar o ganho de compressão sem violar os limites de distorção aceitáveis para diagnósticos, seguindo a estratégia já validada no VSAC \cite{Andrade2025}.

Finalmente, presume-se que os indivíduos monitorados estejam utilizando dispositivos vestíveis previamente associados ao sistema\footnote{A integração física dos dispositivos vestíveis (protocolos de pareamento Bluetooth/Wi-Fi, autenticação e provisionamento) está fora do escopo desta dissertação. O modelo assume que a comunicação entre vestível e gateway \textit{edge} já está estabelecida.}, com capacidade de transmissão contínua ou intermitente, conforme orientado pelo ViSPAC. Esses dispositivos devem operar de forma transparente no ambiente de uma cidade inteligente, permitindo o rastreamento contínuo e a emissão de alertas clínicos em tempo hábil.

Em resumo, as seguintes decisões de projeto compõem o modelo ViSPAC:
\begin{itemize}
\item Arquitetura: O modelo opera em uma estrutura de três camadas (\textit{Edge-Fog-Cloud}), utilizando o protocolo MQTT para comunicação leve entre \textit{Edge} e \textit{Fog}. A camada \textit{Edge} é responsável pela coleta e pela compressão adaptativa dos dados. Já a camada \textit{Fog} assume o cálculo do escore de risco (NEWS2) para garantir uma resposta rápida à \textit{Edge}. Por fim, a camada \textit{Cloud} armazena e analisa os dados históricos e também pode gerar notificações para a camada \textit{Edge}. Essa arquitetura encerra um ciclo de controle dinâmico.
\item Sinais e Priorização: O sistema utiliza os sinais de FC e \textit{SpO\textsubscript{2}} para calcular o escore NEWS2, que serve de base para priorizar os dados e ajustar dinamicamente a frequência de coleta e os parâmetros de compressão.
\item Compressão Híbrida: A abordagem combina uma compressão com perdas (\textit{lossy}) com o algoritmo SDT para otimizar a transmissão em períodos de estabilidade e uma compressão sem perdas (\textit{lossless}) com Huffman/LZW para garantir a integridade de dados críticos.
\item Serialização Binária: O ViSPAC adota o formato binário \textit{MessagePack} para serialização dos dados entre \textit{edge} e \textit{fog}, em substituição ao JSON textual utilizado no VSAC. Essa escolha elimina o \textit{overhead} de caracteres de delimitação e de codificação textual de números, além de permitir a operação direta dos algoritmos de compressão \textit{lossless} sobre \textit{bytes}, sem a necessidade de codificação Base64 intermediária.
\item Validação de Hardware: Os testes devem ser executados com limitações de hardware para simular ambientes \textit{edge}.
\item Contexto Operacional: O modelo assume o uso contínuo de dispositivos vestíveis pelos pacientes em um ambiente de cidade inteligente, permitindo o monitoramento contínuo e a geração de alertas em tempo hábil.
\end{itemize}

\section{Arquitetura}
\label{sec:arquitetura}
Conforme apresentado na seção anterior, a arquitetura do ViSPAC adota uma estrutura em três camadas (\textit{Edge}, \textit{Fog} e \textit{Cloud}). Esta seção detalha os módulos internos e suas interações. A decisão de processar o escore NEWS2 na camada intermediária (\textit{Fog}) fundamenta-se no princípio de computação ciente de localidade. Segundo \cite{bonomi2012}, aplicações de IoT sensíveis à latência exigem que a inteligência computacional seja distribuída geograficamente, o que a aproxima da fonte dos dados. Ao realizar o cálculo do NEWS2 na \textit{Fog}, o sistema minimiza o deslocamento de dados por meio da rede, reduzindo drasticamente o tempo de resposta em comparação a uma abordagem puramente baseada em nuvem.

O centro do ViSPAC reside em seis módulos executados na \textit{Edge} e um executado nas camadas de \textit{Fog/Cloud}. Cada um possui responsabilidades bem definidas e interage de forma orquestrada para garantir economia de recursos, sem perder a fidelidade aos dados críticos. Os módulos podem ser visualizados detalhadamente na Figura \ref{fig:vispac-modules}.

O grau de fidelidade e a frequência de monitoramento do ViSPAC são controlados dinamicamente por um conjunto de quatro parâmetros, definidos pelo Algoritmo 1 com base no risco clínico do paciente. Os parâmetros $DC_s$ e $T_{\text{SDT},s}^{\text{base}}$ ajustam a granularidade da compressão \textit{lossy} para cada sinal $s \in \{\text{FC}, \text{SpO}_2\}$, controlando a precisão de forma individual. Esses valores são definidos de modo que $T_{\text{SDT},s}^{\text{base}} = 2 \times IC^{\text{base}}_s$, garantindo a coerência entre o intervalo de coleta e o limiar de tempo do algoritmo SDT. Em paralelo, o $IC$ e a $\varepsilon$ controlam a frequência do ciclo de reavaliação do paciente. Valores reduzidos para estes parâmetros elevam a resolução e o consumo de banda; valores mais altos promovem a economia de recursos à custa da granularidade.

Abaixo, uma explicação de cada módulo do modelo:
\begin{itemize}
\item \textbf{Notificador:} presente tanto na \textit{Fog} (para resposta rápida) quanto na \textit{Cloud}. É responsável por emitir as notificações de reconfiguração para a \textit{Edge} após o cálculo do NEWS2.
\item \textbf{Receptor:} responsável por receber notificações das camadas de \textit{Fog/Cloud}. Atua como ouvinte em uma fila de mensagens, filtrando as prioridades e repassando essas informações ao Configurador.
\item \textbf{Configurador:} converte a prioridade clínica, expressa pelo escore NEWS2, em um conjunto de quatro parâmetros operacionais: $IC$, $\varepsilon$, $DC$ e $T_{\text{SDT}}$. Os valores de $DC$ e $T_{\text{SDT}}$ são direcionados ao módulo de \textit{Compressão Adaptativa}, enquanto $IC$ e $\varepsilon$ são utilizados para governar os algoritmos de controle de frequência (Algoritmos 2 e 3).
\item \textbf{Compressão Adaptativa:} recebendo dinamicamente os parâmetros $DC$ e $T_{\text{SDT}}$ do Configurador, este módulo implementa o algoritmo SDT, realizando compressão \textit{lossy} das séries de FC e de \textit{SpO\textsubscript{2}}. Picos e vales que excedem $DC$ ou que têm intervalos superiores a $T_{\text{SDT}}$ são preservados; pontos redundantes são descartados. O módulo inclui a função de Integrador, que agrega cada amostra ao identificador de origem para manter a rastreabilidade.
\item \textbf{Empacotador:} recebe os pacotes comprimidos do estágio anterior e determina o destino imediato deles. Os pacotes são concatenadas até formar blocos de aproximadamente 1 MB ou até o tempo máximo definido (o que definirá se o pacote é de prioridade alta ou não). Também o módulo organiza os pacotes por risco clínico, agrupando-os em diferentes filas para posterior encaminhamento e envio.
\item \textbf{Formatador:} serializa o bloco produzido pelo Empacotador em formato binário \textit{MessagePack}, acrescentando campos de verificação de integridade e a versão do protocolo. Diferentemente do JSON textual empregado no VSAC, essa representação binária compacta reduz o tamanho do \textit{payload} antes mesmo da compressão sem perdas e prepara o arquivo para o estágio seguinte.
\item \textbf{Compressão de Saída:} aplica compressão \textit{lossless}. Arquivos com tamanho até 33 kB usam o algoritmo de Huffman, reduzindo a latência de processamento; arquivos maiores utilizam o algoritmo LZW, obtendo taxas de compactação superiores. O resultado final é encaminhado para transmissão à \textit{Fog} via MQTT pelo Enviador, onde novos cálculos do NEWS2 poderão originar notificações de retroalimentação, gerando, assim, um \textit{loop} entre monitoramento e classificação.
\end{itemize}

\begin{figure}[ht]
\caption{Módulos do ViSPAC em micro. Na camada de Edge estão presentes os módulos de Compressão Adaptativa, compostos pela compressão com perdas e pelo Integrador; Empacotador e Formatador; Compressão de Saída, responsável por aplicar a compressão sem perdas e realizar o envio; Receptor, responsável por receber as notificações; e o Configurador, responsável por ajustar os parâmetros da compressão com perdas. Na camada de \textit{Fog}, residem o cálculo primário do NEWS2 e o gerenciamento de filas, enquanto a \textit{Cloud} armazena o histórico, ambos podendo enviar notificações pelo Notificador para a camada de Edge, continuando o ciclo fechado.}
\label{fig:vispac-modules}
\centering
\includegraphics[width=\textwidth]{imagens/vispac-modules.pdf}
\fonte{Elaborado pelo autor}
\end{figure}

A Figura \ref{fig:comparacao_modulos} compara os módulos do ViSPAC com os do VSAC. A principal diferença é que o ViSPAC implementa um ciclo completo de notificações da \textit{fog-cloud}, ajustando dinamicamente a coleta, a compressão e a prioridade dos sinais vitais. Os módulos comunicam-se por interfaces definidas, formando um pipeline em que as decisões de prioridade controlam a granularidade dos dados transmitidos, economizando banda sem comprometer os dados clínicos nas camadas superiores.

\clearpage  % força quebra de página antes
\begin{figure}[p]
\centering
\caption{Comparação entre os módulos dos modelos ViSPAC e VSAC. Na primeira imagem podem-se observar os módulos adicionados ao ViSPAC em razão do VSAC (em azul). São eles: Notificador, Receptor, Configurador, Formatador e alterações na Compressão de Saída e na Compressão Adaptativa, para que comportem o novo modelo. Além disso, o ViSPAC propõe o uso de mais de um sinal vital e implanta ajustes automáticos no módulo Configurador. Ao receber uma notificação do Sistema de monitoração de saúde, o sistema adapta os parâmetros da Compressão Adaptativa aos novos valores, conforme definido na Seção \ref{func}.}
\begin{subfigure}[b]{\textwidth}
\centering
\includegraphics[width=.40\textwidth]{imagens/vispac.pdf}
\caption{Módulos do ViSPAC}
\label{fig:modulos_vispac}
\end{subfigure}
\vspace{0.5cm}

\begin{subfigure}[b]{\textwidth}
    \centering
    \includegraphics[width=.40\textwidth]{imagens/vsac-modules.pdf}
    \caption{Módulos do VSAC}
    \label{fig:modulos_vsac}
\end{subfigure}

\label{fig:comparacao_modulos}
\fonte{Figuras adaptadas de Andrade (2025) \cite{Andrade2025}}
\end{figure}
\clearpage

\section{Funcionamento}
\label{func}
Esta seção apresenta e detalha os três algoritmos centrais do modelo. Inicialmente, o sistema avalia o risco clínico do paciente com o escore NEWS2, que define a intensidade do monitoramento por meio do Algoritmo \ref{alg1}. Para pacientes estáveis, o Algoritmo \ref{alg2} é ativado para otimizar recursos, aumentando gradualmente o intervalo entre as verificações por meio de um mecanismo de back-off exponencial \cite{Jacobson1988}. Essa abordagem, entretanto, pode acarretar risco em períodos de menor vigilância. Para mitigar essa limitação, o Algoritmo \ref{alg3} implementa vigilância contínua, semelhante a um mecanismo de keep-alive \cite{RFC1122}, que permanece em constante observação. Ao detectar qualquer anomalia, o sistema aciona uma reavaliação completa e restabelece o monitoramento intensivo. Dessa forma, o sistema adapta-se de forma inteligente, ajustando o foco e a intensidade do monitoramento às condições clínicas de cada paciente.

A Figura \ref{fig:algs} ilustra o fluxo operacional e a interação entre os três algoritmos propostos do modelo ViSPAC. O Algoritmo 1 define os parâmetros de monitoramento com base no escore NEWS2. Com essa configuração, o Algoritmo 2 otimiza o sistema, aumentando o intervalo entre as coletas (\textit{back-off}) durante períodos de estabilidade. Em paralelo, o Algoritmo 3 atua como uma vigilância contínua, realizando verificações rápidas e forçando a coleta imediata caso detecte uma variação fora do limite estabelecido nos sinais vitais. Essa dinâmica garante que o sistema seja eficiente em recursos, mas permaneça altamente responsivo a qualquer deterioração clínica.

\begin{figure}[ht!]
\caption{Visão unificada do pipeline do ViSPAC do ponto de vista algoritmico. À coleta inicia, seguindo para a compressão adaptativa e envio para o fog. Quando a notificação chega, o Algoritmo 1 aplica novos parâmetros (se necessário) e o Algoritmo 2 verifica se o paciente está estável. Caso sim, aplica-se o back-off, caso contrário, mantém o tempo base configurado pelo Algoritmo 1. Com isso, o ciclo se repete. Em paralelo, o Algoritmo 3 fica monitorando, realizando coletas leves e comparando a margem de erro, os sinais vitais. Caso detecte uma anomalia, dispara uma coleta forçada e o ciclo se inicia novamente.}
\label{fig:algs}
\centering
\includegraphics[width=1\textwidth]{imagens/glue.pdf}
\fonte{Elaborado pelo autor}
\end{figure}

\subsection{Algoritmo 1 - Configurador por Sinal Vital}
\label{alg1}
O Algoritmo 1: Configurador por Sinal Vital propõe um ajuste dinâmico da configuração de monitoramento de sinais vitais, com foco especial em FC e \textit{SpO\textsubscript{2}}. O propósito é definir um conjunto completo de parâmetros operacionais, adaptados ao risco clínico do paciente, conforme determinado pelo escore NEWS2. Estes parâmetros incluem o intervalo de coleta ($IC_s$), que podemos comparar ao \textit{time-to-live} (TTL) do protocolo DNS, no qual dados estáveis podem permanecer em cache por mais tempo, enquanto mudanças acionam atualizações imediatas \cite{Tanenbaum2010}.
Além desses, incluem-se a margem de erro tolerável ($\varepsilon_s$), o desvio máximo de compressão ($DC_s$) e o intervalo máximo entre amostras ($T_{\text{SDT},s}$), todos definidos individualmente por sinal. Em outras palavras, pacientes de maior risco terão seus sinais monitorados com maior frequência e menor compressão (com maior precisão), enquanto pacientes estáveis poderão ser acompanhados em intervalos maiores, economizando recursos computacionais sem comprometer a segurança e a qualidade das informações.

A literatura clínica demonstra que a frequência de monitorização de sinais vitais deve aumentar conforme o risco de deterioração do paciente. Diretrizes do NEWS2 recomendam monitorização mínima a cada 12 horas para pacientes com escore 0 (risco mínimo), passando para intervalos de 4–6 horas se o NEWS2 for entre 1 e 4 (risco baixo), e aumentando para pelo menos 1 vez por hora em pacientes com NEWS2 de 5 a 6 (risco moderado) ou com qualquer parâmetro individual muito alterado (pontuação 3). Para pacientes críticos (NEWS2 $\ge$ 7), indica-se monitoramento contínuo sempre que possível \cite{RoyalCollege2017}. Esses padrões refletem a necessidade de coletar dados vitais com maior frequência quando a probabilidade de mudanças clínicas relevantes é maior. Com base nessas informações, o algoritmo proposto adota uma abordagem mais conservadora do que as diretrizes padrão. Foram estabelecidos tempos de coleta para cada categoria de risco, correspondentes à metade do intervalo máximo definido pelo NEWS2. Por exemplo, para um paciente com escore 0, em vez de monitoramento a cada 12 horas, a coleta é programada a cada 6 horas. O objetivo desta estratégia é ampliar a janela de detecção de eventos adversos, proporcionando uma camada adicional de segurança ao paciente.

\begin{algorithm}[!ht]
\caption{Configuração Dinâmica de Parâmetros por Sinal Vital}
\label{alg:configuracao_dinamica}
\SetKwInOut{Input}{Entrada}
\SetKwInOut{Output}{Saída}
\Input{Escore NEWS2 do paciente}
\Output{Parâmetros: $IC_{FC}, IC_{SpO2}, \varepsilon_{FC}, \varepsilon_{SpO2}, DC_{FC}, DC_{SpO2}, T_{\text{SDT,FC}}, T_{\text{SDT,SpO2}}, risco$}
\BlankLine
\tcp{Classificação do risco clínico}
\uIf{$NEWS2 \ge 7$}{
$risco \leftarrow$ ALTO
}\uElseIf{$5 \le NEWS2 \le 6$}{
$risco \leftarrow$ MODERADO
}\uElseIf{$1 \le NEWS2 \le 4$}{
$risco \leftarrow$ BAIXO
}\Else{
$risco \leftarrow$ MÍNIMO
}
\BlankLine
\tcp{Parâmetros operacionais e de compressão conforme risco}
\tcp{T\_SDT = 2 * IC para cada sinal}
\Switch{$risco$}{
\Case{ALTO}{
$IC_{FC} \leftarrow 15\,\text{s}$;\quad $\varepsilon_{FC} \leftarrow \pm 2\,\text{bpm}$;\quad $DC_{FC} \leftarrow 2\,\text{bpm}$;\quad $T_{\text{SDT,FC}} \leftarrow 30\,\text{s}$;

$IC_{SpO2} \leftarrow 15\,\text{s}$;\quad $\varepsilon_{SpO2} \leftarrow \pm 1\,\%$;\quad $DC_{SpO2} \leftarrow 1\,\%$;\quad $T_{\text{SDT,SpO2}} \leftarrow 30\,\text{s}$\tcp*{Compressão mínima, alta fidelidade}
}
\Case{MODERADO}{
    $IC_{FC} \leftarrow 2\,\text{min}$;\quad $\varepsilon_{FC} \leftarrow \pm 4\,\text{bpm}$;\quad $DC_{FC} \leftarrow 4\,\text{bpm}$;\quad $T_{\text{SDT,FC}} \leftarrow 4\,\text{min}$;
    
    $IC_{SpO2} \leftarrow 3\,\text{min}$;\quad $\varepsilon_{SpO2} \leftarrow \pm 1\,\%$;\quad $DC_{SpO2} \leftarrow 1\,\%$;\quad $T_{\text{SDT,SpO2}} \leftarrow 6\,\text{min}$;
}
\Case{BAIXO}{
    $IC_{FC} \leftarrow 5\,\text{min}$;\quad $\varepsilon_{FC} \leftarrow \pm 6\,\text{bpm}$;\quad $DC_{FC} \leftarrow 6\,\text{bpm}$;\quad $T_{\text{SDT,FC}} \leftarrow 10\,\text{min}$;
    
    $IC_{SpO2} \leftarrow 10\,\text{min}$;\quad $\varepsilon_{SpO2} \leftarrow \pm 2\,\%$;\quad $DC_{SpO2} \leftarrow 2\,\%$;\quad $T_{\text{SDT,SpO2}} \leftarrow 20\,\text{min}$;
}
\Case{MÍNIMO}{
    $IC_{FC} \leftarrow 10\,\text{min}$;\quad $\varepsilon_{FC} \leftarrow \pm 10\,\text{bpm}$;\quad $DC_{FC} \leftarrow 10\,\text{bpm}$;\quad $T_{\text{SDT,FC}} \leftarrow 20\,\text{min}$;
    
    $IC_{SpO2} \leftarrow 15\,\text{min}$;\quad $\varepsilon_{SpO2} \leftarrow \pm 3\,\%$;\quad $DC_{SpO2} \leftarrow 3\,\%$;\quad $T_{\text{SDT,SpO2}} \leftarrow 30\,\text{min}$\tcp*{Compressão máxima, baixa fidelidade}
}
}
\BlankLine
\Return $\langle IC_{FC}, IC_{SpO2}, \varepsilon_{FC}, \varepsilon_{SpO2}, DC_{FC}, DC_{SpO2}, T_{\text{SDT,FC}}, T_{\text{SDT,SpO2}}, risco \rangle$
\end{algorithm}

A Tabela \ref{tab:derivacao_parametros} resume a lógica dos intervalos de coleta ($IC$) definidos. Conforme detalhado, os valores foram dimensionados para o contexto de monitoramento contínuo, a fim de garantir vigilância em tempo hábil (próximo ao real). Vale ressaltar que \textbf{todos os parâmetros apresentados são configuráveis pelo administrador do sistema}, permitindo a adaptação do modelo a diferentes políticas institucionais ou protocolos clínicos específicos.

\begin{table}[!ht]
\centering
\caption{Parâmetros do Algoritmo 1 e justificativa}
\label{tab:derivacao_parametros}
\footnotesize
\begin{tabular}{|c|c|c|c|p{5cm}|}
\hline
\textbf{Risco} & \textbf{NEWS2} & \textbf{Diretriz NEWS2} & \textbf{$IC$ ViSPAC (FC)} & \textbf{Justificativa} \\ \hline
ALTO & $\ge 7$ & Contínuo & 15 s & Máxima vigilância; aproxima monitoramento contínuo \\ \hline
MODERADO & 5–6 & $\ge$ 1$\times$/hora & 2 min & Vigilância frequente para detecção precoce de deterioração \\ \hline
BAIXO & 1–4 & 4–6 horas & 5 min & Equilíbrio entre economia de recursos e segurança clínica \\ \hline
MÍNIMO & 0 & 12 horas & 10 min & Máxima economia; paciente estável dispensa monitoramento intensivo \\ \hline
\end{tabular}
\fonte{Elaborado pelo autor.}
\end{table}

Uma decisão de projeto importante diz respeito à relação entre $IC_s$ e $T_{\text{SDT},s}$. O parâmetro $T_{\text{SDT}}$ define o intervalo máximo que o algoritmo SDT pode manter sem registrar um ponto, mesmo que o sinal permaneça dentro da tolerância $DC_s$. Para garantir coerência operacional, adotou-se a relação $T_{\text{SDT},s}^{\text{base}} = 2 \times IC^{\text{base}}_s$ para cada sinal. Essa proporção assegura que o SDT force um registro apenas após pelo menos duas coletas consecutivas estáveis, evitando registros redundantes em períodos de baixa variabilidade fisiológica. Além disso, como FC e $SpO_2$ possuem intervalos de coleta distintos (como apresentado no Algoritmo 1), cada sinal recebe seu próprio valor de $T_{\text{SDT}}$, permitindo um ajuste fino na compressão de acordo com as características clínicas de cada parâmetro.

Diferentes sinais podem ter impacto distinto no escore: uma alteração sutil na $SpO_2$ pode elevar consideravelmente o NEWS2 (por exemplo, $SpO_2$ caindo de 96\% para 92\% adiciona 2 pontos), enquanto a FC exige variações mais amplas para alterar a pontuação (FC saindo de 80 para 109 bpm adiciona 1 ponto) \cite{RoyalCollege2017}. Além disso, para medir o \textit{SpO\textsubscript{2}} em relógios e pulseiras, o sensor calcula a média do sinal ao longo de 8–12 s. Isso reduz o ruído, mas também atrasa, por alguns segundos, a exibição de uma queda real na saturação \cite{Desai2015}. A FC, por sua vez, pode ser mostrada batimento a batimento. Assim, aceitar um erro de até 5 bpm na FC quase nunca compromete a análise \cite{REDDY2025}, enquanto um erro de 3–4\% na $SpO_2$ pode esconder o início de um caso clínico mais grave. Com base nessas tolerâncias clínicas, os valores de $\varepsilon$ (margem de erro) apresentados no Algoritmo 1 foram definidos: para FC, as margens variam de $\pm$2 bpm (risco ALTO) a $\pm$10 bpm (risco MÍNIMO); para $SpO_2$, as margens são mais rígidas, variando de $\pm$1\% (riscos ALTO e MODERADO) a $\pm$3\% (risco MÍNIMO). Essa parametrização garante confiabilidade onde ela é mais crítica, enquanto permite maior tolerância em pacientes estáveis.

\subsection{Algoritmo 2 - Back-off Exponencial Condicionado ao Risco}
\label{alg2}
Depois que o Algoritmo 1 define todos os parâmetros operacionais para cada paciente $p$ e para cada sinal $s \in \{\text{FC},\text{SpO}_2\}$, o Algoritmo 2 entra em ação para ajustar dinamicamente o intervalo de coleta. Ele trabalha com as leituras que passam pelo processo de compressão, usando o intervalo-base $IC^{\text{base}}_{s,p}$ e a margem de erro $\varepsilon_s$ para implementar um mecanismo de \textit{back-off} exponencial. Esse conceito foi inspirado em protocolos de rede como Ethernet e TCP \cite{Jacobson1988}.

A escolha por uma estratégia exponencial ($2^n$) em vez de linear justifica-se pela necessidade de reduzir rapidamente o congestionamento da rede e o consumo de bateria quando o paciente está estável por períodos prolongados. A lógica é simples: se a variação do sinal vital permanece dentro do limite $\epsilon$ por $K$ ciclos seguidos, a chance de uma mudança significativa no próximo ciclo diminui, o que permite intervalos maiores entre as coletas.

Porém, diferente dos protocolos de rede (em que o tempo de espera pode dobrar após uma única transmissão bem-sucedida), o Algoritmo 2 adota uma abordagem mais conservadora, apropriada ao contexto clínico. Ele introduz um limiar de estabilidade $K$, que determina quantas leituras consecutivas dentro da margem $\varepsilon_s$ são necessárias antes de aplicar o \textit{back-off}. O valor $K = 3$ foi adotado como padrão, representando um equilíbrio entre responsividade e robustez: um valor menor (ex.: $K = 1$) permitiria \textit{back-off} prematuro baseado em leituras isoladas potencialmente ruidosas, enquanto um valor maior (ex.: $K = 5$) atrasaria excessivamente a economia de recursos em pacientes genuinamente estáveis. Apenas após $K$ medições estáveis, o intervalo é dobrado. Isso funciona como um mecanismo de confiança que evita o relaxamento do monitoramento baseado em apenas algumas leituras isoladas.

Essa estratégia só funciona enquanto o paciente está em risco MODERADO, BAIXO ou MÍNIMO. Se o risco subir para ALTO ou se qualquer leitura ultrapassar $\varepsilon_s$, o algoritmo restaura imediatamente o $IC$ padrão.
Além do ajuste dinâmico do intervalo de coleta ($IC^{\text{curr}}_s$), o Algoritmo 2 também atualiza proporcionalmente o parâmetro $T_{\text{SDT},s}^{\text{curr}}$. Quando o \textit{back-off} aumenta o intervalo de coleta, o $T_{\text{SDT}}$ acompanha essa expansão seguindo a fórmula:

\begin{equation}
T_{\text{SDT},s}^{\text{curr}} = \max(T_{\text{SDT},s}^{\text{base}}, 2 \times IC^{\text{curr}}_s)
\end{equation}

Essa estratégia mantém a coerência do modelo: se o sistema confia que o paciente está estável (aumentado $IC$), ele também relaxa a exigência de registros forçados no SDT. Ambos os parâmetros indicam o mesmo nível de confiança na estabilidade clínica. Nos casos de \textit{reset} (leitura instável ou risco ALTO), tanto $IC$ quanto $T_{\text{SDT}}$ retornam aos valores base definidos pelo Algoritmo 1.

Por exemplo, considere um paciente com risco MÍNIMO monitorando $SpO_2$. Inicialmente, $IC^{\text{curr}}_{SpO_2} = 15$ min e $T_{\text{SDT},SpO_2}^{\text{curr}} = 30$ min. Após três leituras consecutivas estáveis ($K = 3$), o primeiro \textit{back-off} dobra ambos os valores para $IC = 30$ min e $T_{\text{SDT}} = 60$ min. Esse processo continua até atingir o teto de $IC^{\text{max}} = 6$ h, momento em que $T_{\text{SDT}}$ atinge 12 h. Caso ocorra uma variação que exceda $\varepsilon_{SpO_2}$, ambos os parâmetros retornam imediatamente aos valores base (15 min e 30 min, respectivamente).

\begin{algorithm}[!ht]
\setcounter{AlgoLine}{0}
\caption{Back-off Exponencial Condicionado ao Risco}
\label{alg:backoff}
\SetKwInOut{Input}{Entrada}
\SetKwInOut{Output}{Saída}
\Input{Leitura $\langle p, s, v, risco_p\rangle$}
\Output{$IC^{\text{curr}}_{s,p}$, $T_{\text{SDT},s,p}^{\text{curr}}$}
\BlankLine
\tcp{Obtém valores base do Algoritmo 1 para o sinal $s$}
$IC^{\text{base}}_{s} \leftarrow \text{PARAMS}[risco_p][IC_s]$;
$T_{\text{SDT},s}^{\text{base}} \leftarrow \text{PARAMS}[risco_p][T_{\text{SDT},s}]$;
\BlankLine
\tcp{Etapa 0 – Só executa em MODERADO, MÍNIMO ou BAIXO}
\If{$risco_p = \text{ALTO}$}{
$\text{stableCnt}_{s,p} \leftarrow 0$;
$IC^{\text{curr}}_{s,p} \leftarrow IC^{\text{base}}_{s}$;
$T_{\text{SDT},s,p}^{\text{curr}} \leftarrow T_{\text{SDT},s}^{\text{base}}$;
\Return $IC^{\text{curr}}_{s,p}, T_{\text{SDT},s,p}^{\text{curr}}$;
}
\BlankLine
\tcp{Etapa 1 – Verifica estabilidade da leitura}
\If{$|v - v_{\text{últ}}|\le \varepsilon_{s}$}{
$\text{stableCnt}_{s,p}++$;
}\Else{
$\text{stableCnt}_{s,p} \leftarrow 0$;
$IC^{\text{curr}}_{s,p} \leftarrow IC^{\text{base}}_{s}$;
$T_{\text{SDT},s,p}^{\text{curr}} \leftarrow T_{\text{SDT},s}^{\text{base}}$;
\Return $IC^{\text{curr}}_{s,p}, T_{\text{SDT},s,p}^{\text{curr}}$;
}
\BlankLine
\tcp{Etapa 2 – Aplica back-off exponencial após K leituras estáveis}
\If{$\text{stableCnt}_{s,p}\ge K$}{
\uIf{$risco_p = \text{MODERADO}$}{
$IC^{\max} \leftarrow 30\,\text{min}$;
}\uElseIf{$risco_p = \text{BAIXO}$}{
$IC^{\max} \leftarrow 2\,\text{h}$;
}\Else{
$IC^{\max} \leftarrow 6\,\text{h}$;
}
$IC^{\text{curr}}_{s,p} \leftarrow \min(IC^{\max}, 2 \times IC^{\text{curr}}_{s,p})$;
$\text{stableCnt}_{s,p} \leftarrow 0$;
  \BlankLine
  \tcp{Etapa 3 – Ajusta $T_{\text{SDT}}$ proporcionalmente ao $IC^{\text{curr}}$}
  $T_{\text{SDT},s,p}^{\text{curr}} \leftarrow \max(T_{\text{SDT},s}^{\text{base}},\, 2 \times IC^{\text{curr}}_{s,p})$\;
}
\BlankLine
\Return $IC^{\text{curr}}_{s,p}, T_{\text{SDT},s,p}^{\text{curr}}$;
\end{algorithm}

Contudo, essa estratégia de alongar o intervalo introduz um risco latente: um paciente pode sofrer uma deterioração aguda após um longo período de silêncio (ex.: 8 horas), e o sistema só detectaria o problema na próxima coleta agendada. Para mitigar essa vulnerabilidade crítica, propõe-se, no Algoritmo 3, uma vigilância contínua adicional, que funciona como uma verificação de pulso (\textit{keep-alive}), garantindo vigilância mínima contínua sem sacrificar a eficiência energética.

Em resumo, o Algoritmo 2 atua como um elástico que alonga o tempo entre as coletas completas. Enquanto o paciente permanece estável em risco MODERADO, BAIXO ou MÍNIMO, ele dobra o intervalo de coleta, respeitando um teto máximo. Se qualquer leitura ultrapassar $\varepsilon_s$ ou se o escore \textit{NEWS2} subir, o intervalo volta instantaneamente ao valor-base. Essa lógica é supervisionada pelo Algoritmo 3, que garante que, mesmo durante os intervalos mais longos, uma verificação de segurança seja realizada.

\subsection{Algoritmo 3 - Vigilância Contínua}
\label{alg3}
Para mitigar o risco de deterioração não detectada durante os longos intervalos de \textit{back-off}, o Algoritmo 3 implementa vigilância contínua. Ele opera em paralelo, executando uma coleta leve em um intervalo de verificação fixo ($IC_{\text{verif}}$). O valor de $IC_{\text{verif}} = 2$ minutos foi escolhido por corresponder ao intervalo base de risco MODERADO definido no Algoritmo 1; essa escolha garante que, mesmo pacientes em \textit{back-off} máximo (até 6 horas para risco MÍNIMO), seus sinais sejam verificados com frequência equivalente à de um paciente de risco moderado, estabelecendo um piso de segurança clínica. Este método é diretamente análogo ao mecanismo de TCP \textit{keep-alives}, um recurso fundamental de protocolos de rede projetado para verificar a integridade de uma conexão ociosa. Assim como o TCP \textit{keep-alives} envia pacotes de sonda para garantir que a outra extremidade ainda está ativa, a coleta leve atua como uma sonda fisiológica para garantir que o estado do paciente não tenha se alterado silenciosamente \cite{RFC1122}.

\begin{algorithm}[!ht]
\setcounter{AlgoLine}{0}
\caption{Vigilância Contínua}
\SetKwInOut{Input}{Entrada}
\SetKwInOut{Output}{Saída}
\Input{Leitura leve $\langle p, s, v\rangle$ executada a cada $IC_{\text{verif}}$}
\Output{Disparo da \texttt{ColetaCompletaImediata($p, s$)} se a verificação falhar}
\BlankLine
\tcp{Executa em paralelo, independentemente do risco}
\tcp{Compara leitura leve com a última leitura válida}
\If{$|v - v_{\text{últ}}|> \varepsilon_{s}$}{
\BlankLine
\tcp{Variação anômala detectada, disparar ação}
\texttt{ColetaCompletaImediata($p, s$)};
}
\end{algorithm}

Uma coleta leve é uma operação de baixo custo computacional: ela apenas mede o sinal vital e o compara à última leitura válida, sem acionar o fluxo completo de compressão e envio às camadas de \textit{fog-cloud}. Se essa verificação rápida detectar uma variação que exceda a margem de erro $\varepsilon_s$, ela força a interrupção imediata do temporizador de \textit{back-off} do Algoritmo 2, disparando uma coleta completa para uma reavaliação imediata do estado do paciente. Dessa forma, o sistema combina eficiência energética com vigilância contínua, garantindo uma resposta rápida a mudanças clínicas súbitas.

\subsection{Resumo da interdependência dos algoritmos}
Os três algoritmos apresentados formam um sistema de controle integrado, onde cada componente depende e complementa os demais: o \textbf{Algoritmo 1} atua como configurador inicial, traduzindo o escore NEWS2 em parâmetros operacionais ($IC$, $\varepsilon$, $DC$, $T_{\text{SDT}}$); o \textbf{Algoritmo 2} otimiza dinamicamente o intervalo de coleta quando há estabilidade prolongada, respeitando os limites definidos pelo Algoritmo 1; e o \textbf{Algoritmo 3} supervisiona continuamente o paciente, podendo interromper o \textit{back-off} do Algoritmo 2 e forçar uma reavaliação pelo Algoritmo 1 caso detecte deterioração. Essa arquitetura em cascata garante que o sistema seja eficiente em condições estáveis, sem abrir mão da vigilância necessária para detectar eventos críticos.

A Tabela~\ref{tab:parametros_sistema_resumido} resume os parâmetros que regem o comportamento dos algoritmos, distinguindo‐os pela sua natureza (default ou dinâmica) e pela entidade que os define ou atualiza. Essa separação explicita uma arquitetura de controle em duas camadas. A primeira é a camada \textit{Default}, composta por valores imutáveis em tempo de execução que codificam diretrizes clínicas e políticas do sistema. As configurações definidas ou alteradas pelo sistema podem ser modificadas pelo administrador. A segunda é a camada Dinâmica: nela, o Escore NEWS2, calculado em tempo hábil pelo sistema de saúde, é traduzido pelos algoritmos em parâmetros operacionais adaptativos ($IC^{\text{base}}_{s}$, $\varepsilon_{s}$, $DC_{s}$, $T_{\text{SDT}}$) e, posteriormente, refinado pelo mecanismo de \textit{back-off}, que ajusta $IC^{\text{curr}}_{s}$. Todos os pacientes iniciam com os mesmos valores e, após as coletas iniciais, são ajustados. Essas configurações garantem que o sistema permaneça ancorado em premissas robustas e seja responsivo às mudanças no estado clínico do paciente.

\begin{table}[!ht]
\centering
\caption{Parâmetros do ViSPAC: natureza e origem}
\label{tab:parametros_sistema_resumido}
\renewcommand{\arraystretch}{1.2}
\small
\begin{tabular}{|p{3cm}|p{4cm}|c|l|}
\hline
\textbf{Parâmetro} & \textbf{Descrição} & \textbf{Natureza} & \textbf{Definido/alterado por} \\ \hline
Escore NEWS2 & Pontuação clínica aferida periodicamente & Entrada & Sistema automatizado de cálculo \\ \hline
Limites de Risco & Faixas do NEWS2 que definem MÍNIMO–ALTO & Default & Diretriz clínica \\ \hline
Regras de Config.\ (Alg.~1) & Mapeia risco $\rightarrow$ $\{IC,\varepsilon,DC,T_{\text{SDT}}\}$ por sinal & Default & Sistema (pré‐deploy) \\ \hline
$K$ & Leituras estáveis necessárias antes do back-off & Default & Sistema \\ \hline
$IC_{\text{max}}$ & Teto de $IC$ após back-off (por nível de risco) & Default & Sistema (Alg.~2) \\ \hline
$IC_{\text{verif}}$ & Intervalo da vigilância contínua (keep-alive) & Default & Sistema (Alg.~3) \\ \hline
Risco Clínico & Classe de risco derivada do NEWS2 & Dinâmico & Alg.~1 \\ \hline
$IC^{\text{base}}_{s}$ & Intervalo base de coleta por sinal $s$ & Dinâmico & Alg.~1 \\ \hline
$\varepsilon_{s}$ & Margem de erro tolerável por sinal $s$ & Dinâmico & Alg.~1 \\ \hline
$DC_{s}$ & Desvio máx.\ de compressão por sinal $s$ & Dinâmico & Alg.~1 \\ \hline
$T_{\text{SDT},s}^{\text{base}}$ & $T_{\text{SDT}}$ base por sinal $s$ (= $2 \times IC^{\text{base}}_{s}$) & Dinâmico & Alg.~1 \\ \hline
$\text{stableCnt}_{s,p}$ & Contador de leituras estáveis consecutivas & Dinâmico & Alg.~2 \\ \hline
$IC^{\text{curr}}_{s}$ & Intervalo corrente após back-off & Dinâmico & Alg.~2 \\ \hline
$T_{\text{SDT},s}^{\text{curr}}$ & $T_{\text{SDT}}$ corrente (= $\max(T_{\text{SDT},s}^{\text{base}}, 2 \times IC^{\text{curr}}_{s})$) & Dinâmico & Alg.~2 \\ \hline
\end{tabular}
\end{table}


\chapter{Metodologia e experimento}

Esta seção descreve a metodologia para avaliar o modelo ViSPAC. A estratégia experimental visa validar a adaptação dinâmica do sistema diante de variações clínicas do paciente, bem como mensurar a eficiência no uso de recursos da rede e no processamento. A abordagem fundamenta-se em simulação controlada na nuvem, utilizando dados reais de sinais vitais para garantir a relevância dos resultados.

Não foi identificado na literatura um \textit{benchmark} padronizado para avaliação de modelos de compressão adaptativa de sinais vitais em arquiteturas \textit{Edge-Fog-Cloud}. Diante dessa lacuna, a metodologia foi construída utilizando o \textbf{modelo VSAC} \cite{Andrade2025} como \textit{baseline} de comparação (representado pelo Cenário 2: Compressão Estática). Complementarmente, adotaram-se métricas consolidadas na literatura sobre compressão de sinais biomédicos: Taxa de Compressão ($T_C$), Distorção por PRD (\textit{Percentage Root-Mean-Square Difference}) e Latência do ciclo de \textit{feedback} ($T_{\text{loop}}$), conforme detalhado na Seção \ref{sec:metricas}.

\section{Design do Experimento}

O experimento foi estruturado em um fluxo de processamento distribuído em três camadas: \textit{edge}, \textit{fog} e \textit{cloud}, reproduzindo uma infraestrutura de Cidades Inteligentes voltada à saúde. O fluxo operacional do experimento é dividido em quatro estágios principais:

\begin{enumerate}
    \item \textbf{Ingestão e Simulação:} Dados provenientes de \textit{datasets} consolidados são injetados nas unidades \textit{edge}, nas quais cada instância simula um conjunto de pacientes com perfis de risco distintos (alto, moderado, baixo e mínimo).
    \item \textbf{Processamento Adaptativo na Borda:} A camada \textit{edge} realiza a compressão dos dados. Dependendo do risco identificado pelo ciclo de \textit{feedback}, o modelo ajusta os parâmetros de coleta ($IC$, $\varepsilon$) e de compressão ($DC$, $T_{\text{SDT}}$).
    \item \textbf{Análise e Feedback na Fog:} A camada \textit{fog} atua como um nó intermediário responsável pela descompressão, pelo cálculo do escore NEWS2 e pela retransmissão imediata dos novos parâmetros operacionais para a \textit{edge}, fechando o laço de controle.
    \item \textbf{Persistência e Análise Histórica:} Os dados processados são encaminhados para a \textit{cloud} por meio de uma fila por risco, onde são armazenados em um banco de dados para permitir a análise pelos agentes de saúde.
\end{enumerate}

A arquitetura foi projetada para ser testada sob diferentes cargas, variando a composição de pacientes em cada nó de borda, a fim de avaliar o desempenho do modelo em cenários de alta variabilidade clínica.

\section{Materiais e Dados}
\label{sec:dataset}
Para a validação experimental do protótipo, foram utilizados dados reais de sinais vitais, especificamente FC (já utilizado no VSAC) e $SpO_2$. A seleção dos dados buscou representar cenários clínicos opostos, incluindo pacientes críticos e indivíduos saudáveis, permitindo avaliar a resposta do modelo ViSPAC em extremos de variabilidade fisiológica. Os dados foram obtidos a partir de duas fontes públicas distintas:

\begin{enumerate}
    \item \textbf{BIDMC PPG and Respiration Dataset \cite{Pimentel2016, BIDMCDataset}\footnote{\url{https://physionet.org/content/bidmc/1.0.0/}}:} Disponibilizado no PhysioNet, este conjunto contém dados fisiológicos coletados de pacientes internados em Unidades de Terapia Intensiva (UTI) no \textit{Beth Israel Deaconess Medical Center} (Boston, EUA).
    \begin{itemize}
        \item \textbf{Aplicação no Experimento:} Utilizado para simular os perfis de risco \textbf{ALTO} e \textbf{MODERADO}. Foram empregados os registros de 53 pacientes, em que cada série temporal possui mais de 400 amostras contínuas. A natureza instável destes sinais desafia a capacidade do modelo de manter a fidelidade dos dados sob compressão.
    \end{itemize}

    \item \textbf{Biosensor Student Health Fitness Data \cite{BiosensorKaggle2024}:} Disponível na plataforma Kaggle, este conjunto de dados reúne dados biométricos de estudantes universitários saudáveis, caracterizados por alta estabilidade e baixo risco clínico.
    \begin{itemize}
        \item \textbf{Aplicação no Experimento:} Utilizado para simular os perfis de risco \textbf{BAIXO} ou \textbf{MÍNIMO}.
        \item \textbf{Pré-processamento e Agrupamento:} Originalmente, este \textit{dataset} apresenta leituras pontuais (uma única aferição por indivíduo), o que inviabilizaria a simulação de um monitoramento contínuo ao longo do tempo. Para contornar essa limitação metodológica, foi aplicada uma técnica de concatenação de registros: os dados de diferentes estudantes foram agrupados de forma sequencial para sintetizar pacientes virtuais. Logo, os dados dos estudantes foram agrupados em 8 pacientes, gerando de 80 a 90 registros por paciente virtual, o que permitiu o experimento.
    \end{itemize}
\end{enumerate}

Como apenas FC e $SpO2$ foram utilizados nos testes, os demais sinais vitais foram fixados e têm valores padrão. Essa composição heterogênea de dados permitiu testar o algoritmo de adaptação dinâmica diante de padrões de sinais vitais com entropias distintas, validando a generalização do modelo.

\section{Ambiente de Avaliação}
\label{sec:ambiente}

A validação experimental do modelo ViSPAC foi conduzida em um ambiente de nuvem totalmente virtualizado na plataforma da Amazon Web Services (AWS). A concepção da infraestrutura buscou simular um cenário realista de Cidades Inteligentes, em que a distribuição geográfica dos recursos e as limitações de hardware são fatores críticos. Para tanto, adotou-se uma arquitetura multirregião, distribuindo as camadas de processamento entre diferentes centros de dados da AWS para introduzir latências de rede representativas de um ambiente de produção em larga escala.

A Figura \ref{fig:arquitetura_aws_multiregiao} apresenta o diagrama detalhado da topologia de rede implementada, evidenciando a segmentação geográfica, a organização das sub-redes e os fluxos de comunicação entre os componentes.

\begin{figure}[ht]
\centering
\includegraphics[width=1.0\textwidth]{imagens/aws.png}
\caption{Diagrama da topologia da infraestrutura experimental distribuída na AWS. A arquitetura é segmentada em duas regiões geográficas distintas: us-east-1 (Norte da Virgínia), que hospeda as camadas \textit{Edge} e \textit{Fog}, e us-west-1 (Norte da Califórnia), que hospeda a camada \textit{Cloud}. Uma conexão entre duas VPCs, chamada de emparelhamento de VPCs (\textit{VPC Peering}), interliga as redes regionais. Na parte superior, observa-se a \textit{VPC Edge/Fog} contendo a sub-rede \textit{Edge} com 20 dispositivos simulados (ex.: E-01, E-02) e a sub-rede \textit{Fog} com o nó concentrador. O fluxo de dados principal ocorre via MQTT da \textit{Edge} para a \textit{Fog}. Na parte inferior, a \textit{VPC Cloud} contém uma API e um banco de dados PostgreSQL, recebendo dados processados da \textit{Fog} por meio de uma API HTTP via peering.}
\label{fig:arquitetura_aws_multiregiao}
\end{figure}

Para garantir a reprodutibilidade do experimento e a gerência eficiente dos 22 nós computacionais envolvidos, toda a infraestrutura foi definida por meio de código (\textit{Infrastructure as Code} - IaC) com a ferramenta Terraform. Os arquivos de configuração utilizados para provisionar este ambiente encontram-se disponíveis no repositório do projeto\footnote{\url{https://github.com/mateusrovedaa/dissertacao/tree/terraform}}.

Cada dispositivo Edge (identificado por seu EDGE\_ID) foi configurado para monitorar um conjunto fixo e reprodutível de pacientes, selecionados aleatoriamente a partir dos datasets \textit{BIDMC PPG and Respiration Dataset} e \textit{Biosensor Student Health Fitness Data}. A reprodutibilidade é garantida por meio de \textit{seeding} determinístico baseado no EDGE\_ID, permitindo a replicação exata dos experimentos. A variabilidade entre edges reflete cenários realistas de implantação distribuída em múltiplas instalações.

Abaixo são detalhados os componentes de cada região, conforme ilustrado na Figura \ref{fig:arquitetura_aws_multiregiao}:

\subsection{Região us-east-1 (Edge e Fog)}

Esta região concentra os componentes responsáveis pela coleta e pelo processamento inicial dos dados, simulando a infraestrutura local de uma cidade.

\begin{itemize}
    \item \textbf{Camada Edge (Sub-rede Edge):} Composta por 20 instâncias EC2 de categoria base \textit{t2.small} (1 vCPU, 1GB RAM). Um aspecto metodológico fundamental foi a imposição de restrições artificiais de hardware nestas instâncias para simular dispositivos IoT de baixo custo. Por meio de mecanismos do sistema operacional (Cgroups), a memória RAM foi limitada a \textbf{256 MB} e a utilização da CPU foi restringida a \textbf{50\%} da capacidade de um núcleo. Conforme mostrado na figura, estas instâncias foram configuradas com diferentes densidades de pacientes (ex.: nó E-01 simulando 5 pacientes de baixo risco) para criar cargas de trabalho heterogêneas. A comunicação de saída para a camada \textit{Fog} é realizada exclusivamente pelo protocolo MQTT.

    A escolha específica destes limites fundamenta-se na equivalência com dispositivos \textit{Single Board Computer} (SBC) amplamente utilizados, como o \textbf{Raspberry Pi Zero} (que possui 512 MB de SDRAM e um processador quad-core ARM Cortex-A53). Visto que instâncias de nuvem operam com processadores de alto desempenho (arquitetura x86\_64), a redução de 50% na capacidade de processamento visa aproximar o desempenho ao de processadores ARM de baixo consumo típicos de IoT. Da mesma forma, a restrição de memória para 256 MB valida a eficiência do algoritmo ViSPAC em cenários em que o sistema operacional e outros processos de suporte já ocupam parte substancial dos recursos, restando uma fatia reduzida para a aplicação de monitoramento.

    \item \textbf{Camada Fog (Sub-rede Fog):} Composta por uma instância \textit{t3.small} (2 vCPU, 2GB RAM), atuando como \textit{gateway} regional. Este nó executa um \textit{broker} MQTT para receber os dados comprimidos da borda, realiza a descompressão, calcula o escore NEWS2 e retorna os parâmetros de feedback para a borda. Simultaneamente, ele atua como ponte para a nuvem, encaminhando dados processados para a região remota.
\end{itemize}

\subsection{Região us-west-1 (Cloud) e Interconexão}

Esta região simula um datacenter centralizado para armazenamento de longo prazo e análises intensivas.

\begin{itemize}
    \item \textbf{Camada Cloud (Sub-rede Cloud):} Hospeda uma instância \textit{t3.small} (2 vCPU, 2GB RAM) executando um banco de dados PostgreSQL para persistência histórica dos sinais vitais e uma API para recebimento de dados.
    \item \textbf{VPC Peering:} A comunicação entre a camada Fog (us-east-1) e a camada Cloud (us-west-1) é viabilizada por meio de uma conexão de emparelhamento de VPCs (\textit{VPC Peering}). O tráfego flui pelo \textit{backbone} da AWS, mas está sujeito às latências inter-regionais naturais, cruciais para a avaliação realista das métricas de tempo de resposta do sistema.
\end{itemize}

\section{Implementação do Modelo ViSPAC}

O software do sistema foi implementado em Python, estruturado de forma modular para operar de forma distribuída. A lógica de processamento divide-se entre a execução leve na borda (centrada na redução de dados) e a execução analítica na camada de \textit{fog} (centrada na tomada de decisão clínica).

\subsection{Pipeline de Compressão na Borda}

Cada instância de borda executa um ciclo contínuo de coleta e processamento. O fluxo de dados foi desenhado para priorizar a latência em situações críticas e a eficiência de banda em situações estáveis. O processamento ocorre em dois estágios:

\begin{enumerate}
    \item \textbf{Compressão Primária (Lossy):} Todos os sinais vitais brutos (FC e $SpO_2$) são submetidos ao algoritmo \textit{Swinging Door Trending} (SDT). Este algoritmo foi selecionado por sua complexidade computacional linear ($O(n)$), o que o torna ideal para o hardware restrito simulado. A agressividade da compressão é determinada pelo parâmetro $DC$ (Desvio de Compressão), ajustado dinamicamente.
    
    \item \textbf{Compressão Secundária (Lossless):} A saída do SDT pode passar por um segundo estágio de compressão sem perdas (Huffman ou LZW) para maximizar a redução do tamanho do pacote. No entanto, implementou-se uma regra de \textbf{bypass para risco crítico}: caso o paciente esteja classificado em risco ALTO, o estágio secundário é ignorado e os dados são transmitidos imediatamente após o SDT. Esta estratégia visa eliminar o \textit{overhead} computacional da segunda compressão, reduzindo a latência ponta-a-ponta em detrimento de uma pequena economia de banda.
\end{enumerate}

Para a implementação dos algoritmos, foram adaptadas bibliotecas de código aberto disponíveis na comunidade, otimizando-as para o fluxo de dados do experimento:
\begin{itemize}
    \item \textbf{SDT:} Baseado na implementação de \textit{Swinging Door Trending}, disponível em repositório público\footnote{\url{https://github.com/chelaxe/SwingingDoor}}, adaptada para suportar janelas de tempo variáveis ($T_{\text{SDT}}$).
    \item \textbf{LZW e Huffman:} Utilizados como algoritmos de entropia para a compressão secundária, com base nas implementações de Gupta\footnote{\url{https://github.com/adityagupta3006/LZW-Compressor-in-Python}} e Bhrigu\footnote{\url{https://github.com/bhrigu123/huffman-coding}}.
\end{itemize}

\subsection{Serialização Binária}
\label{sec:serializacao}

O ViSPAC adota o formato binário \textit{MessagePack}\footnote{\url{https://msgpack.org/}} para a serialização dos lotes transmitidos da \textit{edge} para a \textit{fog}, em substituição ao JSON textual utilizado no VSAC. A escolha fundamenta-se na avaliação de \cite{Friesel2021}, que demonstrou que o \textit{MessagePack} apresenta desempenho de serialização superior ao JSON em microcontroladores embarcados de 8 a 32 bits, além de tamanho de \textit{payload} significativamente reduzido. O \textit{MessagePack} produz representações equivalentes ao JSON, porém em formato binário compacto: números inteiros e de ponto flutuante são armazenados em sua forma nativa (1--9 bytes), enquanto no JSON cada dígito consome um byte de texto. Além disso, estruturas como mapas e arrays são delimitadas por cabeçalhos de poucos bytes, eliminando os caracteres \texttt{\{\}}, \texttt{[]}, \texttt{:} e \texttt{,} exigidos pela notação textual. Essa representação resulta em uma redução no tamanho do \textit{payload} antes da aplicação dos algoritmos \textit{lossless}, sem custo computacional relevante. Adicionalmente, os algoritmos de Huffman e LZW foram adaptados para operar diretamente sobre sequências de bytes, dispensando a codificação Base64 intermediária necessária quando a entrada era textual.

\subsection{Mecanismo de Adaptação e Feedback (Fog)}

A inteligência do sistema reside na camada \textit{Fog}. Ao receber um lote de dados via MQTT, o nó \textit{fog} realiza a descompressão, reconstrói os sinais vitais e calcula o escore NEWS2. Esse escore atua como gatilho para o ciclo de \textit{feedback}: o módulo Configurador, executado na \textit{edge}, recebe a classificação do NEWS2 e aplica os novos valores conforme o Algoritmo~\ref{alg1}. Uma piora no estado clínico provoca uma reconfiguração imediata para alta fidelidade, enquanto a estabilização permite o relaxamento dos parâmetros para economizar recursos.

O encaminhamento dos dados processados para a \textit{cloud} é configurável em dois modos. No modo \textbf{síncrono}, o fog encaminha os dados à \textit{cloud} via HTTP e aguarda a confirmação antes de responder ao \textit{edge}, de modo que a latência percebida pelo \textit{edge} inclui o tempo de ida e volta até a nuvem. No modo \textbf{assíncrono}, o fog responde ao \textit{edge} imediatamente após o processamento e enfileira os dados para encaminhamento posterior. As filas são organizadas por nível de risco clínico, com um \textit{worker} dedicado que as drena, respeitando a ordenação HIGH $>$ MODERATE $>$ LOW $>$ MINIMAL, garantindo que os dados de pacientes críticos cheguem antes à camada de armazenamento. Nesse modo, o tempo de resposta da nuvem não afeta a responsividade do ciclo de \textit{feedback}.

\section{Métricas de Avaliação}
\label{sec:metricas}

A eficácia do modelo ViSPAC é avaliada sob três perspectivas fundamentais: eficiência de rede, latência e fidelidade clínica. A escolha destas métricas fundamenta-se em uma revisão sistemática dos trabalhos relacionados, conforme resumido na Tabela \ref{tab:verificacao_metricas}, garantindo que a avaliação seja comparável ao estado da arte.

\begin{table}[h!]
\centering
\caption{Métricas de avaliação recorrentes na literatura sobre monitoramento remoto de saúde e compressão de dados.}
\label{tab:verificacao_metricas}
\footnotesize 
\setlength{\tabcolsep}{3pt} 
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Trabalho Relacionado} & \textbf{Taxa de Compressão} & \textbf{Latência / Tempo} & \textbf{Distorção / Qualidade} \\ \hline
Zhou et al. \cite{Zhou2025} & Sim & - & PSNR, RMSE, SSIM \\ \hline
Esmaeili et al. \cite{ESMAEILI2023} & Sim & Sim & - \\ \hline
Andrade et al. \cite{Andrade2025} & Sim & - & PRD \\ \hline
Hassan et al. \cite{Hassan2024} & Sim & - & PSNR, PRD, MSE \\ \hline
Shankani et al. \cite{Shankani2025} & - & Sim & - \\ \hline
Chang et al. \cite{Chang2024} & Sim & - & PRD, MSE \\ \hline
\end{tabular}
\fonte{Elaborado pelo autor.}
\end{table}

Com base nesta análise, definem-se as seguintes métricas para o experimento:

\begin{enumerate}
    \item \textbf{Taxa de Compressão ($T_C$):} Quantifica a redução do volume de dados trafegados na rede. É definida pela razão entre o tamanho do arquivo comprimido final ($S_f$) e o tamanho dos dados brutos originais ($S_i$):
    \[
    T_C = \left( \frac{S_f}{S_i} \right) \times 100\%
    \]
    Quanto menor o valor de $T_C$, maior a eficiência do sistema em economizar largura de banda.

    \item \textbf{Latência do Ciclo de Feedback ($T_{\text{loop}}$):} Métrica crítica para sistemas adaptativos mede o tempo total de resposta do sistema a uma mudança clínica. É calculada pela diferença entre o instante de coleta da amostra na borda ($t_{\text{coleta}}$) e o instante em que os novos parâmetros de configuração, gerados após o processamento na \textit{fog}, são efetivamente aplicados no dispositivo ($t_{\text{ajuste}}$):
    \[
    T_{\text{loop}} = t_{\text{ajuste}} - t_{\text{coleta}}
    \]
    Um $T_{\text{loop}}$ baixo indica alta responsividade, essencial para pacientes em deterioração rápida.

    \item \textbf{Distorção do Sinal ($PRD$):} Avalia a perda de qualidade decorrente da compressão \textit{lossy} (SDT). Utiliza-se a Diferença Percentual da Raiz Quadrada Média (\textit{Percentage Root-Mean-Square Difference}), que compara o sinal original ($X$) com o sinal reconstruído ($Y$) ao longo de $N$ amostras:
    \[
    PRD = \sqrt{\frac{\sum_{i=1}^{N}(X_{i} - Y_{i})^{2}}{\sum_{i=1}^{N}X_{i}^{2}}} \times 100
    \]
    Valores de PRD próximos de zero indicam alta fidelidade. Para os sinais clínicos, busca-se um equilíbrio em que o PRD seja minimizado especificamente nos trechos de anomalia clínica.
\end{enumerate}

\section{Cenários de Teste}
\label{sec:cenarios}
Para isolar os benefícios de cada componente da arquitetura, o experimento foi dividido em três cenários distintos. Cada cenário foi executado por um período contínuo de \textbf{12 horas}.  Esta janela temporal (que é duas vezes o limite definido para que o risco mínimo seja coletado, caso o \textit{back-off} atue) foi selecionada para capturar a variabilidade natural dos sinais vitais e o comportamento do tráfego de rede em diferentes estados de carga. As configurações de cada cenário foram controladas por meio de variáveis de ambiente no Terraform. Todos os cenários utilizaram a arquitetura proposta e o mesmo código, porém com desvios conforme o cenário (como a desativação de módulos de compressão e a priorização).

\subsection{Cenário 1: Linha de Base (Baseline)}
Configurado en Terraform como \texttt{scenario1\_baseline}. Este cenário representa a abordagem tradicional de monitoramento contínuo sem inteligência na borda.
\begin{itemize}
    \item \textbf{Configuração:} Módulos de compressão desativados. Encaminhamento fog–cloud em modo síncrono.
    \item \textbf{Dinâmica:} Os dados são coletados e enviados em sua forma bruta (\textit{raw data}) com intervalo de coleta fixo ($IC = 1$ s). Este valor foi escolhido para simular o pior cenário de consumo de banda, em que cada leitura é transmitida sem qualquer otimização.
    \item \textbf{Objetivo:} Estabelecer o pior caso de consumo de banda e de armazenamento, servindo como referência para o cálculo do ganho de eficiência ($T_C$) e para a validação da distorção zero ($PRD = 0$) dos dados originais.
\end{itemize}

\subsection{Cenário 2: Compressão Estática}
Configurado en Terraform como \texttt{scenario2\_static}. Avalia o ganho obtido puramente pela introdução de algoritmos de compressão, sem sensibilidade ao contexto clínico. Este cenário se equipara ao VSAC.
\begin{itemize}
    \item \textbf{Configuração:} Algoritmos SDT (Lossy) e Huffman/LZW (Lossless) ativados. Encaminhamento fog–cloud em modo síncrono.
    \item \textbf{Dinâmica:} Os parâmetros de compressão ($DC$, $T_{\text{SDT}}$) e de coleta ($IC$) são estáticos e prefixados. Não há ciclo de feedback ativo; o sistema ignora as flutuações do escore NEWS2.
    \item \textbf{Objetivo:} Quantificar a redução de dados que pode ser obtida apenas por meio da compressão. Este cenário permite diferenciar o ganho do algoritmo (matemático) do ganho da estratégia adaptativa (arquitetural).
\end{itemize}

\subsection{Cenário 3: ViSPAC (Adaptativo Completo)}
Configurado no Terraform como \texttt{scenario3\_vispac}. Representa a solução proposta em sua totalidade.
\begin{itemize}
    \item \textbf{Configuração:} Todos os módulos ativados, incluindo o ciclo de feedback \textit{Edge-Fog-Cloud} e o encaminhamento assíncrono com filas de prioridade por risco na camada \textit{fog}.
    \item \textbf{Dinâmica:} O sistema ajusta dinamicamente $IC$, $\varepsilon$, $DC$ e $T_{\text{SDT}}$ em resposta ao cálculo do NEWS2 na camada \textit{fog}. Pacientes em estado crítico acionam o modo de alta fidelidade (menor compressão, transmissão imediata), enquanto pacientes estáveis operam em modo de alta eficiência. O \textit{fog} responde ao \textit{edge} imediatamente após o processamento, sem aguardar a confirmação da \textit{cloud}, reduzindo a latência do ciclo de \textit{feedback}.
    \item \textbf{Objetivo:} Demonstrar a capacidade do ViSPAC de gerenciar o \textit{trade-off} entre latência e eficiência. Espera-se que este cenário apresente uma $T_C$ competitiva em relação ao Cenário 2, porém com uma $PRD$ substancialmente menor nos momentos críticos e uma latência ($T_{\text{loop}}$) otimizada para eventos de risco.
\end{itemize}

%=======================================================================
% Resultados
%=======================================================================

%=======================================================================
% Resultados e discussão
%=======================================================================

\chapter{Resultados e discussão}
Este capítulo apresenta a avaliação experimental da arquitetura \textit{Edge-Fog-Cloud} proposta. O objetivo central é validar a eficácia do modelo ViSPAC na otimização do monitoramento remoto de sinais vitais, quantificando ganhos de eficiência de rede, de armazenamento e de manutenção da QoS e da fidelidade clínica. A discussão subsequente analisa as dinâmicas dos algoritmos de compressão adaptativa e de priorização baseada em risco, respondendo às questões de pesquisa levantadas no início deste trabalho. Em suma, a Figura \ref{fig:resumo} apresenta um resumo dos testes executados e dos que serão debatidos nas próximas seções.

\begin{figure}[!htbp]
\centering
\includegraphics[width=1.0\textwidth]{imagens/resumo.png}
\caption{Resumo comparativo das execuções realizadas nos 3 cenários de testes. Cada coluna apresenta os resultados detalhados, exibindo a latência e a distorção para cada nível de risco. Nos cenários 1 e 2, a latência ($tloop$) foi apenas medida, sem adaptação com novos parâmetros.}
\label{fig:resumo}
\fonte{Elaborado pelo autor.}
\end{figure}

Os dados detalhados e os gráficos interativos desta análise podem ser consultados no dashboard online do projeto: \href{https://roveda.dev/dissertacao/results/dashboard.html}{https://roveda.dev/dissertacao/results/dashboard.html}.

\section{Visão Geral e Comparativo Qualitativo}
Os experimentos foram conduzidos em um ambiente de simulação distribuída. Foram utilizados 20 nós de borda e uma população de pacientes com perfis de risco heterogêneos, conforme detalhado na Seção \ref{sec:cenarios}. Para isolar as contribuições de cada componente da arquitetura, três cenários distintos foram avaliados e estão descritos na Tabela \ref{tab:qualitative_comparison}.

\begin{table}[ht]
\caption{Comparativo qualitativo dos cenários experimentais}
\label{tab:qualitative_comparison}
\centering
\renewcommand{\arraystretch}{1.3} % Aumenta levemente o espaçamento
\begin{tabular}{p{2.5cm} p{3.5cm} p{3.5cm} p{4cm}}
\hline
\textbf{Característica} & \textbf{Cenário 1: Linha de Base} & \textbf{Cenário 2: Estático (VSAC)} & \textbf{Cenário 3: ViSPAC (Proposto)} \\ \hline
\textbf{Abordagem} & Transmissão Bruta & Compressão Estática & Compressão Adaptativa ao Risco \\
\textbf{Coleta} & Contínua (1s) & Fixa (15s) & Dinâmica (Algoritmo Back-off) \\
\textbf{Compressão} & Nenhuma & SDT + Huffman/LZW & SDT Adaptativo + Huffman/LZW \\
\textbf{Priorização} & Nenhuma & Nenhuma & Filas de Prioridade por Risco \\
\textbf{Feedback} & Unidirecional & Unidirecional & Bidirecional (Fog $\to$ Edge) \\
\textbf{Objetivo} & Integridade total & Redução de dados & Eficiência e Contexto Clínico \\ \hline
\end{tabular}
\fonte{Elaborado pelo autor.}
\end{table}

O \textbf{Cenário 1 (Linha de Base)} estabelece o pior caso de consumo, simulando dispositivos IoT burros que transmitem dados brutos continuamente. O \textbf{Cenário 2 (Estático)} representa o estado da arte anterior (modelo VSAC), com compressão na borda, mas sem sensibilidade ao contexto. O \textbf{Cenário 3 (ViSPAC)} concretiza a proposta deste trabalho ao integrar a priorização baseada no risco clínico (NEWS2), permitindo a adaptação dinâmica dos parâmetros de coleta e de transmissão.

A Tabela \ref{tab:quantitative_summary} consolida as métricas de desempenho obtidas ao longo de 12 horas de simulação contínua, demonstrando a evolução da eficiência do modelo proposto.

\begin{table}[ht]
\caption{Métricas de desempenho globais da simulação (20 nós edge, 12 horas)}
\label{tab:quantitative_summary}
\centering
\begin{tabular}{lrrr}
\hline
\textbf{Métrica} & \textbf{Linha de Base} & \textbf{Estático} & \textbf{ViSPAC} \\ \hline
Transmissões Totais (pacotes) & 6.642.048 & 564.237 & \textbf{220.403} \\
Volume de Dados Brutos (MB) & 245,11 & 246,96 & 245,01 \\
Volume Trafegado Final (MB) & 245,11 & 61,65 & \textbf{45,21} \\
Taxa de Compressão Média (\%) & 0,00 & 75,0 $\pm$ 10,6 & \textbf{81,6} $\pm$ 9,7 \\
Distorção – PRD Médio Global (\%) & 0,00 & 3,62 $\pm$ 4,94 & \textbf{1,16} $\pm$ 2,67 \\
Latência Média (ms) & 1.358,3 $\pm$ 249,5 & 1.271,2 $\pm$ 149,0 & \textbf{1.048,9} $\pm$ 3,8 \\ \hline
\end{tabular}
\fonte{Resultados experimentais obtidos da simulação. Valores de $\pm$ representam o desvio padrão entre os 20 nós edge ($\sigma$, $n=20$).}
\end{table}

É importante notar que o \textbf{Volume de Dados Brutos} é praticamente idêntico entre os três cenários ($\approx$245~MB), pois representa os mesmos dados fisiológicos serializados em \textit{MessagePack} antes de qualquer compressão. A pequena variação do Cenário Estático (+0,75\%) decorre do \textit{overhead} de metadados de lote (nível de risco, escore NEWS2, \textit{flags} de compressão), que não é totalmente compensado pela amortização em lotes maiores nos \textit{edges} de alto risco. Contudo, o indicador real de eficiência é o \textbf{Volume Trafegado Final}, no qual o ViSPAC demonstra sua superioridade.

\section{Análise de Redução de Transmissões}
A métrica de maior impacto sistêmico observada foi a drástica redução no número de interações com a rede. Comparado à Linha de Base, o ViSPAC reduziu em 96,7\% a frequência de envios, caindo de mais de 6,6 milhões de transmissões para apenas 220.403 (Figura \ref{fig:comparativo_transmissoes}).

\begin{figure}[!htbp]
\centering
\includegraphics[width=1.0\textwidth]{imagens/grafico_comparativo_transmissoes.png}
\caption{Gráfico comparativo do número total de transmissões (eixo primário, barras) e do volume de dados trafegados (eixo secundário, linha). A redução dos pacotes no ViSPAC impacta diretamente a longevidade da bateria dos dispositivos de borda.}
\label{fig:comparativo_transmissoes}
\fonte{Elaborado pelo autor.}
\end{figure}

Essa supressão massiva de tráfego é atribuída à atuação do \textbf{Algoritmo de Back-off (Algoritmo 2)} e à adaptação ao risco do paciente. Ao identificar períodos de estabilidade clínica e desacoplar a coleta da transmissão, o ViSPAC permite que o dispositivo de borda permaneça em modos de baixo consumo por períodos prolongados, despertando apenas para verificações locais (Algoritmo 3) ou quando o intervalo de envio é atingido. Diferentemente do Cenário Estático, que opera com janela fixa, o ViSPAC compra tempo de silêncio na rede, custeado pela estabilidade do paciente.

\section{Eficiência de Compressão e Volume de Dados}
O modelo ViSPAC alcançou uma \textbf{Taxa de Compressão Média de 81,6\%}, superando a de 75,0\% do Cenário Estático. Como consequência, o volume final trafegado foi de apenas 45,21 MB, em comparação aos 245,11 MB originais. A adoção do \textit{MessagePack} como formato de serialização (Seção~\ref{sec:serializacao}) contribuiu com uma redução de aproximadamente 30\% no volume bruto dos \textit{payloads} antes mesmo da compressão \textit{lossless}, pois a representação binária de números e estruturas é significativamente mais compacta do que a notação textual JSON. A Figura \ref{fig:compressao} apresenta esses dados de forma resumida.

\begin{figure}[!htbp]
\centering
\includegraphics[width=0.5\textwidth]{imagens/compressao.png}
\caption{Comparação da compressão média entre os cenários. Como o cenário 1 não possui compressão, ela está zerada. Os cenários 2 e 3 apresentam uma compressão muito próxima, com o cenário 3 tendo vantagem.}
\label{fig:compressao}
\fonte{Elaborado pelo autor.}
\end{figure}

Este ganho em relação ao modelo Estático (VSAC) não decorre de um novo algoritmo matemático de compressão, mas sim da estratégia arquitetural. Ao espaçar as coletas de pacientes estáveis, o ViSPAC gera séries temporais mais redundantes e lineares, um cenário ideal para o algoritmo SDT. Além disso, ao evitar pacotes de alta frequência para pacientes sem alterações, reduz-se o overhead de cabeçalhos de rede (TCP/IP e MQTT), o que corresponderia a uma parte significativa do volume de transmissões pequenas e frequentes.

\section{Fidelidade Clínica e Distorção (PRD)}
Um dos resultados mais significativos deste estudo reside na relação entre a compressão e a qualidade clínica. O ViSPAC obteve maior compressão geral mantendo uma distorção (PRD) média global de apenas \textbf{1,16\%}, consideravelmente menor que os \textbf{3,62\%} do Cenário Estático (Figura \ref{fig:comparativo_prd}). Esse resultado, à primeira vista contraintuitivo (maior compressão com menor erro), explica-se pela \textbf{seletividade clínica} do modelo. No Cenário Estático, uma compressão média é aplicada a todos os pacientes. No ViSPAC:

\begin{itemize}
\item \textbf{Pacientes Estáveis:} Sofrem compressão agressiva e \textit{back-off}. O PRD é elevado localmente, mas clinicamente irrelevante, pois o sinal é constante.
\item \textbf{Pacientes Críticos:} O sistema desativa a compressão agressiva e o \textit{back-off}. O sinal é transmitido com fidelidade quase total.
\end{itemize}

\begin{figure}[!ht]
\centering
\includegraphics[width=0.5\textwidth]{imagens/prd.png}
\caption{Comparação da Distorção PRD média. O ViSPAC apresenta menor distorção global, pois preserva a integridade quase total dos dados em momentos de crise, concentrando a perda de dados apenas em momentos de irrelevância clínica.}
\label{fig:comparativo_prd}
\fonte{Elaborado pelo autor.}
\end{figure}

A Tabela~\ref{tab:prd_by_risk} decompõe o PRD por nível de risco clínico e revela um padrão importante: quando analisados individualmente, os valores de PRD do ViSPAC são \textbf{superiores} aos do Cenário Estático em todas as faixas de risco. Isso ocorre porque os limiares SDT adaptativos do ViSPAC aplicam uma compressão \textit{lossy} mais agressiva do que o limiar fixo do modelo estático.

\begin{table}[ht]
\centering
\caption{Distorção PRD por nível de risco clínico}
\label{tab:prd_by_risk}
\footnotesize
\begin{tabular}{|l|r r|r r|}
\hline
\multirow{2}{*}{\textbf{Nível de Risco}} & \multicolumn{2}{c|}{\textbf{Estático}} & \multicolumn{2}{c|}{\textbf{ViSPAC}} \\
 & \textbf{PRD (\%)} & \textbf{Amostras} & \textbf{PRD (\%)} & \textbf{Amostras} \\ \hline
Alto    & 0,50 & 207.742 & 0,56 & 200.503 \\
Moderado & 0,70 & 40.396  & 1,27 & 5.429   \\
Baixo   & 5,59 & 85.310  & 8,25 & 5.401   \\
Mínimo  & 6,21 & 230.789 & 9,86 & 9.070   \\ \hline
\textbf{Média Global} & \textbf{3,62} & \textbf{564.237} & \textbf{1,16} & \textbf{220.403} \\ \hline
\end{tabular}
\fonte{Elaborado pelo autor.}
\end{table}

Entretanto, a coluna de amostras (\textit{n}) evidencia o mecanismo que explica a média global inferior. No Cenário Estático, o intervalo de coleta é fixo; por isso, pacientes de risco baixo e mínimo acumulam mais de 316 mil amostras com PRD elevado (5,59\%--6,21\%), dominando a média ponderada. No ViSPAC, o \textit{backoff} exponencial espaça progressivamente as coletas desses mesmos pacientes estáveis, reduzindo suas amostras para cerca de 14 mil. Assim, embora cada amostra individual apresente PRD ligeiramente mais alto, essas amostras representam uma fração muito menor do total, e a média global cai para 1,16\%. Em resumo: o ViSPAC comprime mais agressivamente quando comprime, porém comprime \textbf{muito menos vezes}, e o saldo líquido é uma distorção média global substancialmente inferior.

O elevado desvio padrão do PRD entre nós ($\sigma = 2{,}67$) reflete diretamente essa adaptação: nós com pacientes exclusivamente de risco mínimo apresentam PRD próximo de 9,86\%, enquanto nós com pacientes de alto risco mantêm PRD de apenas 0,56\%. Os valores observados enquadram-se dentro dos limiares reportados na literatura para compressão de sinais biomédicos: PRD inferiores a 5\% são considerados adequados para visualização e inferiores a 2\% para diagnóstico~\cite{Hassan2024}. Em todos os cenários de risco alto ou moderado, onde a informação clínica é mais crítica, o PRD do ViSPAC permanece abaixo de 1,27\%, bem dentro da faixa diagnóstica. Contudo, uma validação formal exigiria a avaliação por profissionais de saúde, com base nos sinais reconstruídos, para decisões clínicas, o que representa uma oportunidade para trabalhos futuros.

\section{Análise de Latência e Decomposição por Camada}
A latência percebida pelo \textit{edge} ($T_{\text{loop}}$) é uma métrica composta pela soma de três componentes: o tempo de rede (transmissão e recepção), o processamento do NEWS2 na \textit{fog} e, nos cenários de encaminhamento síncrono, o tempo de envio e de confirmação da \textit{cloud}. Para compreender as diferenças entre os cenários, a Tabela~\ref{tab:latency_decomposition} decompõe a latência média com base nos logs instrumentados do fog.

\begin{table}[!ht]
\centering
\caption{Decomposição da latência média por componente e cenário}
\label{tab:latency_decomposition}
\footnotesize
\begin{tabular}{|l|r|r|r|}
\hline
\textbf{Componente} & \textbf{Linha de Base} & \textbf{Estático} & \textbf{ViSPAC} \\ \hline
Processamento NEWS2 (\textit{fog}) & 2,31 ms & 1,65 ms & 0,88 ms \\ \hline
Encaminhamento fog–cloud & 230,06 ms & 207,73 ms & assíncrono \\ \hline
Rede + \textit{overhead} edge & 1.125,9 ms & 1.061,8 ms & 1.048,0 ms \\ \hline
\textbf{Latência total percebida pelo edge} & \textbf{1.358,3 ms} & \textbf{1.271,2 ms} & \textbf{1.048,9 ms} \\ \hline
\end{tabular}
\fonte{Calculado a partir dos logs do fog e das métricas dos edges.}
\end{table}

A decomposição evidencia três fatores que contribuem para a redução de latência no ViSPAC. O primeiro e mais expressivo é o \textbf{desacoplamento do encaminhamento para a cloud}. Nos Cenários~1 e~2, o fog aguarda a confirmação da \textit{cloud} antes de responder ao edge, o que adiciona 230 ms e 208 ms ao caminho crítico, respectivamente. No ViSPAC, esse encaminhamento ocorre de forma assíncrona via filas de prioridade, eliminando essa parcela da latência percebida pelo edge. O segundo fator é a \textbf{redução do volume dos pacotes transmitidos}. A compressão adaptativa, combinada com a serialização binária \textit{MessagePack}, resulta em pacotes menores, que demandam menos tempo de serialização e de transmissão na rede, contribuindo para a redução da componente de rede de 1.126 ms (Linha de Base) para 1.048 ms (ViSPAC). O terceiro fator, de menor magnitude, é a \textbf{eficiência do processamento no fog}: com lotes menores e menos frequentes, o tempo de processamento do NEWS2 cai de 2,31 ms para 0,88 ms.

Em termos práticos, dos 309,4 ms de redução entre a Linha de Base e o ViSPAC, aproximadamente 230 ms decorrem da decisão de arquitetura de encaminhamento assíncrono, e os 79 ms restantes resultam da combinação de compressão, serialização binária e menor volume de dados na rede. No Cenário~3, a componente de rede responde por 1.048,0 dos 1.048,9 ms de latência total (99,9\%), indicando que o processamento do fog é negligenciável em relação ao tempo de comunicação. Esse resultado reforça a premissa de que futuras otimizações devem concentrar-se na inteligência distribuída na borda, conforme discutido na Seção~\ref{sec:trabalhos_futuros}.

\section{Resumo por Cenário}
A Tabela \ref{tab:resumo_cenario} consolida as características e os resultados de cada cenário, permitindo uma comparação direta dos \textit{trade-offs} envolvidos.

\begin{table}[!ht]
\centering
\caption{Resumo consolidado por cenário de teste}
\label{tab:resumo_cenario}
\footnotesize
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Característica} & \textbf{Linha de Base} & \textbf{Estático (VSAC)} & \textbf{ViSPAC} \\ \hline
Transmissões & 6,6M & 564K & \textbf{220K} \\ \hline
Taxa de Compressão & 0\% & 75,0\% & \textbf{81,6\%} \\ \hline
PRD Médio Global & 0\% & 3,62\% & \textbf{1,16\%} \\ \hline
Latência Média & 1.358 ms & 1.271 ms & \textbf{1.049 ms} \\ \hline
Adaptação ao Risco & Não & Não & \textbf{Sim} \\ \hline
Vigilância Contínua & Não & Não & \textbf{Sim} \\ \hline
\end{tabular}
\fonte{Resultados experimentais.}
\end{table}

O \textbf{Cenário 1 (Linha de Base)} representa o pior cenário operacional, com o máximo consumo de banda e sem perda de dados. O \textbf{Cenário 2 (Estático/VSAC)} demonstra os ganhos puramente algorítmicos da compressão, reduzindo substancialmente o volume sem considerar o contexto clínico. O \textbf{Cenário 3 (ViSPAC)} mostra que a integração da priorização clínica não apenas mantém os ganhos de compressão, mas os amplia enquanto simultaneamente reduz a distorção média.

\section{Comportamento Adaptativo: Estudos de Caso}
Para validar a hipótese de que o sistema reaja corretamente a diferentes perfis clínicos, analisamos o comportamento temporal de três pacientes distintos durante a simulação.

\subsection{Paciente de Risco Alto (Paciente 09)}
O Paciente 09 (nó \texttt{edge-08}) apresentou instabilidade contínua (NEWS2 $\ge 7$). Conforme ilustrado na Figura \ref{fig:evolucao_risco_p09}, o ViSPAC identificou um risco elevado e manteve o sistema em estado de alerta. O mecanismo de \textit{back-off} foi desativado, e as transmissões ocorreram com frequência máxima e compressão mínima. O PRD resultante para este nó foi de 0,42\%, garantindo que a equipe médica remota visualizasse cada nuance das oscilações cardíaca e respiratória.

\begin{figure}[!ht]
\centering
\includegraphics[width=0.8\textwidth]{imagens/evolucao_risco_paciente_09.png}
\caption{Evolução do risco do Paciente 09. O sistema manteve-se em modo de alta fidelidade durante todo o período.}
\label{fig:evolucao_risco_p09}
\fonte{Elaborado pelo autor.}
\end{figure}

\subsection{Paciente de Risco Estável (Paciente 08)}
Em contraste, o Paciente 08 (nó \texttt{edge-06}) manteve sinais vitais dentro da normalidade (NEWS2 0), conforme demonstrado na Figura \ref{fig:evolucao_risco_p8}. A Figura \ref{fig:evolucao_coleta_p8}, por sua vez, demonstra a atuação do Algoritmo 2. Observa-se uma escada nos intervalos de coleta: após confirmar a estabilidade, o sistema dobrou sucessivamente o tempo entre envios até atingir o teto configurado. O nó transmitiu apenas uma fração dos pacotes em comparação ao Paciente 09. Esta economia inteligente libera largura de banda da rede para priorizar o tráfego de pacientes em estado crítico.

\begin{figure}[!ht]
\centering
\includegraphics[width=0.8\textwidth]{imagens/evolucao_risco_paciente_8.png}
\caption{Nível de risco do Paciente 08. Podemos notar que o risco se manteve estável.}
\label{fig:evolucao_risco_p8}
\fonte{Elaborado pelo autor.}
\end{figure}

\begin{figure}[!ht]
\centering
\includegraphics[width=0.8\textwidth]{imagens/evolucao_intervalo_coleta_paciente_8.png}
\caption{Evolução do intervalo de coleta do Paciente 08. Os pontos verdes indicam os momentos em que o algoritmo de back-off aumentou o intervalo devido à estabilidade prolongada.}
\label{fig:evolucao_coleta_p8}
\fonte{Elaborado pelo autor.}
\end{figure}

\subsection{Paciente de Risco Variável (Paciente 37)}
Um dos cenários mais desafiadores e representativos da proposta do ViSPAC pode ser observado no Paciente 37 (\textit{edge-07}, que alternou entre estados de estabilidade e deterioração rápida.
Inicialmente, o paciente apresentava risco BAIXO. Porém, logo após o início da simulação, o paciente teve seu risco alterado para MODERADO, o que levou o ViSPAC a ajustar o tempo de coleta e os parâmetros de compressão. Ao longo da jornada, o paciente oscilou entre riscos moderados e baixos, atingindo, inclusive, o risco ALTO em determinado momento.
Todos os algoritmos foram acionados ao longo da simulação:

\begin{enumerate}
\item \textbf{Detecção (Algoritmo 3):} A vigilância contínua detectou que a leitura atual divergia da anterior, ultrapassando o limiar $\varepsilon$.
\item \textbf{Interrupção:} O temporizador de \textit{back-off} foi cancelado imediatamente quando o algoritmo 3 atuou, forçando uma transmissão fora de hora.
\item \textbf{Reconfiguração:} A camada \textit{Fog} calculou o novo NEWS2 e enviou novos parâmetros à borda.
\item \textbf{Monitoramento Intensivo:} O nó passou a coletar e transmitir com frequência elevada, reduzindo a compressão.
\item \textbf{Retorno à Estabilidade:} Quando o paciente voltou a ficar estável, o \textit{back-off} retomou a atuação.
\end{enumerate}

As Figuras \ref{fig:evolucao_risco_p37} e \ref{fig:evolucao_coleta_p37} demonstram, respectivamente, o risco e os algoritmos em atuação ao longo desse caso.

\begin{figure}[!ht]
\centering
\includegraphics[width=0.8\textwidth]{imagens/evolucao_risco_paciente_37.png}
\caption{Nível de risco do Paciente 37. Podemos notar que o risco permanece instável.}
\label{fig:evolucao_risco_p37}
\fonte{Elaborado pelo autor.}
\end{figure}

\begin{figure}[!ht]
\centering
\includegraphics[width=0.8\textwidth]{imagens/evolucao_intervalo_coleta_paciente_37.png}
\caption{Evolução do intervalo de coleta do Paciente 37. Os pontos verdes indicam os momentos em que o algoritmo de back-off aumentou o intervalo devido à estabilidade. Os pontos vermelhos indicam onde houve uma mudança de risco e, por fim, os pontos amarelos indicam onde o algoritmo 3 precisou atuar, forçando uma coleta em razão da mudança brusca.}
\label{fig:evolucao_coleta_p37}
\fonte{Elaborado pelo autor.}
\end{figure}

Este caso comprova a eficácia do ciclo fechado \textit{Edge-Fog-Cloud}: o sistema economizou recursos quando possível, mas reagiu em tempo hábil à deterioração, comportando-se como um monitor de UTI quando necessário e como um monitor ambulatorial leve nos demais momentos.

\section{Discussão e Resposta às Questões de Pesquisa}
A análise dos resultados permite responder diretamente às questões de pesquisa formuladas na Seção \ref{sec:qp}, validando as hipóteses do trabalho.

\subsection{QP1: Teste com múltiplos sinais vitais}
A expansão do modelo para contemplar simultaneamente FC e $SpO_2$ demonstrou que a abordagem de compressão adaptativa multivariada é viável. O algoritmo SDT conseguiu processar ambos os sinais em paralelo na camada de borda, consumindo menos de 0,2\% de CPU na instância limitada. A correlação clínica entre os sinais foi tratada na camada \textit{Fog} por meio do NEWS2, o que prova que o modelo suporta a complexidade de múltiplos parâmetros fisiológicos sem degradação de desempenho.

\subsection{QP2: Adaptação via notificações Fog/Cloud}
O experimento comprovou a eficácia do mecanismo de \textit{feedback}. A latência média do ciclo ($T_{loop}$) de 1.048,9 ms é adequada para aplicações de monitoramento remoto (não invasivo/não cirúrgico), sendo inferior aos 5,3 segundos relatados por Cassel et al.~\cite{CASSEL2024}. A comparação é aproximada: Cassel reporta o tempo de processamento para 60\% dos sinais muito críticos (percentil), enquanto o ViSPAC reporta a média global de latência de todos os pacientes. Conforme detalhado na Tabela~\ref{tab:latency_decomposition}, essa latência contempla o tempo de rede, a descompressão e o cálculo do NEWS2, sendo beneficiada pelo encaminhamento assíncrono à \textit{cloud}. Ademais, o sistema foi capaz de reconfigurar dinamicamente os parâmetros $IC$, $\varepsilon$ e $DC$ na borda. A arquitetura baseada em MQTT garantiu que essas notificações de controle fossem leves, sem concorrerem com o tráfego de dados dos sinais vitais.

\subsection{QP3: Impacto na qualidade dos dados}
Os resultados de PRD médio global (1,16\% no ViSPAC vs 3,62\% no Estático) respondem positivamente a esta questão. O modelo demonstrou que é possível reduzir o volume de dados \textit{melhorando} a qualidade da informação clínica relevante. A estratégia de vincular a agressividade da compressão ao risco clínico (e não a um parâmetro fixo) garante que a distorção ocorra apenas onde é tolerável (sinais estáveis), preservando a morfologia do sinal em eventos críticos.

\subsection{QP4: Impacto computacional e gestão de coleta}
A avaliação de recursos computacionais mostrou que a sobrecarga introduzida pelos algoritmos de decisão (Configurador, Back-off) é negligenciável em relação aos benefícios de rede. O uso de memória manteve-se estável (~87 MB) e o uso de CPU permaneceu mínimo. O impacto principal foi positivo: ao reduzir em 96,7\% o número de ativações para transmissão, o modelo sugere uma extensão significativa da vida útil da bateria em dispositivos reais, um requisito fundamental para IoT em saúde.

\subsection{Consulta a Especialista Clínica}
\label{sec:validacao_especialista}

Para avaliar a pertinência clínica das decisões de projeto do ViSPAC, foi realizada uma consulta estruturada a uma profissional da área da saúde. A respondente possui formação em Enfermagem, com título de Mestre e Doutora, além de especializações em Saúde Pública, Enfermagem do Trabalho e Auditoria dos Serviços de Saúde. Atua como monitora de simulação clínica em ambiente hospitalar simulado, utilizando protocolos como o NEWS2 e o MEWS em cenários de treinamento com pacientes adultos.

A consulta abordou seis dimensões relevantes para o modelo proposto, cujas respostas são sintetizadas a seguir.

\textbf{Escolha do escore clínico.} A especialista declarou utilizar o \textbf{NEWS2} e o MEWS em sua prática profissional, confirmando que o escore adotado pelo ViSPAC é reconhecido e aplicado em contextos clínicos reais. Seu nível de confiança na avaliação por escores foi de 6 em uma escala de 1 a 7, indicando elevada confiança no instrumento, ainda que reconhecendo que escores não substituem a avaliação clínica completa.

\textbf{Seleção de sinais vitais.} Questionada sobre quais sinais vitais escolheria para monitoramento remoto residencial limitado a dois ou três parâmetros, a respondente indicou \textbf{frequência respiratória, saturação de oxigênio e frequência cardíaca}, por serem ``os mais sensíveis para detectar deterioração precoce''. Dois dos três sinais indicados (FC e $SpO_2$) correspondem exatamente aos utilizados no experimento do ViSPAC, enquanto a frequência respiratória é apontada como extensão prioritária para trabalhos futuros (Seção~\ref{sec:trabalhos_futuros}).

\textbf{Aceitabilidade da latência.} A latência de aproximadamente 1,05~s do ciclo de \textit{feedback} do ViSPAC foi apresentada como referência (arredondada para 1,5~s na formulação da pergunta, para avaliar um limiar mais conservador). A especialista considerou esse tempo ``perfeitamente adequado para monitoramento não invasivo'', corroborando a adequação da arquitetura proposta para cenários de vigilância remota.

\textbf{Confiança em sistemas automatizados.} A respondente afirmou que utilizaria um sistema de alerta automático ``para apoiar a tomada de decisão, mas nunca como substituto da avaliação clínica'', pois ``a tecnologia amplia nossa capacidade de vigilância e antecipa riscos'', embora não capte ``nuances como queixas subjetivas e contexto social''. Essa perspectiva reforça o posicionamento do ViSPAC como um \textbf{sistema de auxílio à tomada de decisão clínica}: ao fornecer dados priorizados e alertas baseados no NEWS2, o modelo amplia a capacidade de vigilância do profissional sem pretender substituir o julgamento clínico, que incorpora variáveis qualitativas inacessíveis a sensores remotos.

\textbf{Sensibilidade versus especificidade.} Diante da escolha entre receber muitos alertas (com falsos positivos) ou poucos alertas (com risco de omissão), a especialista optou pela \textbf{maior sensibilidade}, ressaltando a necessidade de ``estratégia para evitar fadiga de alarmes''. O mecanismo de vigilância contínua do ViSPAC (Algoritmo~3) opera nessa direção: mantém a sensibilidade de detecção mesmo durante intervalos longos de \textit{back-off}, enquanto a classificação por nível de risco nas filas de prioridade organiza os alertas para reduzir a sobrecarga informacional.

\textbf{Critério para intervenção remota.} A especialista indicou que enviaria uma ambulância com base exclusivamente em dados remotos apenas ``quando percebesse evidência forte de risco iminente de vida e impossibilidade de contato'', o que reforça a importância da classificação por níveis de risco implementada pelo ViSPAC: o sistema prioriza a transmissão de alta fidelidade precisamente nos casos em que o escore NEWS2 indica deterioração grave.

Em síntese, as respostas da especialista corroboram as principais decisões arquiteturais do modelo: a adoção do NEWS2 como escore de referência, a seleção de FC e $SpO_2$ como sinais prioritários, a adequação da latência obtida para monitoramento não invasivo e o equilíbrio entre sensibilidade de detecção e eficiência de recursos. A consulta, embora limitada a uma única respondente, fornece uma perspectiva clínica que complementa a avaliação quantitativa apresentada nas seções anteriores.

\subsection{Comparação com Trabalhos Relacionados}
A Tabela \ref{tab:comparacao_trs} apresenta uma comparação quantitativa entre os resultados do ViSPAC e os valores relatados nos trabalhos relacionados. Essa análise permite posicionar a contribuição desta dissertação no contexto do estado da arte.

\begin{table}[!ht]
\centering
\caption{Comparação quantitativa entre ViSPAC e trabalhos relacionados}
\label{tab:comparacao_trs}
\footnotesize
\begin{tabular}{|p{3.5cm}|p{2cm}|p{3.5cm}|p{4.5cm}|}
\hline
\textbf{Trabalho} & \textbf{Compressão} & \textbf{Distorção/Qualidade} & \textbf{Latência/Eficiência} \\ \hline
ViSPAC (proposto) & 81,6\% & PRD médio global 1,16\% & $T_{loop}$ 1,05 s; 96,7\% redução transmissões \\ \hline
VSAC \cite{Andrade2025} & 46\% & Menor que 36\% & – \\ \hline
Chang et al. \cite{Chang2024} & 80\% & 0,8 erro/402 casos & – \\ \hline
Hassan et al. \cite{Hassan2024} & 93,6\% & PRD 2\% & 91,35\% redução tráfego \\ \hline
Vakil et al. \cite{Vakil2024} & 98,6\% & – & 98\% economia energia \\ \hline
Cassel et al. \cite{CASSEL2024} & – & – & 5,3 s (P60 críticos) \\ \hline
Shankani et al. \cite{Shankani2025} & – & – & 40\% redução tráfego; 64\% energia \\ \hline
\end{tabular}
\fonte{Elaborado pelo autor.}
\end{table}

Os resultados permitem identificar os seguintes posicionamentos:
\textbf{Taxa de Compressão.} O ViSPAC alcança 81,6\% de compressão média, valor comparável aos 80\% (5:1) de Chang et al.~\cite{Chang2024} e superior aos 46\% do VSAC~\cite{Andrade2025}. Trabalhos como Hassan et al.~\cite{Hassan2024} (15,7:1) e Vakil et al.~\cite{Vakil2024} (70:1) reportam taxas superiores; contudo, esses estudos focam exclusivamente em ECG, com métodos de \textit{compressive sensing} ou de predição linear, não avaliando múltiplos sinais vitais nem a adaptação dinâmica. A vantagem do ViSPAC reside na \textbf{seletividade clínica}: a compressão agressiva é aplicada apenas a pacientes estáveis, enquanto pacientes críticos recebem transmissão de alta fidelidade.
\textbf{Distorção (PRD).} O PRD médio global de 1,16\% do ViSPAC é consideravelmente inferior aos 2\% reportados por Hassan et al.~\cite{Hassan2024}, mesmo com taxas de compressão comparáveis. Essa diferença decorre da estratégia adaptativa: ao concentrar a perda de informação nos períodos de estabilidade clínica e preservar integralmente os dados em momentos críticos, o modelo minimiza a distorção média global sem sacrificar a capacidade diagnóstica.
\textbf{Latência e Responsividade.} A latência de ciclo de 1.048,9 ms posiciona o ViSPAC favoravelmente em relação aos 5,3 segundos de Cassel et al.~\cite{CASSEL2024}. Embora as métricas não sejam diretamente comparáveis (Cassel reporta percentil 60 de sinais críticos; ViSPAC reporta média global), a melhoria relativa é atribuída a três fatores: o processamento primário do NEWS2 na camada \textit{fog} (em vez de depender exclusivamente da \textit{cloud}), a leveza do protocolo MQTT e o encaminhamento assíncrono para a nuvem, que remove a espera pela confirmação da nuvem do caminho crítico.
\textbf{Eficiência de Transmissão.} A redução de 96,7\% no número de transmissões supera os 40\% de Shankani et al.~\cite{Shankani2025} e os 91,35\% de Hassan et al.~\cite{Hassan2024}. Vakil et al.~\cite{Vakil2024} reportam 98\% de economia energética. Vale notar que a redução de transmissões e a economia de energia são métricas correlatas (menos transmissões implicam menor uso do rádio), porém não equivalentes, pois o consumo energético depende também de fatores como o processamento local e o modo de \textit{sleep}. O ViSPAC oferece uma vantagem qualitativa adicional: a garantia de que pacientes em deterioração clínica recebem monitoramento intensivo imediato, algo não contemplado nos demais trabalhos.

\subsection{Vantagens e Limitações do ViSPAC}
A análise crítica dos resultados permite identificar os seguintes pontos fortes e fracos do modelo proposto:

\textbf{Vantagens:}
\begin{itemize}
\item \textbf{Eficiência adaptativa:} O modelo ajusta automaticamente os parâmetros de compressão e de coleta conforme o estado clínico, eliminando a necessidade de configuração manual por paciente.
\item \textbf{Preservação de dados críticos:} Ao concentrar a compressão agressiva apenas em pacientes estáveis, o ViSPAC garante alta fidelidade nos momentos mais importantes para a tomada de decisão clínica.
\item \textbf{Vigilância contínua:} O mecanismo de \textit{keep-alive} (Algoritmo 3) oferece uma rede de segurança que detecta deteriorações mesmo durante longos intervalos de \textit{back-off}.
\item \textbf{Arquitetura distribuída:} O processamento do NEWS2 na \textit{fog} reduz a latência e a dependência da conectividade com a \textit{cloud}.
\end{itemize}

\textbf{Limitações:}
\begin{itemize}
\item \textbf{Ambiente simulado:} A validação foi conduzida em ambiente de nuvem com restrições artificiais de hardware, não reproduzindo todas as condições de um ambiente IoT real (interferências, variabilidade de bateria, etc.).
\item \textbf{Segurança e privacidade dos dados:} O protótipo atual não implementa criptografia ponta a ponta na comunicação MQTT entre as camadas. Em uma implantação real envolvendo dados clínicos sensíveis, o sistema estaria sujeito a regulamentações como a LGPD (Lei Geral de Proteção de Dados) e a HIPAA (Health Insurance Portability and Accountability Act). Para adequação, seria necessário usar de estratégias como a pseudonimização dos identificadores de pacientes (e de quaisquer dados sensíveis ou identificadores) antes da transmissão.
\item \textbf{Tolerância a falhas no nó Fog:} A arquitetura atual centraliza o processamento do NEWS2 em um único nó \textit{fog}, criando um ponto único de falha. Caso o \textit{fog} fique indisponível, os dispositivos \textit{edge} continuam operando com os últimos parâmetros recebidos, o que pode ser inadequado caso o estado clínico do paciente mude de forma relevante. Em uma implantação de produção, recomenda-se: (i) replicação do nó \textit{fog} com balanceamento de carga; (ii) cálculo local de estimativa do NEWS2 no \textit{edge} como \textit{fallback}; e (iii) em um cenário extremo, a camada \textit{cloud} poderia assumir temporariamente as funções do \textit{fog}, embora com maior latência.
\item \textbf{NEWS2 parcial com apenas 2 dos 7 sinais:} Os demais parâmetros do NEWS2 (frequência respiratória, temperatura, pressão arterial sistólica, nível de consciência e uso de oxigênio suplementar) foram fixados em valores de um paciente saudável. Essa simplificação introduz uma limitação clínica significativa: pacientes com alterações nesses parâmetros fixos seriam classificados incorretamente. Em uma implantação real, todos os 7 parâmetros do NEWS2 devem ser monitorados (ou do sistema de escore escolhido).
\end{itemize}

\section{Análise de Escalabilidade}
\label{sec:escalabilidade}
Os resultados apresentados até aqui demonstram a eficácia do ViSPAC em 20 nós de borda e em 97 pacientes. Contudo, a viabilidade de um modelo de monitoramento em Cidades Inteligentes depende da capacidade de atender a populações em maior número. Esta seção investiga o limite de escalabilidade da arquitetura proposta a partir de uma análise empírica do componente central do sistema: o nó \textit{fog}.

A escolha do fog como objeto de análise decorre de uma observação arquitetural direta. Cada nó \textit{edge} opera de forma autônoma, processando compressão e \textit{back-off} localmente sem depender dos demais. A camada de borda, portanto, escala horizontalmente por construção: adicionar um novo dispositivo \textit{edge} não impacta os demais dispositivos. O nó \textit{fog}, por outro lado, concentra o processamento de todos os lotes recebidos: descomprime os dados, calcula o escore NEWS2, devolve o \textit{feedback} ao edge emissor e enfileira os dados para encaminhamento assíncrono à \textit{cloud}. É, por definição, o gargalo potencial da arquitetura. Determinar sua capacidade máxima equivale a determinar a do sistema como um todo.

Para viabilizar essa análise, o código do \textit{fog} foi instrumentado para registrar, a cada lote MQTT recebido, três intervalos de tempo: o tempo de processamento efetivo (\textit{process\_ms}), que abrange a descompressão e o cálculo do NEWS2; o tempo de encaminhamento (\textit{forward\_ms}); e o tempo total do ciclo (\textit{total\_ms}). No Cenário~3, o encaminhamento à \textit{cloud} opera de forma assíncrona por meio de filas de prioridade, de modo que o \textit{forward\_ms} registrado é zero: o \textit{fog} responde ao \textit{edge} sem aguardar a nuvem. O tempo de serviço efetivo, portanto, corresponde apenas ao processamento local. Ao longo das 12 horas de simulação, o \textit{fog} processou \textbf{35.513 lotes}, fornecendo uma base estatística robusta para a análise.

\subsection{Utilização Observada do Fog}
A Tabela~\ref{tab:fog_metrics} consolida as métricas de tempo extraídas dos logs do \textit{fog} no Cenário~3 (encaminhamento assíncrono).

\begin{table}[!ht]
\centering
\caption{Métricas de desempenho do nó fog no Cenário~3 (35.513 lotes, 12h)}
\label{tab:fog_metrics}
\footnotesize
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Métrica} & \textbf{Média} & \textbf{Mediana} & \textbf{Máximo} \\ \hline
Processamento NEWS2 (\textit{process\_ms}) & 0,88 ms & 0,19 ms & 102,37 ms \\ \hline
Encaminhamento à cloud (\textit{forward\_ms}) & \multicolumn{3}{c|}{assíncrono (fora do caminho crítico)} \\ \hline
Total por lote (\textit{total\_ms}) & 1,14 ms & 0,43 ms & 105,78 ms \\ \hline
\end{tabular}
\fonte{Extraído dos logs do fog (Cenário~3, modo assíncrono).}
\end{table}

O cálculo do escore NEWS2 consome, em média, \textbf{0,88 ms} por lote, com mediana de 0,19 ms. Ao longo de 12 horas e 35.513 lotes, o \textit{fog} dedicou apenas 31 segundos de CPU ao processamento clínico. O tempo total por lote (1,14 ms) inclui a sobrecarga de desserialização \textit{MessagePack} e de publicação da resposta via MQTT, mas permanece na ordem de 1 milissegundo.

Para ilustrar o impacto do encaminhamento assíncrono, nos Cenários 1 e 2, que usam encaminhamento síncrono, o tempo médio de serviço foi de 232,5 ms e 209,5 ms por lote, respectivamente. Nesses cenários, o fog aguardava confirmação da cloud antes de continuar, então a latência inter-regional (208–230 ms) dominava o tempo. No Cenário 3, ao desacoplar o encaminhamento, o tempo de serviço despencou para pouco mais de 1 ms, uma redução de mais de duas ordens de magnitude.

A implementação do \textit{fog} utiliza o MQTT com uma única \textit{thread} de processamento: enquanto um lote é processado, os demais aguardam na fila do \textit{broker}. Esse modelo sequencial configura um sistema de servidor único, cuja utilização ($\rho$) corresponde à fração do tempo em que o servidor esteve efetivamente ocupado~\cite{Kleinrock1975}:

\begin{equation}
\rho = \frac{n \times \bar{t}{fog}}{T{sim}} = \frac{35.513 \times 0{,}00114\text{ s}}{43.200\text{ s}} = 0{,}00094 \quad (0{,}094\%)
\label{eq:rho}
\end{equation}

\noindent onde $n$ é o número de lotes processados, $\bar{t}{fog}$ é o tempo médio de serviço por lote (1,14 ms) e $T{sim}$ é a duração da simulação em segundos.

O resultado indica que, com 20 nós de borda e 97 pacientes, o fog utilizou menos de \textbf{0,1\% da sua capacidade de processamento}. A título de comparação, caso o encaminhamento fosse síncrono (como nos Cenários~1 e~2), a utilização seria de 16–25\%, limitando a capacidade a 65–103 edges por fog. O modo assíncrono, portanto, não apenas reduz a latência percebida no edge, mas também amplia a capacidade do fog em mais de duas ordens de magnitude.

\subsection{Projeção de Capacidade e Limites}
A independência entre os nós \textit{edge} sustenta uma hipótese de escalamento linear: cada edge adicionado contribui com uma parcela incremental e constante de carga para o \textit{fog}. Sob essa premissa, a utilização projetada para $N_e$ nós de borda é:

\begin{equation}
\rho(N_e) = \frac{N_e}{20} \times 0{,}00094
\label{eq:rho_ne}
\end{equation}

Em modelos clássicos de filas (e.g., M/M/1), o tempo médio de resposta cresce como $E[T] = \frac{1}{\mu(1-\rho)}$~\cite{Kleinrock1975,HarcholBalter2013}, onde $\mu$ é a taxa de serviço. Essa relação hiperbólica implica que, a partir de $\rho \approx 0{,}8$, pequenos acréscimos de carga causam aumentos desproporcionais na latência: a $\rho = 0{,}8$, o tempo de resposta é cinco vezes o tempo de serviço; a $\rho = 0{,}9$, dez vezes. Por isso, adota-se, para essa projeção, $\rho \leq 0{,}8$ como limiar conservador de operação estável, pois operar próximo desse valor permite absorver variações súbitas de carga e diferenças no perfil de risco dos pacientes, além de evitar a aproximação dos pontos de saturação do sistema. Aplicando esse limiar:

\begin{equation}
N_e^{max} = 20 \times \frac{0{,}8}{0{,}00094} \approx 17.000 \text{ edges}
\label{eq:nemax}
\end{equation}

Esse valor, equivalente a aproximadamente \textbf{82.500 pacientes}, é um limite teórico de CPU. Na prática, outros componentes da infraestrutura se tornariam gargalos antes que o processamento atingisse sua capacidade máxima. A coluna msg/s da Tabela~\ref{tab:projecao} reflete uma segunda dimensão de dimensionamento: a taxa de chegada de mensagens ao \textit{broker}. Essa taxa é derivada da observação dos cenários de teste realizados: o \textit{fog} recebeu 35.513 lotes em 43.200 segundos, resultando em uma taxa média de $\lambda_{edge} = 35.513 / (43.200 \times 20) \approx 0{,}041\,\text{msg/s}$ por \textit{edge}, linearmente projetada para $N_e$ \textit{edges}. A tabela combina ambas as projeções, indicando, para cada faixa de escala, os componentes de infraestrutura que demandariam atenção.

\begin{table}[!ht]
\centering
\caption{Projeção de escalabilidade do ViSPAC (encaminhamento assíncrono)}
\label{tab:projecao}
\footnotesize
\begin{tabular}{|r|r|c|c|p{5.5cm}|}
\hline
\textbf{Edges} & \textbf{Pacientes} & \textbf{$\rho$ (1 fog)} & \textbf{msg/s} & \textbf{Observação} \\ \hline
20 & 97 & 0,094\% & 0,8 & Experimento realizado \\ \hline
100 & 485 & 0,47\% & 4,1 & Margem ampla para uso (manter como experimento) \\ \hline
500 & 2.425 & 2,4\% & 20,5 & Margem ampla para uso (manter como experimento) \\ \hline
1.000 & 4.850 & 4,7\% & 41,1 & Margem ampla para uso (manter como experimento) \\ \hline
5.000 & 24.250 & 24\% & 205 & Monitorar o uso e verificar banda \\ \hline
10.000 & 48.500 & 47\% & 411 & Monitorar o uso e verificar banda, podendo ter um \textit{broker} dedicado \\ \hline
17.000 & 82.450 & 80\% & 698 & Limite teórico de CPU ($\rho \approx 0{,}8$), não recomendado operar nessa margem pois mudanças súbitas em grande escala podem deixar o sistema inoperável \\ \hline
\end{tabular}
\fonte{Projeção linear a partir da utilização observada no Cenário~3.}
\end{table}

Os limites práticos decorrem de três fatores. O primeiro é a capacidade do \textit{broker} MQTT, responsável pela comunicação entre os \textit{edges} e o \textit{fog}: um servidor Mosquitto de instância única suporta, tipicamente, dezenas de milhares de mensagens por segundo para payloads pequenos, o que acomodaria confortavelmente até milhares de \textit{edges} nas taxas observadas. O segundo fator é a memória consumida pelas filas de prioridade: caso a \textit{cloud} apresente lentidão temporária, os dados se acumulam na fila do fog até que o \textit{worker} consiga drená-los. Em cenários com milhares de \textit{edges}, picos de enfileiramento podem exigir dimensionamento de memória. O terceiro fator é a largura de banda da conexão HTTP entre o \textit{fog} e a \textit{cloud}, que deve ser suficiente para escoar o volume agregado de dados encaminhados pelo \textit{worker} assíncrono.

Uma consideração adicional diz respeito à composição de risco da população monitorada. No experimento, pacientes de risco alto predominaram e geraram aproximadamente 14 vezes mais tráfego do que os de risco baixo (0,424 pacotes por segundo por \textit{edge} contra 0,030). Essa assimetria decorre da própria lógica do ViSPAC: o \textit{back-off} suprime a maior parte das transmissões de pacientes estáveis, enquanto pacientes críticos transmitem continuamente. Em uma implantação em que a maioria da população apresenta risco baixo ou mínimo, a carga por edge seria substancialmente menor, e a capacidade do \textit{fog} poderia superar as projeções da tabela. Em cenários com alta concentração de pacientes críticos, o dimensionamento de múltiplos \textit{fogs} regionais seria necessário.

Em síntese, o encaminhamento assíncrono com filas de prioridade transformou o perfil de escalabilidade do \textit{fog}. O gargalo deixou de ser o processamento (que consome menos de 0,1\% da capacidade) e passou a depender de fatores de infraestrutura (broker, memória, rede), que são dimensionáveis de forma convencional. Para demandas superiores, a arquitetura suporta escalamento horizontal: a adição de $F$ nós fog regionais, cada um com seu próprio \textit{broker} MQTT, distribui a carga de forma proporcional.

%=======================================================================
% Conclusão
%=======================================================================

\chapter{Conclusão}
Esta dissertação apresentou o \textbf{ViSPAC}, um modelo voltado ao monitoramento remoto de sinais vitais em arquiteturas \textit{Edge--Fog--Cloud}. O modelo foi concebido como uma extensão do VSAC, incorporando mecanismos de priorização dinâmica baseados no escore clínico NEWS2 e expandindo a capacidade de processamento para múltiplos sinais vitais (FC e \textit{SpO\textsubscript{2}}).

O principal diferencial do ViSPAC reside na integração de um ciclo fechado de \textit{feedback} entre as camadas \textit{fog-cloud} e \textit{edge}, permitindo ajustar dinamicamente os parâmetros de compressão e frequência de coleta conforme o estado clínico do paciente. Essa abordagem foi implementada por meio de três algoritmos interdependentes: (i) o Configurador por Sinal Vital, que configura os parâmetros operacionais com base no risco clínico; (ii) o \textit{Back-off} Exponencial, que otimiza os intervalos de coleta durante períodos de estabilidade dos pacientes; e (iii) a Vigilância Contínua, que garante a detecção de deteriorações clínicas mesmo durante longos intervalos de silêncio.

Os experimentos foram conduzidos em um ambiente distribuído na AWS, simulando uma infraestrutura de Cidades Inteligentes, com 20 nós de borda operando sob restrições de hardware para se assemelharem às de dispositivos IoT. Os resultados demonstraram a eficácia do modelo proposto em múltiplas dimensões:

\begin{itemize}
    \item \textbf{Eficiência de rede:} O ViSPAC reduziu em 96,7\% o número de transmissões em comparação à linha de base, passando de mais de 6,6 milhões para 220.403 pacotes em 12~horas de simulação. Essa redução drástica impacta diretamente o consumo de energia de dispositivos vestíveis.

    \item \textbf{Compressão:} A taxa de compressão média atingiu 81,6\%, superando os 75,0\% do cenário estático (VSAC). A adoção da serialização binária \textit{MessagePack} reduziu o volume bruto dos \textit{payloads} em aproximadamente 30\% em relação ao JSON textual, e o volume final trafegado foi reduzido de 245,11~MB para 45,21~MB.

    \item \textbf{Fidelidade clínica:} Apesar da maior compressão, o ViSPAC apresentou distorção PRD média global de apenas 1,16\%, substancialmente inferior aos 3,62\% do modelo estático. Esse resultado aparentemente contraditório é explicado pela seletividade clínica: a compressão agressiva é aplicada apenas em momentos de estabilidade, preservando a integridade dos dados em situações críticas.

    \item \textbf{Responsividade:} A latência média do ciclo de \textit{feedback} foi de 1.048,9~ms, adequada para aplicações de monitoramento remoto não invasivo.
\end{itemize}

Retomando a questão de pesquisa principal formulada na Seção~\ref{sec:qp} --- \textit{Como aplicar priorização dinâmica com base em escores de múltiplos sinais vitais, de modo a otimizar a compressão, a coleta e a transmissão de dados clínicos críticos em um ambiente Edge--Fog--Cloud sem prejudicar a qualidade das informações?} --- este trabalho demonstra que a resposta reside na \textbf{integração de escores clínicos ao ciclo de controle distribuído}. Ao vincular os parâmetros de compressão ($DC$, $T_{\text{SDT}}$) e de coleta ($IC$) diretamente ao nível de risco do paciente, o modelo ViSPAC consegue: (i) reduzir em 81,6\% o volume de dados e em 96,7\% as transmissões para pacientes estáveis; além de (ii) preservar a fidelidade clínica (PRD médio global 1,16\%) concentrando a compressão mínima nos pacientes críticos. A arquitetura \textit{Edge--Fog--Cloud} permite que esse ajuste ocorra em tempo hábil (latência média de 1,05~s), viabilizando uma solução que \textbf{otimiza recursos sem comprometer a qualidade da informação clínica}.

Os experimentos corroboram as hipóteses levantadas pelas questões secundárias de pesquisa. Validou-se a viabilidade técnica de utilizar mais de um sinal vital, mantendo o desempenho estável. Paralelamente, o fluxo de notificações \textit{fog-cloud-edge} comprovou sua eficiência via MQTT, e a qualidade dos dados beneficiou-se da compressão orientada ao contexto clínico. Por fim, verificou-se que a sobrecarga computacional decorrente dos algoritmos de decisão é marginal quando comparada aos benefícios auferidos.

Em síntese, o ViSPAC apresenta-se como uma solução equilibrada para o desafio do monitoramento de saúde em larga escala no contexto das Cidades Inteligentes. Ao distribuir a inteligência entre as camadas (processamento do sinal na borda e avaliação do risco na \textit{fog}), o modelo consegue otimizar recursos de rede e energia sem comprometer a capacidade de resposta a eventos clínicos adversos.

\section{Contribuições}
As principais contribuições desta pesquisa são:
\begin{enumerate}
    \item \textbf{Modelo ViSPAC:} Um modelo de compressão adaptativa e priorização inteligente que gerencia múltiplos sinais vitais com ajuste dinâmico baseado no escore NEWS2, integrando compressão híbrida (\textit{lossy} + \textit{lossless}) a um ciclo fechado de controle \textit{Edge--Fog--Cloud}.
    
    \item \textbf{Estratégia de Controle Integrada:} A proposição de três algoritmos interdependentes que, em conjunto, equilibram eficiência e segurança clínica: (i) configuração dinâmica por sinal vital; (ii) \textit{back-off} exponencial condicionado ao risco; e (iii) vigilância contínua de baixo custo (\textit{keep-alive}).
\end{enumerate}

Complementarmente, a avaliação experimental, conduzida em ambiente de nuvem distribuído, com restrições de hardware simuladas para dispositivos IoT, demonstrou a viabilidade técnica do modelo em cenários realistas. O código-fonte e a infraestrutura como código estão disponíveis publicamente, permitindo a reprodução dos experimentos em diferentes contextos.

\section{Transferência de Tecnologia}
A arquitetura e os algoritmos desenvolvidos nesta dissertação têm potencial direto de aplicação no mercado de saúde digital, transcendendo o ambiente acadêmico. A transferência dessa tecnologia para a sociedade pode ser visualizada em três frentes de produtos complementares, cobrindo toda a cadeia de atendimento, conforme ilustrado na Figura~\ref{fig:transferencia_tecnologia} e que poderia ser testada em um ambiente de cidade inteligente (como São Leopoldo).

\begin{figure}[!ht]
\centering
\includegraphics[width=\textwidth]{imagens/transferencia_tecnologia.png}
\caption{Visão de transferência de tecnologia: da pesquisa acadêmica aos produtos de saúde digital. A camada \textit{Edge} opera em dispositivos vestíveis e em gateways domésticos, coletando dados, comprimindo-os e encaminhando-os para a camada \textit{Fog}, que atua como radar de risco em postos de saúde e ambulâncias do SAMU. Por fim, a camada \textit{Cloud} oferece gestão estratégica às secretarias de saúde. As setas indicam a comunicação contínua entre as camadas.}
\label{fig:transferencia_tecnologia}
\fonte{Elaborado pelo autor.}
\end{figure}

\begin{itemize}
    \item \textbf{Camada Edge (Gateway Doméstico):} Desenvolvimento de um dispositivo concentrador (\textit{System on Chip} ou aplicativo para smartphone) que recebe dados de múltiplos vestíveis (smartwatches, cintas cardíacas, oxímetros) via Bluetooth. Este gateway executaria o ViSPAC, comprimindo os sinais antes de encaminhá-los à camada \textit{Fog}. Como diferencial de mercado, a solução ofereceria uma extensão significativa da vida útil da bateria dos vestíveis (que apenas transmitem via Bluetooth de curto alcance) e redução do consumo de dados móveis. \textit{Exemplo prático:} Um paciente diabético poderia usar seu smartwatch convencional conectado a um gateway ViSPAC em casa, que decide inteligentemente quando transmitir dados para a nuvem, reduzindo os custos do plano de dados em até 90\%.
    
    \item \textbf{Camada Fog (Aplicação de Triagem):} Uma solução de software para instalar em servidores locais das Unidades Básicas de Saúde (UBS) e no SAMU (Serviço de Atendimento Móvel de Urgência). Esta aplicação funcionaria como um radar de risco, permitindo que equipes de socorro visualizem, em tempo hábil, apenas os pacientes em deterioração clínica na sua área de atuação, com latência mínima e independência da nuvem central. \textit{Exemplo prático:} Em um cenário de desastre com múltiplas vítimas, a central do SAMU poderia visualizar um mapa com pontos coloridos (verde, amarelo e vermelho) indicando a criticidade de cada paciente monitorado na região, permitindo priorizar o despacho de ambulâncias aos casos mais graves primeiro.
    
    \item \textbf{Camada Cloud (Plataforma de Gestão):} Um serviço SaaS (\textit{Software as a Service}) voltado a secretarias de saúde, planos de saúde e hospitais. Diferente da visão tática da \textit{Fog}, esta camada ofereceria uma visão estratégica: análise de tendências da população, auditoria de eventos passados e integração com prontuários eletrônicos, valorizando o armazenamento eficiente dos dados históricos comprimidos pelo ViSPAC. \textit{Exemplo prático:} Uma Secretaria Municipal de Saúde poderia identificar, por meio de dashboards analíticos, que determinado bairro apresenta aumento de 30\% nos escores médios do NEWS2 durante ondas de calor, direcionando campanhas preventivas e o reforço de equipes naquela região.
\end{itemize}

\section{Trabalhos Futuros}
\label{sec:trabalhos_futuros}
A partir dos resultados obtidos e das limitações identificadas, emergem três direções principais para pesquisas futuras:
\begin{enumerate}
    \item \textbf{Inteligência na borda:} A latência média de 1.048,9~ms corresponde, em sua grande parte, ao tempo de rede entre a edge e a fog. Para reduzi-la, trabalhos futuros podem explorar o cálculo de risco do NEWS2 diretamente no dispositivo edge, utilizando modelos leves de aprendizado de máquina ou o cálculo bruto. Pacientes estáveis poderiam ser gerenciados localmente, reservando a comunicação com o fog apenas para eventos de mudança de risco ou para validação periódica.
    
    \item \textbf{Novos algoritmos de compressão:} O SDT demonstrou-se eficaz, mas outras técnicas podem ser avaliadas para sinais mais variáveis. Algoritmos baseados em wavelets, autoencoders variacionais e métodos de compressão sensíveis ao contexto clínico representam alternativas promissoras para maximizar a taxa de compressão mantendo a fidelidade diagnóstica.
    
    \item \textbf{Algoritmos alternativos de priorização:} A arquitetura modular do ViSPAC permite substituir o NEWS2 por outros escores. Trabalhos futuros podem avaliar escores especializados (PEWS, MEWS), modelos de \textit{machine learning} treinados no histórico do próprio paciente ou a fusão de múltiplos indicadores clínicos em um escore composto.
\end{enumerate}

%=======================================================================
% Referências
%=======================================================================
\bibliography{exemplo}

\end{document}

